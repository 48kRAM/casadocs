{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "statwt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**WARNING**: If not run in preview mode,\n",
    "this application can modify the WEIGHT, WEIGHT_SPECTRUM, SIGMA,\n",
    "SIGMA_SPECTRUM, FLAG, and FLAG_ROW columns of the input MS. If you want\n",
    "a pristine copy of the input MS to be preserved, you should make a copy\n",
    "of it before running this application.\n",
    "\n",
    "This application computes values for the\n",
    "WEIGHT and WEIGHT_SPECTRUM (if present) columns and/or the SIGMA and\n",
    "SIGMA_SPECTRUM (if present) columns based on the variance of values in\n",
    "the CORRECTED_DATA or DATA column. If the MS does not have the specified\n",
    "data column, the application will fail. The following algorithm is\n",
    "used:\n",
    "\n",
    "1.  For unflagged data in each sample,\n",
    "    create two sets of values, one set is composed solely of the real\n",
    "    part of the data values, the other set is composed solely of the\n",
    "    imaginary part of the data values.\n",
    "2.  Compute the weighted (by exposure\n",
    "    time) variance of each of these sets, v$_r$ and v$_i$. The\n",
    "    weighted variance per unit inverse exposure time, v, is computed\n",
    "    using v = sum(e$_i$ \\* (V$_i$ -\n",
    "    \\<V\\>)$^2$)/N, where e$_i$ is the\n",
    "    exposure time for real/imaginary part of&nbsp; visibility V$_i$ and\n",
    "    \\<V\\> = sum(e$_i$ \\* V$_i$)/sum(e$_i$) is the\n",
    "    weighted mean of all the visibilities in the set, and N is the\n",
    "    number of (unflagged) visibilities (see also this [Knowledgebase\n",
    "    Article)](https://casa.nrao.edu/casadocs-devel/stable/memo-series/casa-knowledgebase/calculation-of-weights-for-data-with-varying-integration-time)  \n",
    "3.  Compute v$_{eq}$ $=$ (v$_{r}$ $+$ v$_{i}$)$/$2.\n",
    "4.  The associated weight of visibility\n",
    "    V$_i$&nbsp; is&nbsp; e$_i$ / V (see\n",
    "    [Knowledgebase\n",
    "    Article)](https://casa.nrao.edu/casadocs-devel/stable/memo-series/casa-knowledgebase/calculation-of-weights-for-data-with-varying-integration-time).\n",
    "    The weight will have unit of (data unit), e.g., Jy. The visibility\n",
    "    weights are what this application computes and writes.\n",
    "\n",
    "Data are aggregated on a per-baseline,\n",
    "per-data description ID basis. Data are aggregated in bins determined by\n",
    "the specified values of the *timebin* and *chanbin* parameters. By\n",
    "default, data for separate correlations are aggregated separately. This\n",
    "behavior can be overriden by specifying *combine=\"corr\"* (see\n",
    "below).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules regarding creating/initializing WEIGHT_SPECTRUM column\n",
    "\n",
    "1.  If run in preview mode\n",
    "    (*preview=True*), no data are modified and no columns are\n",
    "    added.\n",
    "2.  Else if *datacolumn='residual'* or\n",
    "    '*residual_data'* and a CORRECTED_DATA column exists, the WEIGHT and\n",
    "    WEIGHT_SPECTRUM columns are not modified.\n",
    "3.  Else if the MS already has a\n",
    "    WEIGHT_SPECTRUM and this column has been initialized (has values) it\n",
    "    will always be populated with the new weights. The WEIGHT column\n",
    "    will be populated with the corresponding median values of the\n",
    "    associated WEIGHT_SPECTRUM array.\n",
    "4.  Else if the frequency interval\n",
    "    (*chanbin*) is not the default ('spw', not to be confused with the\n",
    "    parameter *spw*), the WEIGHT_SPECTRUM column will be created (if it\n",
    "    doesn't already exist) and the new weights will be written to it.\n",
    "    The WEIGHT column should be populated with the corresponding median\n",
    "    values of the WEIGHT_SPECTRUM array.\n",
    "5.  Otherwise the single value for each\n",
    "    spectral window will be written to the WEIGHT column; the\n",
    "    WEIGHT_SPECTRUM column will not be added if it doesn't already\n",
    "    exist, and if it does, it will remain uninitialized (no values will\n",
    "    be written to it).\n",
    "6.  In cases where columns are added and\n",
    "    initialized, the WEIGHT_SPECTRUM values will be set equal to the\n",
    "    corresponding WEIGHT values, and the SIGMA_SPECTRUM values will be\n",
    "    set to the corresponding SIGMA values.\n",
    "\n",
    "In cases where columns are added and\n",
    "initialized, the WEIGHT_SPECTRUM values will be set equal to the\n",
    "corresponding WEIGHT values, and the SIGMA_SPECTRUM values will be set\n",
    "to the corresponding SIGMA values.\n",
    "\n",
    "**WARNING**:&nbsp;For some cases when only a subset of data is\n",
    "selected and the WEIGHT_SPECTRUM and/or SIGMA_SPECTRUM columns are\n",
    "created, there is a known code issue in which these columns are not\n",
    "properly created and initialized for the specified subset of data,\n",
    "although they are properly initialized for the entire dataset. In such\n",
    "cases, an exception will be thrown. Because the columns are created for\n",
    "the entire dataset, the user simply needs to rerun the statwt task using\n",
    "the same parameters and the task should complete as expected. Should\n",
    "this condition occur when the user is using the ms.statwt() tool method,\n",
    "the user should close the ms tool, and then reopen it using the same\n",
    "data set and configure the same selection, and rerun ms.statwt(). The\n",
    "tool method should then complete as expected.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rules for modifying WEIGHT, WEIGHT_SPECTRUM, SIGMA, and SIGMA_SPECTRUM\n",
    "\n",
    "1.  If *datacolumn='corrected'* or\n",
    "    *'residual'*, then values are written to the WEIGHT and\n",
    "    WEIGHT_SPECTRUM (if applicable) columns only.\n",
    "2.  If *datacolumn='data'* or\n",
    "    *'residual_data'* and the CORRECTED_DATA column does not exist, then\n",
    "    values are written to the WEIGHT and WEIGHT_SPECTRUM (if applicable)\n",
    "    columns and values in the SIGMA and SIGMA_SPECTRUM are set to\n",
    "    1/$\\sqrt{\\rm {newly\\,computed\\,weight}}$.\n",
    "    If a weight value is 0, the corresponding sigma value is -1.\n",
    "3.  If *datacolumn='data'* or\n",
    "    *'residual_data'* and the CORRECTED_DATA column does exist, then the\n",
    "    WEIGHT and WEIGHT_SPECTRUM columns are not updated and values in the\n",
    "    SIGMA and SIGMA_SPECTRUM are set to 1/$\\sqrt{\\rm {newly\\,computed\\,weight}}$.\n",
    "    If a weight value is 0, the corresponding sigma value is -1. In this\n",
    "    case, you should either split out the DATA column and run\n",
    "    **statwt**, or run with *datacolumn='corrected'* or *'residual'* to\n",
    "    update WEIGHT/WEIGHT_SPECTRUM. Otherwise the data are internally not\n",
    "    consistent.\n",
    "\n",
    "**NOTE**: **statwt** will produce an error\n",
    "if the measurement set has WEIGHT_SPECTRUM and/or SIGMA_SPECTRUM columns\n",
    "for which some rows are initialized (have values) and other rows have no\n",
    "data. It is recommended to run the **initweights** task to completely\n",
    "initialize these columns if you encounter this error.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Binning\n",
    "\n",
    "One of two algorithms can be used for time\n",
    "binning. If *slidetimebin=True*, then a sliding time bin of the\n",
    "specified width is used. If *slidetimebin=False*, then block time\n",
    "processing is used. The sliding time bin algorithm will generally be\n",
    "both more memory intensive and take longer than the block processing\n",
    "algorithm. Each algorithm is discussed in detail below.\n",
    "\n",
    "If the value of *timebin* is an\n",
    "integer,this value represents the number of contiguous, unique time\n",
    "stamps (from the MS TIME column) that should be used for averaging.\n",
    "\n",
    "\n",
    "The *timebin* parameter can also be\n",
    "specified as a quantity (string) that must have time conformant\n",
    "units.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Time Processing\n",
    "\n",
    "The data are processed in contiguous time\n",
    "blocks in this case. This means that all WEIGHT_SPECTRUM values will be\n",
    "set to the same value for all data within the same time bin/channel\n",
    "bin/correlation bin (see the section on channel binning and description\n",
    "of combine=\"corr\" for more details on channel binning and correlation\n",
    "binning).\n",
    "\n",
    "If timebin is specified as a time quantity\n",
    "(eg, '110s'), then the time bins are not necessarily contiguous and are\n",
    "not necessarily the same width. The start of a bin is always coincident\n",
    "with a value from the TIME column, So for example, if values from the\n",
    "TIME column are \\[20s, 60s, 100s, 140s, 180s, 230s\\], and timebin =\n",
    "110s, the first bin would start at 20s and run to 130s, so that data\n",
    "from timestamps 20s, 60s, and 100s will be included in the first bin.\n",
    "The second bin would start at 140s, so that data for timestamps 140s,\n",
    "180s, and 230s would be included in the second bin.\n",
    "\n",
    "In the case\n",
    "where timebin is an integer, this denotes the number of contigous\n",
    "timestamps that should be binned together. Note that, in this case, for\n",
    "rows \"left over\" in the upper edge of the bin, their values are computed\n",
    "using timebin that would include rows with times earlier than them. For\n",
    "example, in an MS with 8 rows in one block to be processed and\n",
    "timebin=3, timestamps 1, 2, and 3 would be used to compute the weights\n",
    "of the first three three rows, and rows 4, 5, and 6 would be used to\n",
    "compute weights for the next three rows as expected. Rows 7 and 8 are\n",
    "\"left over\" rows, but three rows (as per the integer timebin\n",
    "specification) are still used to compute them. Row 7 and 8 weights are\n",
    "computed by combining data in rows 6, 7, and 8. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliding Time Window Processing\n",
    "\n",
    "In the sliding time window case, in the\n",
    "case where timebin is a time quantity, the time window is always\n",
    "centered on the timestamp of the row in question and extends *timebin*2\n",
    "around that timestamp, subject the the time block boundaries. In the\n",
    "case where timebin is an integer, there are two cases to\n",
    "consider:\n",
    "\n",
    "1.  timebin is odd: In this case the\n",
    "    target row's data and the data from the +/-(n-1)/2 rows around the\n",
    "    target row are also used. \n",
    "2.  timebin is even: In this case, the\n",
    "    target row's data and the data from the n/2 rows after the target\n",
    "    row and the n/2 - 1 rows before the target row are used.\n",
    "\n",
    "In all cases for \"edge\" rows, the timebin\n",
    "extends from the edge of the block to the corresponding timebin value of\n",
    "rows away from the edge, so that the timebin is not symmetrical around\n",
    "the target rows, but includes the number of rows specified by the\n",
    "timebin value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overriding Default Block Boundaries** **\n",
    "\n",
    "Rows with the same baselines and data\n",
    "description IDs which are included in that window are used for\n",
    "determining the weight of that row. The boundaries of the time block to\n",
    "which the window is restricted are determined by changes in FIELD_ID,\n",
    "ARRAY_ID, and SCAN_NUMBER. One can override this behavior for FIELD_ID\n",
    "and/or SCAN_NUMBER by specifying the combine parameter (see below).\n",
    "Unlike the time block processing algorithm, this sliding time window\n",
    "algorithm requires that details of all rows for the time window in\n",
    "question are kept in memory, and thus the sliding window algorithm in\n",
    "general and the block processing row when timebin is an int, requires\n",
    "more memory than the block processing method when timebin is a quantity.\n",
    "Also, unlike the block processing method which computes a single value\n",
    "for all weights within a single bin, the sliding window method requires\n",
    "that each row (along with each channel and correlation bin) be processed\n",
    "individually, so in general the sliding window method will take longer\n",
    "than the block processing method.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel Binning\n",
    "\n",
    "The width of channel bins is specified via\n",
    "the *chanbin* parameter. Channel binning occurs within individual\n",
    "spectral windows; bins never span multiple spectral windows. Each\n",
    "channel will be included in exactly one bin. The default value 'spw'\n",
    "indicates that all channels in each spectral window are to be included\n",
    "in a single bin.\n",
    "\n",
    "Any other string value is interpreted as a\n",
    "quantity, and so should have frequency units, e.g., \"1MHz\". In this\n",
    "case, the channel frequencies from the CHAN_FREQ column of the\n",
    "SPECTRAL_WINDOW subtable of the MS are used to determine the bins. The\n",
    "first bin starts at the channel frequency of the 0th channel in the\n",
    "spectral window. Channels with frequencies that differ by less than the\n",
    "value specified by the *chanbin* parameter are included in this bin. The\n",
    "next bin starts at the frequency of the first channel outside the first\n",
    "bin, and the process is repeated until all channels have been\n",
    "binned.  \n",
    "  \n",
    " If specified as an integer, the value is\n",
    "interpreted as the number of channels to include in each bin. The final\n",
    "bin in the spectral window may not necessarily contain this number of\n",
    "channels. For example, if a spectral window has 15 channels, and\n",
    "*chanbin* is specified to be 6, then channels 0-5 will comprise the\n",
    "first bin, channels 6-11 the second, and channels 12-14 the third, so\n",
    "that only three channels will comprise the final bin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Minimum required number of visibilities\n",
    "\n",
    "The *minsamp* parameter allows the user to\n",
    "specify the minimum number of unflagged visibilities that must be\n",
    "present in a sample for that sample's weight to be computed. If a sample\n",
    "has less than this number of unflagged points, the associated weights of\n",
    "all the points in the sample are set to zero, and all the points in the\n",
    "sample are flagged.\n",
    "\n",
    "**WARNING**:&nbsp;Since\n",
    "**statwt**&nbsp;treats each baseline separately,&nbsp;selecting only a\n",
    "single channel in a spectral window will not satisfy the minimum number\n",
    "of samples (*minsamp*) if **statwt** is run with default parameters,\n",
    "leading to all the data in that spectral window being flagged. For such\n",
    "data, the user will need to change the default parameters in order to\n",
    "aggregate enough samples to satisfy minsamp (e.g., by setting\n",
    "*combine='corr'* if there are multiple correlation products, or\n",
    "timebin\\>1).\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating data across boundaries\n",
    "\n",
    "By default, data are not aggregated across\n",
    "changes in values in the columns ARRAY_ID, SCAN_NUMBER, STATE_ID,\n",
    "FIELD_ID, and DATA_DESC_ID. One can override this behavior for\n",
    "SCAN_NUMBER, STATE_ID, and FIELD_ID by specifying the *combine*\n",
    "parameter. For example, specifying *combine=\"scan\"* will ignore scan\n",
    "boundaries when aggregating data. Specifying *combine=\"field, scan\"*\n",
    "will ignore both scan and field boundaries when aggregating data. Also\n",
    "by default, data for separate correlations are aggregated separately.\n",
    "Data for all correlations within each spectral window can be aggregated\n",
    "together by specifying \"corr\" in the *combine* parameter. Any\n",
    "combination and permutation of \"scan\", \"field\", \"state\", and \"corr\" are\n",
    "supported by the *combine* parameter. Other values will be silently\n",
    "ignored.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics algorithms\n",
    "\n",
    "The supported statistics algorithms are\n",
    "described in detail in the imstat and ia.statistics() help. For the\n",
    "current application, these algorithms are used to compute vr and vi (see\n",
    "above), such that the set of the real parts of the visibilities and the\n",
    "set of the imaginary parts of the visibilities are treated as\n",
    "independent data sets.&nbsp; Care should be taken not to tune these\n",
    "algorithms in a way that will discard significant portions of the tails\n",
    "of the underlying noise distribution (e.g., *fence \\< 2* for the\n",
    "'HINGES-FENCES' algorithm).\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range of acceptable weights\n",
    "\n",
    "The *wtrange* parameter allows one to\n",
    "specify the acceptable range (inclusive, except for zero) for weights.\n",
    "Data with weights computed to be outside this range will be flagged. If\n",
    "not specified (empty array), all weights are considered to be\n",
    "acceptable. If specified, the array must contain exactly two\n",
    "non-negative numeric values. Note that data with weights of zero are\n",
    "always flagged. The units of the *wtrange* parameter will always match\n",
    "that of the WEIGHT column, even if the task is modifying the SIGMA\n",
    "column.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including/excluding channels\n",
    "\n",
    "Channels can be included in the\n",
    "computation of the weights by specifying the fitspw parameter. This\n",
    "parameter accepts a valid MS channel selection string. Data associated\n",
    "with the selected channels will be used in computing the weights; all\n",
    "other channels will be excluded from the computation of weights. By\n",
    "default (empty string), all channels are included.&nbsp;If the\n",
    "Boolean&nbsp;*excludechans*&nbsp;parameter is set to True, the channel\n",
    "selection will be inverted and exclude the selection made\n",
    "in&nbsp;*fitspw*.&nbsp;\n",
    "\n",
    "**CAUTION**: Use of *fitspw*, when\n",
    "*chanbin* is not 'spw', may lead to the excluded channels being flagged\n",
    "for having less than the minimum number of samples (*minsamp*).\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview mode\n",
    "\n",
    "By setting *preview=True*, the application\n",
    "is run in preview mode. In this mode, no data in the input MS are\n",
    "changed, although the amount of data that the application would have\n",
    "flagged is reported.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA column\n",
    "\n",
    "The *datacolumn* parameter can be\n",
    "specified to indicate which data column should be used for computing the\n",
    "weights. The values \"corrected\" for the CORRECTED_DATA column and \"data\"\n",
    "for the DATA column are supported (minimum match, case insensitive). One\n",
    "may specify 'residual' in which case the values used are the result of\n",
    "the CORRECTED_DATA column minus the model, or 'residual_data' in which\n",
    "case the values used are the DATA column minus the model, where model is\n",
    "the MODEL_DATA column if it exists, or if it doesn't, the virtual source\n",
    "model if one exists, or if that doesn't, then no model is used and the\n",
    "'residual' and 'residual_data' cases are equivalent to the 'corrected'\n",
    "and 'data' cases, respectively. The last two options are to allow for\n",
    "operation on timescales or frequency ranges which are larger than that\n",
    "over which the sky signal is expected to be constant. This situation\n",
    "arises in e.g., OTF mapping, and also perhaps with sources with\n",
    "significant spectral structure. In cases where a necessary column\n",
    "doesn't exist, an exception will be thrown and no data will be\n",
    "changed.\n",
    "\n",
    "**NOTE**: It\n",
    "is the user's responsibility to ensure that a model has been set for all\n",
    "selected fields before using *datacolumn='residual'* or\n",
    "*'residual_data'*.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return value\n",
    "\n",
    "In all cases, the mean and variance of the set of all weights computed\n",
    "by the application is reported and returned in a dictionary with keys\n",
    "'mean' and 'variance'. Weights for which there are corresponding flags\n",
    "(=True) prior to running the application are excluded from the\n",
    "computation of these statistics. If the WEIGHT_SPECTRUM values are\n",
    "available, they are used to compute the statistics, otherwise, the\n",
    "WEIGHT values are used. The returned statistics are always computed\n",
    "using the 'CLASSIC' algorithm; the value of *statalg* has no impact on\n",
    "how they are computed. The units of the the returned statistics will\n",
    "always match that of the WEIGHT column, even if the task is modifying\n",
    "the SIGMA column.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other considerations\n",
    "\n",
    "Flagged values are not used in computing\n",
    "the weights, although the associated weights of these values are\n",
    "updated. If the variance for a set of data is 0, all associated flags\n",
    "for that data are set to True, and the corresponding weights are set to\n",
    "0.\n",
    "\n",
    "&nbsp;"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
