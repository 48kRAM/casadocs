{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution Algorithms\n",
    "\n",
    "Minor cycle algorithms (Hogbom, Clark, Multi-Scale, Multi-Term)\n",
    "\n",
    "Deconvolution refers to the process of reconstructing a model of the sky\n",
    "brightness distribution, given a dirty/residual image and the\n",
    "point-spread-function of the instrument. This process is called a\n",
    "deconvolution because under certain conditions, the dirty/residual image\n",
    "can be written as the result of a convolution of the true sky brightness\n",
    "and the PSF of the instrument. Deconvolution forms the minor cycle of\n",
    "iterative image reconstruction in CASA.\n",
    "\n",
    "![4988e07e094ae12dd994cc53a49115f279a3ce9b.png](4988e07e094ae12dd994cc53a49115f279a3ce9b.png)\n",
    "\n",
    "|         |                                                                                                                                |\n",
    "|:--------|--------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Type    | Figure                                                                                                                         |\n",
    "| ID      | FigConvolution.png                                                                                                             |\n",
    "| Caption | The observed image (left) is the result of a convolution of the PSF (middle) and the true sky brightness distribution (right). |\n",
    "\n",
    "The image reconstruction framework is based on Cotton-Schwab major/minor\n",
    "cycles <a href=\"#cit1\" id=\"ref-cit1\" class=\"ref-cit\">[1]</a>. Within\n",
    "this system, the minor cycle algorithm operates largely in the image\n",
    "domain starting with a PSF and a residual image (i.e. the gradient of\n",
    "chi-square or the right hand side of the normal equations). The output\n",
    "is an incremental model image that defines the 'step' taken during the\n",
    "chi-square minimization process. In the next major cycle, the\n",
    "contribution of this model image is subtracted out of the list of\n",
    "visibilities and the result is regridded and transformed to produce a\n",
    "new residual image. This approach allows for a practical trade-off\n",
    "between the efficiency of operating in the image domain (or simply with\n",
    "gridded visibilities) and the accuracy that comes from returning to the\n",
    "ungridded list of visibilities after every 'step'. It also allows for\n",
    "minor cycle algorithms that have their own internal optimization schemes\n",
    "(i.e. they need not be strict chi-square minimizations) with their own\n",
    "control parameters. Note that any minor cycle algorithm that can operate\n",
    "on gridded visibilities can fit into this framework. The inputs to the\n",
    "minor cycle algorithm are the residual image, psf and perhaps a starting\n",
    "model. Outputs are a model image.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN Algorithm\n",
    "\n",
    "The CLEAN algorithm forms the basis for most deconvolution algorithms\n",
    "used in radio interferometry. The peak of the residual image gives the\n",
    "location and strength of a potential point source. The effect of the PSF\n",
    "is removed by subtracting a scaled PSF from the residual image at the\n",
    "location of each point source, and updating the model. Many such\n",
    "iterations of finding peaks and subtracting PSFs form the minor cycle.\n",
    "\n",
    "There are several variants of the CLEAN algorithm. Some operate with a\n",
    "delta function sky model and others with a multi-scale sky model. In all\n",
    "cases, the the sky brightness is parameterized in a sparse basis such\n",
    "that in practice, the minor cycle algorithm needs only to search for the\n",
    "location and amplitude of peaks. This makes it efficient. For example,\n",
    "fields of compact sources are best represented by delta function\n",
    "locations and amplitudes. Extended emission is modeled as a linear\n",
    "combination of components of different scale sizes and transformed into\n",
    "a multi-scale basis where again, delta functions are all that are\n",
    "required to mark the location and amplitude of blobs of different sizes.\n",
    "Multi-term algorithms for wideband imaging model the sky brightness and\n",
    "its spectrum simultaneously, using coefficients of a Taylor polynomial\n",
    "as a sparse representation of a smooth spectrum. In this case, the\n",
    "location of each (multi-scale) component is chosen via a search and the\n",
    "values of the Taylor coefficients for that component are solved for via\n",
    "a direct linear least squares calculation.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hogbom\n",
    "\n",
    "Hogbom CLEAN <a href=\"#cit2\" id=\"ref-cit2\" class=\"ref-cit\">[2]</a>\n",
    "operates with a point-source model of the sky brightness distribution.\n",
    "The minor cycle searches for the location and amplitude of components\n",
    "and then subtracts a scaled and shifted version of the full PSF to\n",
    "update the residual image for each point source. This algorithm is\n",
    "efficient in that delta functions are optimal for fields of compact\n",
    "sources, but susceptible to errors due to inappropriate choices of\n",
    "imaging weights, especially if the PSF has high sidelobes. It uses the\n",
    "full PSF during its update step to ensure that the next residual is as\n",
    "accurate as possible, but this can get compute intensive.  \n",
    "\n",
    "In its original form, the Hogbom algorithm operated just once in the\n",
    "image domain without new residuals being computed via a major cycle. In\n",
    "our CASA Imager implementation, it is treated as a minor cycle where one\n",
    "periodically does major cycles as well (to guard against minor cycle\n",
    "evolution that is not strictly constrained by the ungridded\n",
    "visibilities).\n",
    "\n",
    "Since Hogbom CLEAN uses only delta functions, it is most appropriate for\n",
    "fields of isolated point sources. It will incur errors when imaging\n",
    "extended emission and this is typically seen as a mottled appearance of\n",
    "smooth structure and the presence of correlated residuals.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clark\n",
    "\n",
    "Clark CLEAN <a href=\"#cit3\" id=\"ref-cit3\" class=\"ref-cit\">[3]</a> also\n",
    "operates only in the image-domain, and uses a point-source model. There\n",
    "are two main differences from the Hogbom algorithm. The first is that it\n",
    "does its residual image updates using only a small patch of the PSF.\n",
    "This is an approximation that will result in a significant speed-up in\n",
    "the minor cycle, but could introduce errors in the image model if there\n",
    "are bright sources spread over a wide field-of-view where the flux\n",
    "estimate at a given location is affected by sidelobes from far-out\n",
    "sources. The second difference is designed to compensate for the above.\n",
    "The iterations are stopped when the brightest peak in the residual image\n",
    "is below the first sidelobe level of the brightest source in the initial\n",
    "residual image and the residual image is re-computed by subtracting the\n",
    "sources and their responses in the gridded Fourier domain (to eliminate\n",
    "aliasing errors). Image domain peak finding and approximate subtractions\n",
    "resume again. These two stages are iterated between until the chosen\n",
    "minor cycle exit criteria are satisfied (to trigger the next true major\n",
    "cycle that operates on ungridded visibilities).\n",
    "\n",
    "Since Clark CLEAN also uses only delta function, it is similar in\n",
    "behavior to Hogbom. The main difference is that the minor cycle is\n",
    "expected to be much faster (for large images) because only a small\n",
    "fraction of the PSF is used for image-domain updates. Typically, errors\n",
    "due to such a truncation are controlled by transitioning to a uv-I2+Q2+U2+V2subtraction\n",
    "or a major cycle when the peak residual reaches the level of the highest\n",
    "sidelobe for the strongest feature.\n",
    "\n",
    "For polarization imaging, Clark searches for the peak in\n",
    "\n",
    "$I^2 + Q^2 + U^2 + V^2$\n",
    "\n",
    "$I^2 + Q^2 + U^2 + V^2$\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarkstokes\n",
    "\n",
    "In the '*clarkstokes*' algorithm, the Clark psf is used, but for\n",
    "polarization imaging the Stokes planes are cleaned sequentially for\n",
    "components instead of jointly as in '*clark*'. This means that this is\n",
    "the same as 'clark' for Stokes I imaging only. This option can also be\n",
    "combined with *imagermode='csclean'*.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Scale\n",
    "\n",
    "Cornwell-Holdaway Multi-Scale CLEAN (CH-MSCLEAN)\n",
    "<a href=\"#cit4\" id=\"ref-cit4\" class=\"ref-cit\">[4]</a> is a\n",
    "scale-sensitive deconvolution algorithm designed for images with\n",
    "complicated spatial structure. It parameterizes the image into a\n",
    "collection of inverted tapered paraboloids. The minor cycle iterations\n",
    "use a matched-filtering technique to measure the location, amplitude and\n",
    "scale of the dominant flux component in each iteration, and take into\n",
    "account the non-orthogonality of the scale basis functions while\n",
    "performing updates. In other words, the minor cycle iterations consider\n",
    "all scales together and model components are chosen in the order of\n",
    "decreasing integrated flux.\n",
    "\n",
    "MS-CLEAN can be formulated as a chi-square minimization applied to a sky\n",
    "model that parameterizes the sky brightness as a linear combination of\n",
    "flux components of different scale sizes. The figure below illustrates\n",
    "how a source with multi-scale features is represented by two scale sizes\n",
    "(for example) and how the problem reduces to one of finding the location\n",
    "and amplitudes of delta function components (something for which a CLEAN\n",
    "based approach is optimal). The top left and bottom left images show\n",
    "flux components of two different scale sizes. The images in the middle\n",
    "column show sets of delta functions that mark the locations and\n",
    "amplitudes of the flux components for each scale. The image on the far\n",
    "right is the sum of the convolutions of the first two columns of\n",
    "images. \n",
    "\n",
    "![ae3f0711d60cf1c82efb14326ff360c221a6f8c2.png](ae3f0711d60cf1c82efb14326ff360c221a6f8c2.png)\n",
    "\n",
    "|         |                                                                                                              |\n",
    "|:--------|--------------------------------------------------------------------------------------------------------------|\n",
    "| Type    | Figure                                                                                                       |\n",
    "| ID      | fig_msmodel.png                                                                                              |\n",
    "| Caption | A pictorial representation of how a source with structure at multiple spatial scales is modeled in MS-CLEAN. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing 'scales'\n",
    "\n",
    "In practice, the user must specify a set of scale sizes for the\n",
    "algorithm to use (in units of the number of pixels). As of now, this can\n",
    "be done only manually with the user making guesses of what the\n",
    "appropriate scale sizes are. This figure illustrates how the scales can\n",
    "be chosen, for a given structure on the sky. \n",
    "\n",
    "![eee4ed5ee088da2e6ad6378a3db5fa2719e9ae58.png](eee4ed5ee088da2e6ad6378a3db5fa2719e9ae58.png)\n",
    "\n",
    "|         |                                                                                    |\n",
    "|:--------|------------------------------------------------------------------------------------|\n",
    "| Type    | Figure                                                                             |\n",
    "| ID      | fig_multiscale_example.png                                                         |\n",
    "| Caption | An example set of multiscale 'scale sizes' to choose for a given source structure. |\n",
    "\n",
    "It is recommended that a '0' scale always be included to model\n",
    "unresolved sources. Beyond that, scale sizes should approximately follow\n",
    "the sizes of dominant structures in the image. For structure with very\n",
    "bright and sharp edges, a series of nearby scale sizes works best, often\n",
    "in conjunction with a mask. The largest scale size should be less than\n",
    "or equal to the smaller dimension of large scale features. One must also\n",
    "take care to avoid scale sizes that correspond to the unmeasured short\n",
    "spacings in the central region of uv space, as the reconstruction on\n",
    "these scales will see no constraints from the data and can result in\n",
    "arbitrary values (or divergence). For mosaics of extended emission, it\n",
    "is sometimes possible to use large scale sizes in the minor cycle if\n",
    "there are enough connected structures across pointings, but since there\n",
    "still is no actual short spacing uv data to constrain those scales, they\n",
    "should be used with caution. A reasonable starting point for setting the\n",
    "scales (assuming the cell size samples the mainlobe of the psf by a\n",
    "factor of \\~5) is *scales=\\[0,5,15\\]*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scale Bias\n",
    "\n",
    "By default, the optimal choice of scale per iteration is that which\n",
    "produces the maximum principal solution (assuming independent scales).\n",
    "Given this normalization, all scales supplied via the *scales* parameter\n",
    "are treated equally.\n",
    "\n",
    "In addition to this base normalization, a *smallscalebias* parameter may\n",
    "be used to bias the solution towards smaller or larger scales. This is\n",
    "especially useful when very large scale emission is coupled with weak\n",
    "compact features. The peak from each scale's smoothed residual is\n",
    "multiplied by ( 1 - *smallscalebias* \\* scale/maxscale ) to increase or\n",
    "decrease the amplitude relative to other scales, before the scale with\n",
    "the largest peak is chosen.\n",
    "\n",
    "*smallscalebias=0.0* (default) implies equal weight to all scales (as\n",
    "per the natural normalization that comes with the principal solution).\n",
    "Increasing it from 0.0 to 1.0 biases the reconstruction towards smaller\n",
    "scales in the supplied range. Decreasing it from 0.0 to -1.0 biases it\n",
    "towards larger scales in the supplied range.  It can be useful to\n",
    "experiment with MS-clean in *interactive=True* mode. If you notice that\n",
    "bright regions of emission are overcleaned in the first few major cycles\n",
    "(i.e. negative regions will appear in the residual image), it suggests\n",
    "that too much cleaning is happening on the largest scales and it can\n",
    "help to increase the *smallscalebias*. Additionally, it is often\n",
    "necessary to clean comparatively deeply to reap the full benefit of a\n",
    "multi-scale CLEAN.  Note also that scale bias (*smallscalebias*) is a\n",
    "fine-tuning tool that will be useful only if the list of supplied scale\n",
    "sizes is also appropriate to the structure being deconvolved; before\n",
    "turning to smallscalebias, it is advisable to first ensure that the\n",
    "*scales* parameter is set to reasonable values.\n",
    "\n",
    "**NOTE**: An improved *smallscalebias* paramater was implemented in CASA\n",
    "5.6 for both MultiScale and MTMFS deconvolution algorithms. Details can\n",
    "be found in [this CASA\n",
    "memo](https://casa.nrao.edu/casadocs-devel/stable/memo-series/casa-memos/casa_memo9_ms_mtmfs_clean.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Resolution CLEAN\n",
    "\n",
    "A related approach, called Multi-Resolution CLEAN is available in AIPS\n",
    "(and not in CASA). It is very similar to MS-CLEAN, although it operates\n",
    "on one scale size at a time. It smoothes the residual image and PSF by a\n",
    "particular scale size, and runs the minor cycle only on that scale. It\n",
    "switches scales after the next major cycle. This algorithm uses a\n",
    "different scale-based normalization (compared to MS-CLEAN) and has its\n",
    "own *scalebias* parameter which has its own formula. \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Term (with Multi-Scale)\n",
    "\n",
    "Multi-Scale Multi-Frequency synthesis (MSMFS)\n",
    "<a href=\"#cit5\" id=\"ref-cit5\" class=\"ref-cit\">[5]</a> is a wide-band\n",
    "imaging algorithm that models the wide-band sky brightness distribution\n",
    "as a collection of inverted, tapered paraboloids of different scale\n",
    "sizes, whose amplitudes follow a polynomial in frequency. A linear-least\n",
    "squares approach is used along with standard clean-type iterations to\n",
    "solve for best-fit spectral and spatial parameters. A point-source\n",
    "version of this algorithm can be run by specifying only one scale size\n",
    "corresponding to a delta-function.\n",
    "\n",
    "![b552095e2060703d930b11d1c63af3a9f32051be.png](b552095e2060703d930b11d1c63af3a9f32051be.png)\n",
    "\n",
    "|         |                                                                                                                                                                                                                                               |\n",
    "|:--------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Type    | Figure                                                                                                                                                                                                                                        |\n",
    "| ID      | figconvolutionmt.png                                                                                                                                                                                                                          |\n",
    "| Caption | A 2x2 system of equations to represent the fitting of a 2-term Taylor polynomial (Note that this is only a representative diagram using the same images shaded differently). In reality, the Hessian matrix contains different spectral PSFs. |\n",
    "\n",
    "The figure illustrates the set of normal equations that are to be solved\n",
    "in the image domain. What is usually a single convolution is now a joint\n",
    "convolution operator. The images on the left represent Taylor-weighted\n",
    "residual images, the 2x2 matrix contains spectral PSFs (the instruments'\n",
    "responses to spectra given by different Taylor functions), and the model\n",
    "images on the right represent Taylor coefficients per component. (Note :\n",
    "This figure only illustrates the structure of the system of equations.)\n",
    "\n",
    "More details about the algorithm and how to choose parameters such as\n",
    "the number of Taylor coefficients (nterms) and the reference frequency\n",
    "(reffreq) are given in the [Wideband\n",
    "Imaging](https://casa.nrao.edu/casadocs-devel/stable/imaging/synthesis-imaging/wide-band-imaging)\n",
    "section. \n",
    "\n",
    " \n",
    "\n",
    "Multiple Scales as part of the MTMFS algorithm are treated in the same\n",
    "way as MS-Clean (above), with the *scales* and  *smallscalebias*\n",
    "parameters available for choosing a range of scales and fine-tuning\n",
    "which ones get preference during reconstruction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Restoration\n",
    "\n",
    "The final list of flux components (or an image containing just the\n",
    "component delta functions) is restored by smoothing it with a Gaussian\n",
    "that matches the resolution of the main lobe of the PSF and adding back\n",
    "the residual image. This step is done in order to compensate for the\n",
    "unphysical nature of CLEAN based component images that include delta\n",
    "functions, and to include residual flux (especially for extended\n",
    "emission) that was not picked up as part of the model image. The need\n",
    "for restoration varies depending on the choice of algorithm but since\n",
    "all our CLEAN-based approaches include delta functions (with or without\n",
    "multi-scale components), this restoration step is always applied.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-term restoration\n",
    "\n",
    "Multi-term (wideband) restoration is a bit different from standard\n",
    "restoration in that it also modifies the residuals that are added to the\n",
    "smoothed model. Residuals are converted from Taylor-weighted averages of\n",
    "the residual data into Taylor coefficient space such that they represent\n",
    "the 'next higher order term' being imaged (a standard way of represent\n",
    "error). Practical implications of this are a higher than expected rms in\n",
    "the zero-th order image because the higher order terms being fitted have\n",
    "more reconstruction error and are not strictly linearly independent from\n",
    "the zero-th order term. In the outputs of the Multi-Term algorithm, the\n",
    "restored images contain these modified residuals, whereas the residual\n",
    "images contain the unmodified residuals which conform to what\n",
    "astronomers typically mean by 'residual' images. More details about the\n",
    "algorithm are provided in the [Wideband\n",
    "Imaging](https://casa.nrao.edu/casadocs-devel/stable/wide-band-imaging)\n",
    "section.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Bias\n",
    "\n",
    "Clean bias, an effect noticed for decades by users of the CLEAN\n",
    "algorithm, is a systematic shift of reconstructed peak intensities to\n",
    "lower than expected values. This is usually seen in deep imaging runs\n",
    "with large numbers of closely-spaced weak sources, and when the PSF has\n",
    "sidelobes above the 0.1 level. The use of masks or clean boxes to\n",
    "constrain the search space alleviates the problem. A PSF with lower\n",
    "sidelobes (for example the PSF from MFS imaging as compared to a single\n",
    "channel PSF) can also prevent this type of flux bias with the CLEAN\n",
    "algorithm and more importantly it does so without having to invoke\n",
    "complicated masking procedures.\n",
    "\n",
    "The clean bias effect can be explained by considering that the CLEAN\n",
    "algorithm is an L1-norm basis-pursuit method that is optimized for\n",
    "sparse signals that can be described with a minimal number of basis\n",
    "functions. For astronomical images this implies well-separated point\n",
    "sources whose properties can be described by single basis functions (one\n",
    "pixel each) and whose central peaks are minimally affected by PSF\n",
    "sidelobes from neighbouring sources. In a crowded field of point\n",
    "sources, especially with a PSF with high sidelobes, the CLEAN algorithm\n",
    "is more error-prone in the low SNR regime. A systematic lowering of\n",
    "source brightness can be explained by the algorithm constructing many\n",
    "artificial source components from the sidelobes of real sources.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Algorithms\n",
    "\n",
    "There are other options that are present in our code base, but not used\n",
    "much, could be experimental, coming in the near future, or simply\n",
    "untested. Information on how to add external algorithms is given below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MEM\n",
    "\n",
    "This algorithm models the sky brightness distribution as a collection of\n",
    "point-sources and uses a prior image along with an entropy-based penalty\n",
    "function to bias the solution of pixel amplitudes. The Maximum Entropy\n",
    "method (MEM) <a href=\"#cit6\" id=\"ref-cit6\" class=\"ref-cit\">[6]</a>\n",
    "<a href=\"#cit7\" id=\"ref-cit7\" class=\"ref-cit\">[7]</a> is a pixel-based\n",
    "deconvolution algorithm that performs a rigorously-constrained\n",
    "optimization in a basis of pixel amplitudes. MEM uses the Bayesian\n",
    "formulation of chi-square minimization, and applies a penalty function\n",
    "based on relative image entropy. This choice of penalty function biases\n",
    "the estimate of the true sky brightness towards a known prior image. If\n",
    "a flat image is chosen as the prior, the solution is biased towards\n",
    "being smooth, and produces a more realistic reconstruction of extended\n",
    "emission. Positivity and emptiness constraints can be applied on the\n",
    "image pixels via a penalty function.\n",
    "\n",
    "The MEM implementation in CASA's imager is unstable, and is unlikely to\n",
    "get attention as there are better methods available now. Please use\n",
    "multi-scale CLEAN instead.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ASP\n",
    "\n",
    "The Adaptive Scale Pixel (ASP)\n",
    "<a href=\"#cit8\" id=\"ref-cit8\" class=\"ref-cit\">[8]</a> deconvolution\n",
    "algorithm parameterizes the sky brightness distribution into a\n",
    "collection of Gaussians and does a formal constrained optimization on\n",
    "their parameters. In the major cycle, visibilities are predicted\n",
    "analytically with high accuracy. In the minor cycle, the location of a\n",
    "flux component is chosen from the peak residual, and the parameters of\n",
    "the largest Gaussian that fits the image at that location are found. The\n",
    "total number of flux-components is also updated as the iterations\n",
    "proceed.\n",
    "\n",
    "This algorithm is currently not available in CASA, but is on the\n",
    "mid-term implementation plan. \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison between deconvolution algorithms : One example\n",
    "\n",
    "Due to the fact that the uv-sampling is always incomplete, the result of\n",
    "a reconstruction algorithm can vary depending on the choice of sky model\n",
    "and the type of algorithm and constraints used. This figure shows a\n",
    "comparison between point-source CLEAN, MS-CLEAN, MEM and the ASP\n",
    "algorithms.\n",
    "\n",
    "In the figure below, the top row of panels show the component images\n",
    "that illustrate the different sky models being used. The middle row of\n",
    "panels shows restored images (used for the science). It should be noted\n",
    "that they are all different from each other and that they are all valid\n",
    "images. The main difference appears to be the achievable angular\n",
    "resolution. The bottom panels show residual images (gradient of\n",
    "chi-square) which radio astronomers typically use to judge whether all\n",
    "the signal in the data has been modeled or not. These images show how\n",
    "well the different methods handle extended emission. For example, CLEAN\n",
    "results in significant correlated flux in the residuals. MEM does better\n",
    "but the error pattern has significant structure outside the source too.\n",
    "MS-CLEAN has lower residuals than the two previous methods but has a\n",
    "characteristic pattern arising from using a fixed set of scale sizes to\n",
    "model complicated spatial structure. The ASP method shows much more\n",
    "noise-like residuals owing to the fact that at each iteration it finds\n",
    "best-fit components. Most more recent algorithms derived using\n",
    "compressed-sensing theory are reported (in the literature) to produce\n",
    "results similar to the ASP algorithm, as they all also perform fits to\n",
    "parameterized basis functions.\n",
    "\n",
    " \n",
    "\n",
    "![616ac63cbaf38d3c0b28e3970409e95713395ce3.png](616ac63cbaf38d3c0b28e3970409e95713395ce3.png) \n",
    "\n",
    "|         |                                                                                |\n",
    "|:--------|--------------------------------------------------------------------------------|\n",
    "| Type    | Figure                                                                         |\n",
    "| ID      | Create a short, unique name                                                    |\n",
    "| Caption | A comparison between point-source CLEAN, MS-CLEAN, MEM and the ASP algorithms. |\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Other Deconvolution algorithms\n",
    "\n",
    "External deconvolution algorithms can be connected to our imaging\n",
    "framework in order to access our data I/O and gridding routines (with\n",
    "parallelization) and avail of the option of operating within major/minor\n",
    "cycle loops instead of as stand-alone methods that don’t often connect\n",
    "to the data. The only pre-requisite is that the algorithm is able to\n",
    "operate in the image domain on a residual image and a PSF, and produce a\n",
    "model image as output. \n",
    "\n",
    "It should be noted that although many recently developed\n",
    "compressed-sensing algorithms do not explicitly make this uv-domain and\n",
    "image-domain distinction, their practical implementations do, and in\n",
    "some cases it is possible to frame the algorithm within a major/minor\n",
    "cycle structure (with residual visibilities being computed as 'data -\n",
    "model'). Another way of saying this is that our software can be used to\n",
    "implement the data-\\>image and image-\\>data transforms, while\n",
    "implementing an external reconstruction algorithm. The only exceptions\n",
    "are algorithms that require the gridding of something other than 'data -\n",
    "model' and which cannot be implemented as linear combinations in the\n",
    "image domain.\n",
    "\n",
    "Attempts by external algorithm developers to connect to our framework\n",
    "are welcome, as are suggestions for improving this interface to be more\n",
    "usable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task Interface\n",
    "\n",
    "**tclean** can be used in 'only major cycle' mode by setting *niter=0*.\n",
    "If *calcres=False*, *calcpsf=False* are set, then **tclean** can be also\n",
    "used to start directly with minor cycle algorithms that pick up\n",
    ".residual and .psf images from disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tool interface\n",
    "\n",
    "Python scripts can use our PySynthesisImager\n",
    "library to access each operational step of the **tclean** task, and to\n",
    "add or delete steps as necessary. Examples are given in the **tclean**\n",
    "task documentation (at the end of the examples page).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Within C++\n",
    "\n",
    "For C++ programmers, it is possible to connect a new deconvolution\n",
    "algorithm by deriving from SDAlgorithmBase\n",
    "and implementing three main routines (initialization, cleanup, and a\n",
    "'takeOneStep' method that does the series of minor cycle iterations).\n",
    "\n",
    " \n",
    "\n",
    "|                 |                        |\n",
    "|:----------------|------------------------|\n",
    "| Citation Number | 1                      |\n",
    "| Citation Text   | Schwab and Cotton 1983 |\n",
    "\n",
    "|                 |             |\n",
    "|:----------------|-------------|\n",
    "| Citation Number | 2           |\n",
    "| Citation Text   | Hogbom 1974 |\n",
    "\n",
    "|                 |            |\n",
    "|:----------------|------------|\n",
    "| Citation Number | 3          |\n",
    "| Citation Text   | Clark 1980 |\n",
    "\n",
    "|                 |               |\n",
    "|:----------------|---------------|\n",
    "| Citation Number | 4             |\n",
    "| Citation Text   | Cornwell 2008 |\n",
    "\n",
    "|                 |                     |\n",
    "|:----------------|---------------------|\n",
    "| Citation Number | 5                   |\n",
    "| Citation Text   | Rau & Cornwell 2011 |\n",
    "\n",
    " \n",
    "\n",
    "|                 |                         |\n",
    "|:----------------|-------------------------|\n",
    "| Citation Number | 6                       |\n",
    "| Citation Text   | Cornwell and Evans 1985 |\n",
    "\n",
    " \n",
    "\n",
    "|                 |                             |\n",
    "|:----------------|-----------------------------|\n",
    "| Citation Number | 7                           |\n",
    "| Citation Text   | Narayan and Nityananda 1986 |\n",
    "\n",
    "|                 |                             |\n",
    "|:----------------|-----------------------------|\n",
    "| Citation Number | 8                           |\n",
    "| Citation Text   | Bhatnagar and Cornwell 2004 |\n",
    "\n",
    " \n",
    "\n",
    "Bibliography\n",
    "\n",
    "  \n",
    "<sup>1.\\ Schwab\\ and\\ Cotton\\ 1983\\ [↩](#ref-cit1 \"Jump back to citation 1 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>2.\\ Hogbom\\ 1974\\ [↩](#ref-cit2 \"Jump back to citation 2 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>3.\\ Clark\\ 1980\\ [↩](#ref-cit3 \"Jump back to citation 3 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>4.\\ Cornwell\\ 2008\\ [↩](#ref-cit4 \"Jump back to citation 4 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>5.\\ Rau\\ &\\ Cornwell\\ 2011\\ [↩](#ref-cit5 \"Jump back to citation 5 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>6.\\ Cornwell\\ and\\ Evans\\ 1985\\ [↩](#ref-cit6 \"Jump back to citation 6 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>7.\\ Narayan\\ and\\ Nityananda\\ 1986\\ [↩](#ref-cit7 \"Jump back to citation 7 in the text.\")</sup>\n",
    "\n",
    "  \n",
    "<sup>8.\\ Bhatnagar\\ and\\ Cornwell\\ 2004\\ [↩](#ref-cit8 \"Jump back to citation 8 in the text.\")</sup>"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
