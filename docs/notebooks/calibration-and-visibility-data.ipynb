{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration & Visibilities \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visibilities Import Export \n",
    "\n",
    "Description of how to import and export Visibility Data to CASA.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview \n",
    "\n",
    "Overview of Visibility Data Import Export chapter\n",
    "\n",
    "[To use CASA to process your data, you first will need to get it into a form that is understood by the package. These are \"MeasurementSets\" for synthesis and single dish data, which is the purpose of this chapter. Importing images, or \"image tables\" as understood by CASA, is explained [here](https://casa.nrao.edu/casadocs-devel/stable/imaging/image-analysis/image-import-and-export).]{\n",
    "\n",
    "There are a number of tasks used to fill telescope-specific data and to import/export standard formats. These are:\n",
    "\n",
    "-   **importasdm** --- import of ALMA data in ASDM format\n",
    "-   **importuvfits** --- import visibility data in UVFITS format\n",
    "-   **importfitsidi** --- import visibility data in the FITS-IDI format\n",
    "-   **importvla** --- import data from VLA that is in export format\n",
    "-   **importmiriad** --- import data from MIRIAD visibilities\n",
    "-   **importatca** --- import ATCA data that is in the RPFITS (archive) format\n",
    "-   **importgmrt** --- import GMRT data\n",
    "-   **importasap** --- convert ASAP (ATNF Spectral Analysis Package) into a CASA visibility data format\n",
    "-   **importnro** --- import NRO 45m data \n",
    "-   **exportasdm** --- convert a CASA MS into an ASDM\n",
    "-   **exportuvfits** --- export a CASA MS in UVFITS format\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UV Data Import \n",
    "\n",
    "Converting Telescope UV Data to a MeasurementSet\n",
    "\n",
    "There are a number of tasks available to bring data in various forms into CASA as a MeasurementSet:\n",
    "\n",
    "-   ALMA and VLA Science Data Model format via **importasdm** and **importevla**\n",
    "-   historic VLA Archive format data via **importvla**\n",
    "-   ATCA Data via **importatca**\n",
    "-   MIRIAD Data from various telescopes via **importmiriad**\n",
    "-   GMRT Data via **importgmrt**\n",
    "-   UVFITS format can be imported into and exported from CASA (**importuvfits**, **importfitsidi**, and **exportuvfits**)\n",
    "\n",
    "\n",
    "##### ALMA and VLA Filling of Science Data Model (ASDM) data \n",
    "\n",
    "The ALMA and JVLA projects have agreed upon a common archival science data model (ASDM; sometimes also called SDM) format, and have jointly developed the software to fill this data into CASA. In the ASDM format, the bulk of the data is contained in large binary data format (BDF) tables, with the meta-data and ancillary information in XML tables. This is structured as a directory, like the MS, and was designed to be similar to the MS to facilitate conversion.\n",
    "\n",
    "The content of an ASDM can be listed with the task **asdmsummary**:\n",
    "\n",
    "```\n",
    "#asdmsummary :: Summarized description of an ASDM dataset.\n",
    "asdm = '' #Name of input ASDM directory\n",
    "```\n",
    "\n",
    "with an output that contains the list and positions of the antennas, followed by the metadata of each scan like observation time, source name, frequency and polarization setup:\n",
    "\n",
    "```python\n",
    "Input ASDM dataset : TDEM0008.sb3373760.eb3580330.55661.22790537037\n",
    "========================================================================================\n",
    "ASDM dataset :TDEM0008.sb3373760.eb3580330.55661.22790537037\n",
    "========================================================================================\n",
    "\n",
    "Exec Block : ExecBlock_0\n",
    "Telescope : JVLA\n",
    "Configuration name : B\n",
    "Observer name : Dr. Juergen Ott\n",
    "The exec block started on 2011-04-10T05:28:13.200000000 and ended on 2011-04-10T10:27:12.300000256\n",
    "\n",
    "27 antennas have been used in this exec block.\n",
    "        Id     Name         Make Station    Diameter         X              Y             Z\n",
    "     Antenna_0  ea01    UNDEFINED   W36        25    -1606841.96   -5042279.689    3551913.017\n",
    "     Antenna_1  ea02    UNDEFINED   E20        25     -1599340.8   -5043150.965    3554065.219\n",
    "     Antenna_2  ea03    UNDEFINED   E36        25   -1596127.728   -5045193.751    3552652.421\n",
    "     Antenna_3  ea04    UNDEFINED   W28        25   -1604865.649    -5042190.04    3552962.365\n",
    "     Antenna_4  ea05    UNDEFINED   W08        25   -1601614.091   -5042001.653    3554652.509\n",
    "     Antenna_5  ea06    UNDEFINED   N24        25    -1600930.06   -5040316.397    3557330.397\n",
    "     Antenna_6  ea07    UNDEFINED   E32        25   -1597053.116   -5044604.687    3553058.987\n",
    "     Antenna_7  ea08    UNDEFINED   N28        25   -1600863.684   -5039885.318    3557965.319\n",
    "     Antenna_8  ea09    UNDEFINED   E24        25    -1598663.09   -5043581.392    3553767.029\n",
    "     Antenna_9  ea10    UNDEFINED   N32        25   -1600781.039   -5039347.456    3558761.542\n",
    "     Antenna_10  ea11    UNDEFINED   E04        25    -1601068.79    -5042051.91    3554824.835\n",
    "     Antenna_11  ea12    UNDEFINED   E08        25   -1600801.926   -5042219.366    3554706.448\n",
    "     Antenna_12  ea14    UNDEFINED   W12        25   -1602044.903   -5042025.824    3554427.832\n",
    "     Antenna_13  ea15    UNDEFINED   W24        25   -1604008.742   -5042135.828    3553403.707\n",
    "     Antenna_14  ea16    UNDEFINED   N12        25   -1601110.052   -5041488.079    3555597.439\n",
    "     Antenna_15  ea17    UNDEFINED   W32        25   -1605808.656   -5042230.082    3552459.202\n",
    "     Antenna_16  ea18    UNDEFINED   N16        25   -1601061.961    -5041175.88    3556058.022\n",
    "     Antenna_17  ea19    UNDEFINED   W04        25   -1601315.893    -5041985.32    3554808.305\n",
    "     Antenna_18  ea20    UNDEFINED   N36        25   -1600690.606   -5038758.734    3559632.061\n",
    "     Antenna_19  ea21    UNDEFINED   E12        25    -1600416.51    -5042462.45    3554536.041\n",
    "     Antenna_20  ea22    UNDEFINED   N04        25   -1601173.979   -5041902.658    3554987.518\n",
    "     Antenna_21  ea23    UNDEFINED   E16        25   -1599926.104   -5042772.967    3554319.789\n",
    "     Antenna_22  ea24    UNDEFINED   W16        25   -1602592.854   -5042054.997      3554140.7\n",
    "     Antenna_23  ea25    UNDEFINED   N20        25   -1601004.709   -5040802.809    3556610.133\n",
    "     Antenna_24  ea26    UNDEFINED   W20        25   -1603249.685   -5042091.404    3553797.803\n",
    "     Antenna_25  ea27    UNDEFINED   E28        25   -1597899.903   -5044068.676    3553432.445\n",
    "     Antenna_26  ea28    UNDEFINED   N08        25    -1601147.94   -5041733.837    3555235.956\n",
    "\n",
    "Number of scans in this exec Block : 234\n",
    "\n",
    "scan #1 from 2011-04-10T05:28:13.200000000 to 2011-04-10T05:33:35.500000256\n",
    "        Intents : OBSERVE_TARGET\n",
    "        Sources : 1331+305=3C286\n",
    "        Subscan #1 from 2011-04-10T05:28:13.200000000 to 2011-04-10T05:33:35.500000256\n",
    "                Intent : UNSPECIFIED\n",
    "                Number of integrations : 322\n",
    "\n",
    "                 Binary data in uid:///evla/bdf/1302413292901\n",
    "                 Number of integrations : 322\n",
    "                 Time sampling : INTEGRATION\n",
    "                 Correlation Mode : CROSS_AND_AUTO\n",
    "                 Spectral resolution type : FULL_RESOLUTION\n",
    "                 Atmospheric phase correction : AP_UNCORRECTED\n",
    "                 SpectralWindow_0 : numChan = 256, frame = TOPO,\n",
    "                 firstChan = 8484000000, chandWidth = 125000 x Polarization_0 : corr = RR,LL\n",
    "\n",
    "scan #2 from 2011-04-10T05:33:35.500000256 to 2011-04-10T05:35:35.200000000\n",
    "        Intents : OBSERVE_TARGET\n",
    "        Sources : 1331+305=3C286\n",
    "        Subscan #1 from 2011-04-10T05:33:35.500000256 to 2011-04-10T05:35:35.200000000\n",
    "                Intent : UNSPECIFIED\n",
    "                Number of integrations : 119\n",
    "\n",
    "                 Binary data in uid:///evla/bdf/1302413293280\n",
    "                 Number of integrations : 119\n",
    "                 Time sampling : INTEGRATION\n",
    "                 Correlation Mode : CROSS_AND_AUTO\n",
    "                 Spectral resolution type : FULL_RESOLUTION\n",
    "                 Atmospheric phase correction : AP_UNCORRECTED\n",
    "                 SpectralWindow_0 : numChan = 256, frame = TOPO,\n",
    "                 firstChan = 8484000000, chandWidth = 125000 x Polarization_0 : corr = RR,LL\n",
    "\n",
    "scan #3 from 2011-04-10T05:35:35.200000000 to 2011-04-10T05:36:34.999999488\n",
    "        Intents : OBSERVE_TARGET\n",
    "        Sources : 1331+305=3C286\n",
    "        Subscan #1 from 2011-04-10T05:35:35.200000000 to 2011-04-10T05:36:34.999999488\n",
    "...\n",
    "```\n",
    "\n",
    "The **importasdm** task will fill SDM1.2 and SDM1.3 format data into a CASA visibility data set (MS). ALMA data was recorded in SDM1.2 format from October 2009 until May 2011. Since May 2011, ALMA is using the SDM 1.3 format. In particular all science data from cycle 0 onwards is in SDM1.3. The JVLA also started using SDM1.2 in October 2009 and continues to use this format. **importasdm** can read all of the above formats. The parameter *useversion* can be used to enable the options *process_syspower*, *process_caldevice*, and *process_pointing*.\n",
    "\n",
    "The default inputs of **importasdm** are:\n",
    "\n",
    "```\n",
    "#importasdm :: Convert an ALMA Science Data Model observation into a\n",
    "CASA visibility file (MS) or single-dish data format (Scantable)\n",
    "asdm                =         ''        #Name of input asdm directory (on\n",
    "                                        #disk)\n",
    "vis                 =         ''        #Root name of the MS to be created.\n",
    "                                        #Note the .ms is NOT added\n",
    "createmms           =      False        #Create a multi-MS output\n",
    "singledish          =      False        #Set true to output single-dish data\n",
    "                                        #format\n",
    "corr_mode           =      'all'        #specifies the correlation mode to be\n",
    "                                        #considered on input. A quoted string\n",
    "                                        #containing a sequence of ao, co,\n",
    "                                        #ac,or all separated by whitespaces\n",
    "                                        #is expected\n",
    "srt                 =      'all'        #specifies the spectral resolution\n",
    "                                        #type to be considered on input. A\n",
    "                                        #quoted string containing a sequence\n",
    "                                        #of fr, ca, bw, or all separated by\n",
    "                                        #whitespaces is expected\n",
    "time_sampling       =      'all'        #specifies the time sampling\n",
    "                                        #(INTEGRATION and/or SUBINTEGRATION)\n",
    "                                        #to be considered on input. A quoted\n",
    "                                        #string containing a sequence of i,\n",
    "                                        #si, or all separated by whitespaces\n",
    "                                        #is expected\n",
    "ocorr_mode          =       'ca'        #output data for correlation mode\n",
    "                                        #AUTO_ONLY (ao) or CROSS_ONLY (co) or\n",
    "                                        #CROSS_AND_AUTO (ca)\n",
    "compression         =      False        #Flag for turning on data compression\n",
    "lazy                =      False        #Make the MS DATA column read the ASDM\n",
    "                                        #Binary data directly (faster import,\n",
    "                                        #smaller MS)\n",
    "asis                =         ''        #Creates verbatim copies of the\n",
    "                                        #ASDMtables in the ouput MeasurementSet.\n",
    "                                        #Value given must be a string\n",
    "                                        #of table names separated by spaces;\n",
    "                                        #A * wildcard is allowed.\n",
    "wvr_corrected_data  =       'no'        #Specifies which values are considerd\n",
    "                                        #in the SDM binary data to fill the\n",
    "                                        #DATA column in the MAIN table of the\n",
    "                                        #MS. Expected values for this option\n",
    "                                        #are: no, for uncorrected data\n",
    "                                        #(default), yes, for the corrected\n",
    "                                        #data, and both, for for corrected\n",
    "                                        #and uncorrected data. Note if both\n",
    "                                        #is selected two MeasurementSets are\n",
    "                                        #created, one with uncorrected data\n",
    "                                        #and the other with corrected data.\n",
    "scans               =         ''        #processes only the specified scans.\n",
    "                                        #This value is a semicolon separated\n",
    "                                        #list of scan specifications. A scan\n",
    "                                        #specification consists of an exec\n",
    "                                        #block index followed by the :\n",
    "                                        #character;  followed by a comma\n",
    "                                        #separated list of scan indexes or\n",
    "                                        #scan index ranges. A scan index is\n",
    "                                        #relative to the exec block it\n",
    "                                        #belongs to. Scan indexes are 1-based\n",
    "                                        #while exec blocks are 0-based. \"0:1\"\n",
    "                                        #or \"2:2~6\" or\n",
    "                                        #\"0:1,1:2~6,8;2:,3:24~30\" \"1,2\" are\n",
    "                                        #valid values for the option. \"3:\"\n",
    "                                        #alone will be interpreted as, all\n",
    "                                        #the scans of the exec block#3.  An\n",
    "                                        #scan index or a scan index range not\n",
    "                                        #preceded by an exec block index will\n",
    "                                        #be interpreted as, all the scans\n",
    "                                        #with such indexes in all the exec\n",
    "                                        #blocks.  By default all the scans\n",
    "                                        #are considered.\n",
    "ignore_time         =      False        #All the rows of the tables Feed,\n",
    "                                        #History, Pointing, Source, SysCal,\n",
    "                                        #CalDevice, SysPower, and Weather are\n",
    "                                        #processed independently of the time\n",
    "                                        #range of the selected exec block /\n",
    "                                        #scan.\n",
    "process_syspower    =       True        #The SysPower table is processed if\n",
    "                                        #and only if this parameter is set to\n",
    "                                        #true.\n",
    "process_caldevice   =       True        #The CalDevice table is processed if\n",
    "                                        #and only if this parameter is set to\n",
    "                                        #true.\n",
    "process_pointing    =       True        #The Pointing table is processed if\n",
    "                                        #and only if this parameter is set to\n",
    "                                        #true. If set to False, the POINTING\n",
    "                                        #table is empty in the resulting MS\n",
    "process_flags       =       True        #Create online flags in the FLAG_CMD\n",
    "                                        #sub-table.\n",
    "     tbuff          =        0.0        #Time padding buffer (seconds)\n",
    "     applyflags     =      False        #Apply the flags to the MS.\n",
    "     savecmds       =      False        #Save flag commands to an ASCII file\n",
    "     outfile        =         ''        #Name of ASCII file to save flag\n",
    "                                        #commands\n",
    "\n",
    "flagbackup          =       True        #Back up flag column before applying\n",
    "                                        #flags.\n",
    "verbose             =      False        #Output lots of information while the\n",
    "                                        #filler is working\n",
    "overwrite           =      False        #Over write an existing MS(s)\n",
    "showversion         =      False        #Report the version of asdm2MS being\n",
    "                                        #used\n",
    "useversion          =       'v3'        #Version of asdm2MS to be used ('v3'\n",
    "                                        #(default, should work for all data))\n",
    "bdfflags            =      False        #Set the MS FLAG column according to\n",
    "                                        #the ASDM _binary_ flags\n",
    "with_pointing_correction =      False   #add (ASDM::Pointing::encoder -\n",
    "                                        #ASDM::Pointing::pointingDirection)\n",
    "                                        #to the value to be written in\n",
    "                                        #MS::Pointing::direction\n",
    "convert_ephem2geo   =       True        #if True, convert any attached\n",
    "                                        #ephemerides to the GEO reference\n",
    "                                        #frame (time-spacing not changed)\n",
    "```\n",
    "\n",
    "If *scans* is set, then **importasdm** processes only the scans specified in the option's value. This value is a semicolon separated list of scan specifications. A scan specification consists of an exec block index followed by the character ':' followed by a comma separated list of scan indexes or scan index ranges. A scan index is relative to the exec block it belongs to. Scan indexes are 1-based while exec blocks are 0-based. The expressions\n",
    "\n",
    "```\n",
    " \"0:1\"\n",
    " \"2:2~6\"\n",
    " \"0:1,1:2~6,8;2:,3:24~30\"\n",
    " \"1,2\"\n",
    " \"3:\"\n",
    "```\n",
    "\n",
    "are all valid values for the [selection](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset). The \\\"3:\\\" selector will be interpreted as 'all the scans of the exec block 3'. A scan index or a scan index range not preceded by an exec block index will be interpreted as 'all the scans with such indexes in all the exec blocks'. By default all the scans are considered.\n",
    "\n",
    "When *process_flags=True* the task will create online flags based on the Flag.xml, Antenna.xml and SpectralWindow.xml files and copy them to the *FLAG_CMD* sub-table of the MS. The flags will NOT be applied unless the parameter *applyflags* is set to *True*. Optionally, the flags can also be saved to an external ASCII file if savecmds is set to *True*. The flags can later be applied to the MS using task **flagdata** in *list* mode.\n",
    "\n",
    "When *bdfflags=True* the task will apply online flags contained in the ASDM BDF data by calling the executable bdflags2MS which the user can also do from the OS prompt. This is recommended for ALMA data.\n",
    "\n",
    "If *singledish=True*, output data format is scantable (single-dish data format) instead of MS. In that case, you must specify name or id of the antenna that you want to obtain data. This can be done by using *antenna* parameter that is defined as a subparameter of *singledish*. For single-dish mode, only auto-correlation data are filled, i.e. *ocorr_mode* is forcibly set to '*ao*'.\n",
    "\n",
    "The option *createmms* prepares the output file for [parallel processing](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing) and creates a [multi-MS](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing/the-multi-ms).\n",
    "\n",
    " \n",
    "\n",
    "###### Specifics on importing Janksy VLA data with importasdm \n",
    "\n",
    "As of CASA 5.4, the task importevla is no longer available to import JVLA data, but a lot of its functionality is replaced by importasdm. However, several additional steps are required to duplicate the behaviour of importevla when using importasdm, involving a difference in default parameters and the fact that some of the on-the-go flagging cannot be performed by importasdm.\n",
    "\n",
    "To mimic the behaviour of importevla, change the following parameters in **importasdm** from their default settings:\n",
    "\n",
    "-   *ocorr_mode = \\'co\\'* to import cross-correlations only (discarding auto-correlations)*    *\n",
    "-   *with_pointing_correction = True* to add pointing corrections*    *\n",
    "-   *process_flags = True* (default) to read in the online flags, then *applyflags = True* to apply the online flags and/or *savecmd = True* to save flag commands to an ascii table.\n",
    "-   For ephemeris objects: convert_ephem2geo = False\n",
    "\n",
    "While online flags can thus be created by leaving the parameter *process_flags = True* by default, additional flagging steps need to be performed after **importasdm** to flag zero values and shadowing of antennas:\n",
    "\n",
    "-   **Shadow flags:** use task **flagdata**, with *mode = \\'shadow\\'* (and optionally *reason = \\'shadow\\'*). The parameters *tolerance* and *addantenna* can be specified in flagdata in the same way they were used in importevla. *    *\n",
    "-   **Zero clipping flags:** use task **flagdata**, with ***mode = \\'clip\\',*** *correlation = \\'ABS_ALL\\',* and *clipzeros = True* (and optionally *reason = \\'clip\\'*)*.* Note that the non-default case in importevla where *flagpol = False c*an be replicated by setting *correlation=\\\"ABS_RR, ABS_LL\\\".*\n",
    "\n",
    "Like **importasdm**, the task **flagdata** can also save the flagging commands to an ascii table by setting *savepars = True.* To NOT apply the flags (*applyflags=False* in importevla) add *action=\\'calculate\\'* to flagdata. You may also chose to add a reason using the cmdreason argument, e.g. *cmdreason=\\\"CLIP_ZERO_ALL\\\".*\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**WARNING***:* The task **flagdata** can only write out the flag commands for that invocation of flagdata. The default *overwrite=True* must be used to overwrite an existing file. In order to save the commands from all 3 possible flagging steps (importasdm, zero, and shadow) each step must be saved to a separate file, which must then be concatenated into a single file to be used to flag the data.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "###### Import of ASDM data with option *lazy=True* \n",
    "\n",
    "With *lazy=False,* **importasdm** will fill the visibilities into a newly created *DATA* column of the MS converting them from their binary format in the ASDM to the CASA Table format.\n",
    "\n",
    "If, however, *lazy* is set to *True*, the task will create the *DATA* column with an ALMA data-specific storage manager, the asdmstman, which enables CASA to directly read the binary data from the ASDM with on-the-fly conversion. No redundant copy of the raw data is created.\n",
    "\n",
    "This procedure has the advantage that it saves more than 60% disk space and at least in some cases makes the access to the *DATA* column ≥ 10% faster because the data I/O volume is decreased. For the same reason, it also accelerates the import itself by ca. a factor 2. The acceleration is particularly large in the **applycal** task and here particularly on standard SATA disks.\n",
    "\n",
    "E.g., if your ASDM has a size of 36 GB, the import with default parameters will turn this into an MS of 73 GB size (total disk space consumption = 36 GB + 73 GB = 109 GB). With *lazy=True*, the imported MS has a size of only 2 GB (total disk space consumption = 36 GB + 2 GB = 38 GB). I.e. your total disk space savings are ca. 65%. Even when you compare to the case where you delete the ASDM after normal import, the solution with lazy import and keeping the ASDM will save you ca. 48% disk space (in the example above 38 GB compared to 73 GB).\n",
    "\n",
    "The only caveats are the following:\n",
    "\n",
    "1.  You must not delete your ASDM. You can, however, move it but you have to update the reference stored in the MS. Symbolic links will work. See below on how to use the tool method **ms.asdmref()** to manipulate the ASDM reference.\n",
    "2.  The lazily imported *DATA* column is read-only. But in any normal data reduction, the *DATA* column (as opposed to *CORRECTED_DATA*) is treated as read-only anyway.\n",
    "\n",
    "The lazily imported MS is numerically identical with the traditionally imported MS and so are all results derived from the MSs.\n",
    "\n",
    "An important additional tool to manipulate lazily imported MSs is the new method **ms.asdmref()** in the **ms** tool. If the MS is imported from an ASDM with option *lazy=True*, the DATA column of the MS is virtual and directly reads the visibilities from the ASDM. A reference to the original ASDM is stored with the MS. If the ASDM needs to be moved to a different path, the reference to it in the MS needs to be updated. This can be achieved with **ms.asdmref()**.\n",
    "\n",
    "The method takes one argument: *abspath*. When called with *abspath* equal to an empty string (default), the method just reports the currently set ASDM path or an empty string if the ASDM path was not set, i.e. the MS was not lazily imported.\n",
    "\n",
    "If you want to move the referenced ASDM to a different path, you can set the new absolute path by providing it as the value of *abspath* to the method.\n",
    "\n",
    "```\n",
    " ms.open('uid___A12345_X678_X910.ms',False)\n",
    " ms.asdmref('/home/alma/myanalysis/uid___A12345_X678_X910')\n",
    " ms.close()\n",
    "```\n",
    "\n",
    "will set the new location of the referenced ASDM to /home/alma/myanalysis/uid\\_\\_\\_A12345_X678_X910. Contrary to what one would expect from the parameter name, you can also provide a *relative* path as *abspath*. This path will be interpreted as relative to the location of the MS.\n",
    "\n",
    "<div>\n",
    "\n",
    "<div>\n",
    "\n",
    "<div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Info**: the lazily imported MS itself can be moved without any restrictions independently from the referenced ASDM as long as the path to the ASDM remains accessible, even across file systems.\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "##### VLA: Filling data from archive format (importvla) \n",
    "\n",
    "VLA data in archive format (i.e., as downloaded from the historic VLA data archive) are read into CASA from disk using the **importvla** task. The inputs are:\n",
    "\n",
    "```\n",
    "#importvla :: import VLA archive file(s) to a MeasurementSet:\n",
    "\n",
    "archivefiles  =         ''   #Name of input VLA archive file(s)\n",
    "vis           =         ''   #Name of output visibility file\n",
    "bandname      =         ''   #VLA frequency band name:''=>obtain all bands in archive files\n",
    "frequencytol  =   150000.0   #Frequency shift to define a unique spectral window (Hz)\n",
    "project       =         ''   #Project name:  '' => all projects in file\n",
    "starttime     =         ''   #start time to search for data\n",
    "stoptime      =         ''   #end time to search for data\n",
    "applytsys     =       True   #apply nominal sensitivity scaling to data & weights\n",
    "autocorr      =      False   #import autocorrelations to ms, if set to True\n",
    "antnamescheme =      'new'   #'old' or 'new'; 'VA04' or '4' for ant 4\n",
    "keepblanks    =      False   #Fill scans with empty source names (e.g. tipping scans)?\n",
    "evlabands     =      False   #Use updated eVLA frequencies and bandwidths\n",
    "```\n",
    "\n",
    "The main parameters are *archivefiles* to specify the input VLA Archive format file names, and *vis* to specify the output MS name.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** The scaling of VLA data both before and after the June 2007 Modcomp-turnoff is fully supported, based on the value of *applytsys*.\n",
    "</div>\n",
    "\n",
    "Note that *archivefiles* takes a string or list of strings, as there are often multiple files for a project in the archive.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "archivefiles = ['AP314_A950519.xp1','AP314_A950519.xp2']\n",
    "   vis = 'NGC7538.ms'\n",
    "```\n",
    "\n",
    "The **importvla** task allows selection on the frequency band. Suppose that you have 1.3 cm line observations in K-band and you have copied the archive data files AP314_A95019.xp\\* to your working directory and started casa. Then,\n",
    "\n",
    "```\n",
    "  default('importvla')\n",
    "   archivefiles = ['AP314_A950519.xp1','AP314_A950519.xp2','AP314_A950519.xp3']\n",
    "   vis = 'ngc7538.ms'\n",
    "   bandname = 'K'\n",
    "   frequencytol = 10e6\n",
    "   importvla()\n",
    "```\n",
    "\n",
    "If the data is located in a different directory on disk, then use the full path name to specify each archive file, e.g.:\n",
    "\n",
    "```\n",
    "archivefiles=['/home/rohir2/jmcmulli/ALMATST1/Data/N7538/AP314_A950519.xp1',\n",
    "     '/home/rohir2/jmcmulli/ALMATST1/Data/N7538/AP314_A950519.xp2',\n",
    "     '/home/rohir2/jmcmulli/ALMATST1/Data/N7538/AP314_A950519.xp3']\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** **importvla** will import the on-line flags (from the VLA system) along with the data. Shadowed antennas will also be flagged. The flags will be put in the *MAIN* table and thus available to subsequent tasks and tools. If you wish to revert to unflagged data, use **flagmanager** to save the flags (if you wish), and then use **flagdata** with *mode='manual'* and *unflag=True* to toggle off the flags.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "The other parameters are:\n",
    "\n",
    "###### Parameter applytsys \n",
    "\n",
    "The *applytsys* parameter controls whether the nominal sensitivity scaling (based on the measured *TSYS*, with the weights scaled accordingly using the integration time) is applied to the visibility amplitudes or not. If *True*, then it will be scaled so as to be the same as AIPS **FILLM** (i.e. approximately in deciJanskys). Note that post-Modcomp data is in raw correlation coefficient and will be scaled using the *TSYS* values, while Modcomp-era data had this applied online. In all cases **importvla** will do the correct thing to data and weights based on an internal flag in the VLA Archive file, either scaling it or unscaling based on your choice for *applytsys*.\n",
    "\n",
    "If *applytsys=True* and you see strange behavior in data amplitudes, it may be due to erroneous *TSYS* values from the online system. You might want to then fill with *applytsys=False* and look at the correlation coefficients to see if the behavior is as expected.\n",
    "\n",
    "###### Parameter bandname\n",
    "\n",
    "The *bandname* indicates the VLA Frequency band(s) to load, using the traditional bandname codes. These are:\n",
    "\n",
    "-   '4' = 48-96 MHz\n",
    "-   'P' = 298-345 MHz\n",
    "-   'L' = 1.15-1.75 GHz\n",
    "-   'C' = 4.2-5.1 GHz\n",
    "-   'X' = 6.8-9.6 GHz\n",
    "-   'U' = 13.5-16.3 GHz\n",
    "-   'K' = 20.8-25.8 GHz\n",
    "-   'Q' = 38-51 GHz\n",
    "-   '' = all bands (default)\n",
    "\n",
    "Note that as the transition from the VLA to JVLA progressed, the actual frequency ranges covered by the bands expanded, and additional bands were added (namely 'S' from 2-4 GHz and 'A' from 26.4-40 GHz).\n",
    "\n",
    "###### Parameter frequencytol\n",
    "\n",
    "The *frequencytol* parameter specifies the frequency separation tolerated when assigning data to spectral windows. The default is *frequencytol=150000* (Hz). For Doppler tracked data, where the sky frequency changes with time, a *frequencytol* \\< 10000 Hz may produce too many unnecessary spectral windows.\n",
    "\n",
    "###### Parameter project\n",
    "\n",
    "You can specify a specific *project* name to import from archive files. The default '' will import data from all projects in file(s) archivefiles.\n",
    "\n",
    "For example for VLA Project AL519:\n",
    "\n",
    "```\n",
    "project = 'AL519'    #this will work\n",
    "project = 'al519'    #this will also work\n",
    "```\n",
    "\n",
    "while *project='AL0519'* will NOT work (even though that is what queries to the VLA Archive will print it as - sorry!).\n",
    "\n",
    "###### Parameters starttime and stoptime \n",
    "\n",
    "You can specify start and stop times for the data, e.g.:\n",
    "\n",
    "```\n",
    "starttime = '1970/1/31/00:00:00'\n",
    "stoptime = '2199/1/31/23:59:59'\n",
    "```\n",
    "\n",
    "Note that the blank defaults will load all data fitting other criteria.\n",
    "\n",
    "###### Parameter autocorr \n",
    "\n",
    "Note that autocorrelations are filled into the data set if *autocorr=True*. Generally for the VLA, autocorrelation data is not useful, and furthermore the imaging routine will try to image the autocorrelation data (it assumes it is single dish data) which will swamp any real signal. Thus, if you do fill the autocorrelations, you will have to flag them before imaging.\n",
    "\n",
    "###### Parameter antnamescheme \n",
    "\n",
    "The *antnamescheme* parameter controls whether **importvla** will try to use a naming scheme where JVLA antennas are prefixed with EA (e.g. 'EA16') and old VLA antennas have names prefixed with VA (e.g. 'VA11'). Our method to detect whether an antenna is JVLA is not yet perfected, and thus unless you require this feature, simply use *antnamescheme='old'*.\n",
    "\n",
    "###### Parameter evlabands \n",
    "\n",
    "The *evlabands=True* option is provided to allow users to access JVLA frequencies outside the standard VLA tunings (e.g. the extended C-band above 6 GHz).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT:** use of this option for standard VLA data will cause unexpected associations, such as X-band data below 8 GHz being extracted to C-band (as the JVLA C-band is 4--8 GHz). Use with care.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "##### Import ATCA and CARMA data \n",
    "\n",
    "There are several ways to import data from ATCA and CARMA into CASA. The data from these arrays has historically been processed in MIRIAD. For simple cases (single source and frequency) exporting from MIRIAD to UVFITS format and importing using **importuvfits** often works ok, although some fixes to the resulting MeasurementSet may be needed.\n",
    "\n",
    "The **importmiriad** task reads MIRIAD visibility data and can handle multiple frequencies and sources in the input. Since it does not apply any calibration, make sure to apply it beforehand in MIRIAD.\n",
    "\n",
    "The **importatca** task reads the ATCA archive format (RPFITS) directly, avoiding the need to go through MIRIAD to load the data. It can handle ATCA data from both the old and new (CABB) correlator.\n",
    "\n",
    " \n",
    "\n",
    "###### Import MIRIAD visibilities (importmiriad)\n",
    "\n",
    "The task **importmiriad** allows one to import visibilities in the MIRIAD data format to be converted to a MS. The task has mainly been tested on data from the ATCA and CARMA telescopes and the inputs are:\n",
    "\n",
    "```\n",
    "#importmiriad :: Convert a Miriad visibility file into a CASA MeasurementSet\n",
    "mirfile             =         ''        #Name of input Miriad visibility file\n",
    "vis                 =         ''        #Name of output MeasurementSet\n",
    "tsys                =      False        #Use the Tsys to set the visibility weights\n",
    "spw                 =      'all'        #Select spectral windows\n",
    "vel                 =         ''        #Select velocity reference (TOPO,LSRK,LSRD)\n",
    "linecal             =      False        #(CARMA) Apply line calibration\n",
    "wide                =      'all'        #(CARMA) Select wide window averages\n",
    "debug               =          0        #Display increasingly verbose debug messages\n",
    "```\n",
    "\n",
    "The *mirfile* parameter specifies a single MIRIAD visibility file which should have any calibration done in MIRIAD already applied to it.\n",
    "\n",
    "Set the *tsys* parameter to *True* to change the visibility weights from the MIRIAD default (usually the integration time) to the inverse of the noise variance using the recorded system temperature.\n",
    "\n",
    "The *spw* parameter can be used to select all or some of the simultaneous spectral windows from the input file. Use the default of 'all' for all the data or use e.g., *spw='0,2'* to select the first and third window.\n",
    "\n",
    "The *vel* parameter can be used to set the output velocity frame reference. For ATCA this defaults to '*TOPO*' and for CARMA it defaults to '*LSRK*'. Only change this if your data comes out with the incorrect velocity.\n",
    "\n",
    "The *linecal* parameter is only useful for CARMA data and can apply the line calibration if it is stored with the MIRIAD data.\n",
    "\n",
    "The *wide* parameter is only useful for CARMA data and can select which of the wide-band channels should be loaded.\n",
    "\n",
    " \n",
    "\n",
    "###### Import ATCA RPFITS data (importatca) \n",
    "\n",
    "The data from the ATCA is available from the archive in files in the RPFITS format. These files can be imported into CASA with the **importatca** task.\n",
    "\n",
    "```\n",
    "#importatca :: Import ATCA RPFITS file(s) to a MeasurementSet\n",
    "files               =['*.C1234']        #Name of input ATCA RPFits file(s)\n",
    "vis                 = 'c1234.ms'        #Name of output visibility file\n",
    "                                        #(MeasurementSet)\n",
    "options             =         ''        #Processing options: birdie, reweight,\n",
    "                                        #noxycorr, fastmosaic, hires, noac\n",
    "                                        #(comma separated list)\n",
    "spw                 =       [-1]        #Specify the spectral windows to use,\n",
    "                                        #default=all\n",
    "nscans              =     [0, 0]        #Number of scans to skip followed by\n",
    "                                        #number of scans to read\n",
    "lowfreq             =   '0.1GHz'        #Lowest reference frequency to select\n",
    "highfreq            =   '999GHz'        #Highest reference frequency to select\n",
    "fields              =       ['']        #List of field names to select\n",
    "edge                =          8        #Percentage of edge channels to flag.\n",
    "                                        #For combined zooms, this specifies\n",
    "                                        #the percentage for a single zoom\n",
    "                                        #window\n",
    "```\n",
    "\n",
    "The files parameter can take a string or a list of strings as input and also allows the use of wildcards as shown in the example above.\n",
    "\n",
    "For older ATCA continuum data (before the CABB correlator, April 2009) use *options='birdie,reweight'* to suppress internally generated RFI.\n",
    "\n",
    "The options parameter:\n",
    "\n",
    "-   *birdie* - (pre-CABB data only) Discard edge channels and channels affected by internal RFI.\n",
    "-   *reweight* - (pre-CABB data only) Suppress ringing of RFI spikes by reweighting of the lag spectrum\n",
    "-   *noxycorr* - do not apply the xy phase correction as derived from the switched noise calibration, by default this is applied during loading of the data.\n",
    "-   *fastmosaic* - use this option if you are loading mosaic data with many pointings and only one or two integrations per pointing. This option changes the tiling of the data to avoid excessive I/O.\n",
    "-   *hires* - use this option if you have data in time binning mode (as used for pulsars) but you want to make it look like data with very short integration time (no bins).\n",
    "-   *noac* - discard the auto-correlation data\n",
    "\n",
    "The *spw* parameter takes a list of integers and can be used to select one or more of the simultaneous frequencies. With CABB there can be up to 34 spectra. The order of the frequency bands in the RPFITS file is: the two continuum bands (0 and 1), followed by the zoom bands for the first frequency and then the zoom bands for the second frequency. Note that this *spw* parameter does not take a string with wildcards. Use *spw=-1* to get all the data.\n",
    "\n",
    "The *nscans* parameter can be used to select part of a file, e.g., to retrieve a few test scans for a quick look.\n",
    "\n",
    "The *lowfreq* and *highfreq* parameters select data based on the reference frequency.\n",
    "\n",
    "The *fields* parameter selects data based on the field/source name.\n",
    "\n",
    "The *edge* parameter specifies how many edge channels to discard as a percentage of the number of channels in each band. E.g., the default value of 8 will discard 8 channels from the top and bottom of a 2048 channel spectrum.\n",
    "\n",
    " \n",
    "\n",
    "###### UVFITS Import \n",
    "\n",
    " \n",
    "\n",
    "The UVFITS format is not exactly a standard, but is a popular archive and transport format nonetheless. CASA supports UVFITS files written by the AIPS FITTP task, and others.\n",
    "\n",
    "UVFITS is supported for both import and export.\n",
    "\n",
    "###### Import using importuvfits \n",
    "\n",
    "To import UVFITS format data into CASA, use the **importuvfits** task:\n",
    "\n",
    "```\n",
    "#In CASA: inp(importuvfits)\n",
    "fitsfile            =         ''  #Name of input UVFITS file\n",
    "vis                 =         ''  #Name of output visibility file (MS)\n",
    "antnamescheme       =      'old'  #For VLA only; 'new' or 'old'; 'VA04' or '04' for VLA ant 4\n",
    "```\n",
    "\n",
    "This is straightforward, since all it does is read in a UVFITS file and convert it as best it can into a MS.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "importuvfits(fitsfile='NGC5921.fits',vis='ngc5921.ms')\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**INFO: **Here is a hint for handling CARMA data loaded into CASA using importuvfits:\n",
    "\n",
    "tb.open(\"c0104I/ANTENNA\",nomodify=False)\n",
    "namelist=tb.getcol(\"NAME\").tolist()\n",
    "for i in range(len(namelist)):\n",
    " name = 'CA'+namelist[i]\n",
    " print ' Changing '+namelist[i]+' to '+name\n",
    " namelist[i]=name\n",
    " \n",
    "tb.putcol(\"NAME\",namelist)\n",
    "tb.close()\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "###### Import using importfitsidi \n",
    "\n",
    "Some **uvfits** data is written in the FITS-IDI standard. Those files can be imported into CASA with the **importfitsidi** task:\n",
    "\n",
    "```\n",
    "#importfitsidi :: Convert a FITS-IDI file to a CASA visibility data set\n",
    "fitsidifile         =       ['']       #Name(s) of input FITS-IDI file(s)\n",
    "vis                 =          ''       #Name of output visibility file (MS)\n",
    "constobsid          =      False        #If True, give constant obs ID==0 to\n",
    "                                        #the data from all input fitsidi\n",
    "                                        #files (False = separate obs id for\n",
    "                                        #each file)\n",
    "scanreindexgap_s    =        0.0        #min time gap (seconds) between\n",
    "                                        #integrations to start a new scan\n",
    "```\n",
    "\n",
    "The *constobs* parameter can be used to give all visibilities the same observation id of 0. *scanreindexgap_s* controls the gap that defines different scans.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "importfitsidi(fitsidifile='NGC1300.fits',vis='NGC1300.ms')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeasurementSet Export \n",
    "\n",
    "Convert a MeasurementSet to UVFITS\n",
    "\n",
    "##### Export using exportuvfits\n",
    "\n",
    "The **exportuvfits** task will take a MS and write it out in UVFITS format. The defaults are:\n",
    "\n",
    "```\n",
    "#exportuvfits :: Convert a CASA visibility data set to a UVFITS file:\n",
    "vis                 =         ''        #Name of input visibility file\n",
    "fitsfile            =         ''        #Name of output UV FITS file\n",
    "datacolumn          = 'corrected'       #Visibility file data column\n",
    "field               =         ''        #Select field using field id(s) or field name(s)\n",
    "spw                 =         ''        #Select spectral window/channels\n",
    "antenna             =         ''        #Select data based on antenna/baseline\n",
    "timerange           =         ''        #Select data based on time range\n",
    "avgchan             =          1        #Channel averaging width (value > 1 indicates averaging)\n",
    "writesyscal         =      False        #Write GC and TY tables, (Not yet available)\n",
    "multisource         =       True        #Write in multi-source format\n",
    "combinespw          =       True        #Export the spectral windows as IFs\n",
    "     padwithflags   =       True        #Fill in missing data with flags to fit IFs\n",
    "\n",
    "writestation        =       True        #Write station name instead of antenna name\n",
    "overwrite           =      False        #Overwrite output file if it exists?\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "exportuvfits(vis='ngc5921.split.ms',\n",
    "fitsfile='NGC5921.split.fits',\n",
    "multisource=False)\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "The MS selection parameters *field, spw, antenna*, and *timerange* follow the [standard selection syntax](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset).\n",
    "\n",
    "The *datacolumn* parameter chooses which data-containing column of the MS is to be written out to the UV FITS file. Choices are: '*data*', '*corrected*', and '*model*'.\n",
    "\n",
    "There are a number of special parameters that control what is written out. These are mostly here for compatibility with AIPS.\n",
    "\n",
    "The *writesyscal* parameter toggles whether GC and TY extension tables are written. These are important for VLBA data, and for JVLA data.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT:** The *writesyscal* option is not yet available.\n",
    "</div>\n",
    "\n",
    "The *multisource* parameter determines whether the UV FITS file is a multi-source file or a single-source file, if you have a single-source MS or choose only a single source. Note: the difference between a single-source and multi-source UVFITS file here is whether it has a source (SU) table and the source ID in the random parameters. Some programs (e.g. difmap) only accept single-source files. If you select more than one source in fields, then the *multisource* parameter will be overridden to be *True* regardless.\n",
    "\n",
    "The *combinespw* parameter allows, if some conditions are met, exporting of all spectral windows (SpW) as a set of \\\"IF\\\"s in a single \\\"FREQID\\\" setup instead of giving each SpW its own FREQID in the FITS file. In this context an IF (Intermediate Frequency) is a specialization of an SpW, where each IF in a UV FITS file must have the same number of channels and polarizations, each channel must have the same width, and each IF must be present (even if flagged) throughout the entire observation. If these conditions are not met the data must be exported using multiple FREQIDs, the UV FITS equivalent of a general SpW. This matters since many (sub)programs will work with multiple IFs, but not multiple FREQIDs. For example, a UV FITS file with multiple FREQIDs can be read by AIPS, but you may find that you have to separate the FREQIDs with SPLIT before you can do very much with them. Therefore *combinespw* should be *True* if possible. Typically MSes where each band was observed simultaneously can be exported with *combinespw=True*. MSes where the tuning changed with time, e.g. 10 minutes at 4.8 GHz followed by 15 minutes at 8.4 GHz, should be exported to multiple UV FITS files using *spw* to select one tuning (set of simultaneous SpWs) per file.\n",
    "\n",
    "The *writestation* parameter toggles the writing of the station name instead of antenna name.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visibility Data Selection \n",
    "\n",
    "How to select visibility data\n",
    "\n",
    "Once in MS form, subsets of the data can be operated on using the tasks and tools. In CASA, there are three common data selection parameters used in the various tasks: *field*, *spw*, and *selectdata*. In addition, the *selectdata* parameter, if set to *True*, will open up a number of other sub-parameters for selection. The selection operation is unified across all the tasks. The available *selectdata* parameters may not be the same in all tasks. But if present, the same parameters mean the same thing and behave in the same manner when used in any task.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "field = ''         #field names or index of calibrators ''==>all\n",
    "spw = ''           #spectral window:channels: ''==>all\n",
    "selectdata = False #Other data selection parameters\n",
    "```\n",
    "\n",
    "versus\n",
    "\n",
    "```\n",
    "field = ''         #field names or index of calibrators ''==>all\n",
    "spw = ''           #spectral window:channels: ''==>all\n",
    "selectdata = True  #Other data selection parameters\n",
    "timerange = ''     #time range: ''==>all\n",
    "uvrange = ''       #uv range''=all\n",
    "antenna = ''       #antenna/baselines: ''==>all\n",
    "scan = ''          #scan numbers\n",
    "msselect = ''      #Optional data selection (Specialized. but see help)\n",
    "```\n",
    "\n",
    "The following are the general syntax rules and descriptions of the individual selection parameters of particular interest for the tasks.\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**Info:** The full documentation of the MeasurementSet data selection syntax can be found on the [CASAcore documentation](https://casacore.github.io/casacore-notes/) page, document 263 \"[Measurement Selection Syntax](https://casacore.github.io/casacore-notes/263.html)\" (see also [CASA Memo 1](https://casa.nrao.edu/casadocs-devel/stable/memo-series/casa-memos/casa_memo3_msselection_bhatnagar.pdf)). Links to relevant subsections are provided in the subsections below.]{\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General selection syntax \n",
    "\n",
    "Most of the selections are effected through the use of selection strings. This sub-section describes the general rules used in constructing and parsing these strings. Note that some selections are done through the use of numbers or lists. There are also parameter-specific rules that are described under each parameter.\n",
    "\n",
    "All lists of basic selection specification-units are comma separated lists and can be of any length. White-spaces before and after the commas (e.g. *'3C286, 3C48, 3C84'*) are ignored, while white-space within sub-strings is treated as part of the sub-string (e.g.* **'3C286, VIRGO A, 3C84'*). In some cases, spaces need to be quoted, e.g. *\\\"'spw 1'\\\"* (note the double quote around the single quotes).\n",
    "\n",
    "All integers can be of any length (in terms of characters) composed of the characters 0--9. Floating point numbers can be in the standard format (*DIGIT.DIGIT*, *DIGIT.*, or *.DIGIT*) or in the mantissa-exponent format (e.g. *1.4e9*). Places where only integers make sense (e.g. IDs), if a floating point number is given, only the integer part is used (it is truncated).\n",
    "\n",
    "Range of numbers (integers or real numbers) can be given in the format *\\'N0\\~N1\\'*. For integer ranges, it is expanded into a list of integers starting from *N0* (inclusive) to *N1* (inclusive). For real numbers, it is used to select all values present for the appropriate parameter in the MeasurementSet between *N0* and *N1* (including the boundaries). Note that the `'~'` (tilde) character is used rather than the more obvious '*-*' in order to accommodate hyphens in strings and minus signs in numbers.\n",
    "\n",
    "Wherever appropriate, units can be specified. The units are used to convert the values given to the units used in the MeasurementSet. For ranges, the unit is specified only once (at the end) and applies to both the range boundaries.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### String Matching \n",
    "\n",
    "String matching can be done in three ways. Any component of a comma separated list that cannot be parsed as a number, a number range, or a physical quantity is treated as a regular expression or a literal string. If the string does not contain the characters *'\\*', '{', '}'** *or *'?'*, it is treated as a literal string and used for exact matching. If any of the above mentioned characters are part of the string, they are used as a regular expression. As a result, for most cases, the user does not need to supply any special delimiters for literal strings and/or regular expressions. For example:\n",
    "\n",
    "```\n",
    "field = '3'    #match field ID 3 and not select field named \"3C286\".\n",
    "\n",
    "field = '3*'   #used as a pattern and matched against field names. If\n",
    "               #names like \"3C84\", \"3C286\", \"3020+2207\" are found,\n",
    "               #all will match. Field ID 3 will not be selected\n",
    "               #(unless of course one of the above mentioned field\n",
    "               #names also correspond to field ID 3!).\n",
    "\n",
    "field = '30*'  #will match only with \"3020+2207\" in above set.\n",
    "```\n",
    "\n",
    "However if it is required that the string be matched exclusively as a regular expression, it can be supplied within a pair of *'/'* as delimiters (e.g. *'/.+BAND.+/'*). A string enclosed within double quotes (*'\\\"'*) is used exclusively for pattern matching (patterns are a simplified form of regular expressions - used in most UNIX commands for string matching). Patterns are internally converted to equivalent regular expressions before matching. See the Unix command \\\"info regex\\\", or visit [http://www.regular-expressions.info](http://www.regular-expressions.info), for details of regular expressions and patterns.\n",
    "\n",
    "Strings can include any character except the following:\n",
    "\n",
    "```\n",
    "',' ';' '\"' '/' NEWLINE\n",
    "```\n",
    "\n",
    "(since these are part of the selection syntax). Strings that do not contain any of the characters used to construct regular expressions or patterns are used for exact matches. Although it is highly discouraged to have name in the MS containing the above mentioned reserved characters, if one does choose to include the reserved characters as parts of names etc., those names can only be matched against quoted strings (since regular expression and patterns are a super-set of literal strings -- i.e., a literal string is also a valid regular expression).\n",
    "\n",
    "This leaves *'\\\"', '\\*', '{', '}'* or *'?'** *as the list of printable character that cannot be part of a name (i.e., a name containing this character can never be matched in a MSSelection expression). These will be treated as pattern-matching even inside double double quotes (*'\\\" \\\"'*). There is currently no escape mechanism (e.g. via a backslash).\n",
    "\n",
    "Some examples of strings, regular expressions, and patterns:\n",
    "\n",
    "-   The string *'LBAND'** *will be used as a literal string for exact match. It will match only the exact string *LBAND*.\n",
    "-   The wildcarded string *'\\*BAND\\*'* will be used as a string pattern for matching. This will match any string which has the sub-string *BAND* in it.\n",
    "-   The string *'\\\"\\*BAND\\*\\\"'* will also be used as a string pattern, matching any string which has the sub-string *BAND* in it.\n",
    "-   The string *'/.+BAND.+/'* will be used as a regular expression. This will also match any string which as the sub-string *BAND* in it. (the *.+* regex operator has the same meaning as the *\\*** *wildcard operator of patterns).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *field* Parameter \n",
    "\n",
    "The *field* parameter is a string that specifies which field names or ids will be processed in the task or tool. The field selection expression consists of comma separated list of field specifications inside the string.\n",
    "\n",
    "Field specifications can be literal field names, regular expressions or patterns (see above). Those fields for which the entry in the NAME column of the *FIELD* MS sub-table match the literal field name/regular expression/pattern are selected. If a field name/regular expression/pattern fails to match any field name, the given name/regular expression/pattern are matched against the field code. If still no field is selected, an exception is thrown.\n",
    "\n",
    "Field specifications can also be given by their integer *IDs*. *IDs* can be a single or a range of *IDs*. Field *ID* selection can also be done as a boolean expression. For a field specification of the form *'\\>ID'*, all field IDs greater than ID are selected. Similarly for *'\\<ID'* all field *IDs* less than the *ID* are selected.\n",
    "\n",
    "For example, if the MS has the following observations:\n",
    "\n",
    "```python\n",
    "MS summary:\n",
    "==========\n",
    "FIELDID SPWID NChan Pol NRows Source Name\n",
    "\n",
    "---------------------------------------------------------------\n",
    "0 0 127 RR 10260 0530+135\n",
    "1 0 127 RR 779139 05582+16320\n",
    "2 0 127 RR 296190 05309+13319\n",
    "3 0 127 RR 58266 0319+415\n",
    "4 0 127 RR 32994 1331+305\n",
    "5 1 1 RR,RL,LL,RR 23166 KTIP\n",
    "```\n",
    "\n",
    "one might select\n",
    "\n",
    "```\n",
    "field = '0~2,KTIP'  #FIELDID 0,1,2 and field name KTIP\n",
    "field = '0530+135' #field 0530+135\n",
    " field = '05*'          #fields 0530+135,05582+16320,05309+13319 \n",
    "```\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**Field Selection**](http://casacore.github.io/casacore-notes/263.html#x1-190004 \"Field Selection\") - Expression for selection data along frequency axis (CASAcore docs)\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *spw* Parameter\n",
    "\n",
    "The *spw* parameter is a string that indicates the specific spectral windows and the channels within them to be used in subsequent processing. Spectral window selection (*'SPWSEL'*) can be given as a spectral window integer *ID*, a list of integer *IDs*, a spectral window name specified as a literal string (for exact match) or a regular expression or pattern.\n",
    "\n",
    "The specification can be via frequency ranges or by indexes. A range of frequencies are used to select all spectral windows which contain channels within the given range. Frequencies can be specified with an optional unit --- the default unit being *Hz*. Other common choices for radio and mm/sub-mm data are *kHz, MHz**,* and *GHz*. You will get the entire spectral windows, not just the channels in the specified range. You will need to do channel selection (see below) to do that.\n",
    "\n",
    "The spw can also be selected via comparison for integer IDs. For example, *'\\>ID'** *will select all spectral windows with *ID* greater than the specified value, while *'\\<ID'** *will select those with *ID* lesser than the specified value.\n",
    "\n",
    "Spectral window selection using strings follows the standard rules: \n",
    "\n",
    "```\n",
    "spw = '1'                      #SPWID 1\n",
    " spw = '1,3,5'                #SPWID 1,3,5\n",
    " spw = '0~3'                  #SPWID 0,1,2,3\n",
    " spw = '0~3,5'               #SPWID 0,1,2,3 and 5\n",
    " spw = '<3,5'                 #SPWID 0,1,2,3 and 5\n",
    " spw = '*'                      #All spectral windows\n",
    " spw = '1412~1415MHz' #Spectral windows containing 1412-1415MHz. \n",
    "```\n",
    "\n",
    "In some cases, the spectral windows may allow specification by name. For example, \n",
    "\n",
    "```\n",
    "spw = '3mmUSB, 3mmLSB'      #choose by names (if available)might be meaningful for the dataset in question.\n",
    "```\n",
    "\n",
    "Note that the order in which multiple spws are given may be important for other parameters. For example, the *mode = 'channel'* in **clean** uses the first *spw* as the origin for the channelization of the resulting image cube.\n",
    "\n",
    " \n",
    "\n",
    "##### Channel selection in the *spw* parameter \n",
    "\n",
    "Channel selection can be included in the spw string in the form *'SPWSEL:CHANSEL'* where *CHANSEL* is the channel selector. In the end, the spectral selection within a given spectral window comes down to the selection of specific channels. We provide a number of shorthand selection options for this. These *CHANSEL* options include:\n",
    "\n",
    "-   Channel ranges: *\\'START\\~STOP\\'**  *\n",
    "-   Frequency ranges: \\'*FSTART\\~FSTOP\\' *\n",
    "-   Channel striding/stepping: *\\'START\\~STOP\\^STEP\\'* or *\\'FSTART\\~FSTOP\\^FSTEP\\'*\n",
    "\n",
    "The most common selection is via channel ranges *\\'START\\~STOP\\'* or frequency ranges *\\'FSTART\\~FSTOP\\'*:\n",
    "\n",
    "```\n",
    "spw = '0:13~53'        #spw 0, channels 13-53, inclusive\n",
    "spw = '0:1413~1414MHz' #spw 0, 1413-1414MHz section only\n",
    "```\n",
    "\n",
    "All ranges are inclusive, with the channel given by, or containing the frequency given by, *START* and *STOP* plus all channels between included in the selection. You can also select the spectral window via frequency ranges *\\'FSTART\\~FSTOP\\'*, as described above: \n",
    "\n",
    "```\n",
    "spw = '1413~1414MHz:1413~1414MHz' #channels falling within 1413~1414MHz\n",
    " spw = '*:1413~1414MHz'                      #does the same thing\n",
    "```\n",
    "\n",
    "You can also specify multiple spectral window or channel ranges, e.g. \n",
    "\n",
    "```\n",
    "spw = '2:16, 3:32~34' #spw 2, channel 16 plus spw 3 channels 32-34\n",
    "spw = '2:1~3;57~63'   #spw 2, channels 1-3 and 57-63\n",
    "spw = '1~3:10~20'     #spw 1-3, channels 10-20\n",
    "spw = '*:4~56'        #all spw, channels 4-56\n",
    "```\n",
    "\n",
    "Note the use of the wildcard in the last example.\n",
    "\n",
    "A step can be also be included using *\\'\\^STEP\\'** *as a postfix:\n",
    "\n",
    "```\n",
    "spw = '0:10~100^2'        #chans 10,12,14,...,100 of spw 0\n",
    "spw = ':^4'               #chans 0,4,8,... of all spw\n",
    "spw = ':100~150GHz^10GHz' #closest chans to 100,110,...,150GHz\n",
    "```\n",
    "\n",
    "A step in frequency will pick the channel in which that frequency falls, or the nearest channel.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**Frequency Selection**](http://casacore.github.io/casacore-notes/263.html#x1-230006 \"Frequency Selection\") - Expression for selection along the frequency axis (CASAcore docs)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *selectdata* Parameters\n",
    "\n",
    "The *selectdata* parameter, if set to True (default), will expand the inputs to include a number of sub-parameters, given below and in the individual task descriptions (if different). If *selectdata = False*, then the sub-parameters are treated as blank for selection by the task.\n",
    "\n",
    "The common *selectdata* expanded sub-parameters are:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *antenna* Parameter \n",
    "\n",
    "The *antenna* selection string is a semi-colon (*';'*) separated list of baseline specifications. A baseline specification is of the form:\n",
    "\n",
    "-   *'ANT1'** *--- Select all baselines including the antenna(s) specified by the selector *ANT1*.\n",
    "\n",
    "-   *'ANT1&'* --- Select only baselines between the antennas specified by the selector *ANT1*.\n",
    "\n",
    "-   *'ANT1&ANT2'* --- Select only the cross-correlation baselines between the antennas specified by selector *ANT1* and antennas specified by selector *ANT2*. Thus *'ANT1&'* is an abbreviation for *'ANT1&ANT1'*.\n",
    "\n",
    "-   *'ANT1&&ANT2'* --- Select only auto-correlation and cross-correlation baselines between antennas specified by the selectors *ANT1* and *ANT2*. Note that this is what the default *antenna=''** *gives you.\n",
    "\n",
    "-   *'ANT1&&&'* --- Select only autocorrelations specified by the selector *ANT1*.\n",
    "\n",
    "The selectors *ANT1* and *ANT2* are comma-separated lists of antenna integer-*IDs* or literal antenna names, patterns, or regular expressions. The *ANT* strings are parsed and converted to a list of antenna integer-*IDs* or *IDs* of antennas whose name match the given names/pattern/regular expression. Baselines corresponding to all combinations of the elements in lists on either side of ampersand are selected.\n",
    "\n",
    "Integer *IDs* can be specified as single values or a range of integers. When items of the list are parsed as literal strings or regular expressions or patterns. All antenna names that match the given string (exact match)/regular expression/pattern are selected.\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "ALERT: Just for antenna selection, a user supplied integer (or integer list) is converted to a string and matched against the antenna name. If that fails, the normal logic of using an integer as an integer and matching it with antenna index is done. Note that currently there is no method for specifying a pure index (e.g. a number that will not first be checked against the name).\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "The comma is used only as a separator for the list of antenna specifications. The list of baselines specifications is a semi-colon separated list, e.g.\n",
    "\n",
    "```\n",
    "antenna = '1~3 & 4~6 ; 10&11'\n",
    "```\n",
    "\n",
    "will select baselines between antennas *1,2,3* and *4,5,6* (*'1&4', '1&5', ..., '3&6'*) plus baseline *'10&11'*.\n",
    "\n",
    "The wildcard operator (*'\\*'*) will be the most often used pattern. To make it easy to use, the wildcard (and only this operator) can be used without enclosing it in quotes. For example, the selection\n",
    "\n",
    "```\n",
    "antenna = 'VA*'\n",
    "```\n",
    "\n",
    "will match all antenna names which have *'VA'** *as the first 2 characters in the name (irrespective of what follows after these characters).\n",
    "\n",
    "There is also a negation operator *\"**!**\"* that can be used to de-select antennas or baselines.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "```\n",
    "antenna=''           #shows blank autocorr pages\n",
    "antenna='*&*'        #does not show the autocorrs\n",
    "antenna='*&&*'       #show both auto and cross-cor (default)\n",
    "antenna='*&&&'       #shows only autocorrs\n",
    " \n",
    "antenna='5&*'        #shows non-auto baselines with AN 5\n",
    "\n",
    "antenna='5,6&&&'     #AN 5 and 6 autocor\n",
    "antenna='5&&&;6&*'   #AN 5 autocor plus cross-cors to AN 6\n",
    "antenna='5,6,7&'     #all baselines in common between antennas 5, 6, and 7\n",
    "antenna='!5'         #baselines not involving AN 5\n",
    "```\n",
    "\n",
    "Antenna numbers as names: Needless to say, naming antennas such that the names can also be parsed as a valid token of the syntax is a bad idea. Nevertheless, antenna names that contain any of the reserved characters and/or can be parsed as integers or integer ranges can still be used by enclosing the antenna names in double quotes (*\\' \\\"ANT\\\" \\'*). E.g. the string\n",
    "\n",
    "```\n",
    "antenna = '10~15,21,VA22'\n",
    "```\n",
    "\n",
    "will expand into an antenna *ID* list *10,11,12,13,14,15,21,22* (assuming the index of the antenna named *'VA22'* is *22*). If, however, the antenna with *ID* index *50* is named *'21'*, then the string\n",
    "\n",
    "```\n",
    "antenna = '10~15,21,VA22'\n",
    "```\n",
    "\n",
    "will expand into an antenna *ID* list of *10,11,12,13,14,15,50,22*. *Keep in mind that numbers are FIRST matched against names, and only against indices if that matching fails.* There is currently no way to force a selection to use the index, and if there an antenna with that name it will select that.\n",
    "\n",
    "Read elsewhere (e.g. info regex under Unix) for details of regular expression and patterns.\n",
    "\n",
    "#####  Antenna stations \n",
    "\n",
    "Instead of antenna names, the antenna station names are also accepted by the selection syntax., e.g. *'N15'* for the JVLA.\n",
    "\n",
    " \n",
    "\n",
    "##### ANT\\@STATION selection syntax \n",
    "\n",
    "Sometimes, data from multiple array configurations are stored in a single MS. But some antennas may have been moved during reconfiguration and the* **'ANT\\@STATION'* syntax can distinguish between them. '*ANT*' is the antenna name or index and '*STATION*' is the antenna station name, e.g., *'EA12\\@W03'* selects antenna *EA012* but only at times when it is positioned on station *W03*. Wildcards are accepted, e.g. *'EA12@\\*'* selects all visibilities from antenna *EA12*, and *'\\*\\@W03'* would select all antennas that are located on station '*W03*' during any observations included in the MS.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**[Antenna/Baseline Selection](http://casacore.github.io/casacore-notes/263.html#x1-100003 \"Antenna/Baseline Selection\") **- Expression for selection along baseline/antenna aixs (CASAcore docs)]{\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *scan* Parameter  \n",
    "\n",
    "The *scan* parameter selects the scan *ID* numbers of the data. There is currently no naming convention for scans. The scan *ID* is filled into the MS depending on how the data was obtained, so use this with care.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```\n",
    "scan = '3'          #scan number 3.\n",
    "scan = '1~8'      #scan numbers 1 through 8, inclusive\n",
    "scan = '1,2,4,6'  #scans 1,2,4,6\n",
    "scan = '<9'        #scans <9 (1-8)NOTE: ALMA and VLA/JVLA number scans starting with 1 and not 0. You can see what the numbering is in your MS using the **listobs** task with *verbose=True.*\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**Scan/Sub-array Selection**](http://casacore.github.io/casacore-notes/263.html#x1-350009 \"Scan/Sub-array Selection\") - Expression for selection based on scan or sub-array indices (CASAcore docs)\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *timerange* Parameter \n",
    "\n",
    " The time strings in the following (*T0*, *T1* and *dT*) can be specified as *YYYY/MM/DD/HH:MM:SS.FF*. The time fields (i.e., *YYYY*, *MM*, *DD*, *HH*, *MM*, *SS* and *FF*), starting from left to right, may be omitted and they will be replaced by context sensitive defaults as explained below.\n",
    "\n",
    "Some examples:\n",
    "\n",
    " \n",
    "\n",
    "*timerange=\\'T0\\~T1\\'*: Select all time stamps from *T0* to *T1*. For example:\n",
    "\n",
    "```\n",
    "timerange = '2007/10/09/00:40:00 ~ 2007/10/09/03:30:00'\n",
    "```\n",
    "\n",
    "Note that fields missing in *T0* are replaced by the fields in the time stamp of the first valid row in the MS. For example,\n",
    "\n",
    "```\n",
    "timerange = '09/00:40:00 ~ 09/03:30:00'\n",
    "```\n",
    "\n",
    "where the* **YY/MM/* part of the selection has been defaulted to the start of the MS.\n",
    "\n",
    "Fields missing in *T1*, such as the date part of the string, are replaced by the corresponding fields of *T0* (after its defaults are set). For example:\n",
    "\n",
    "```\n",
    "timerange = '2007/10/09/22:40:00 ~ 03:30:00'\n",
    "```\n",
    "\n",
    "does the same thing as above.\n",
    "\n",
    " \n",
    "\n",
    "*timerange=\\'T0\\'*:  Select all time stamps that are within an integration time of *T0*. For example:\n",
    "\n",
    "```\n",
    "timerange = '2007/10/09/23:41:00'\n",
    "```\n",
    "\n",
    "Integration time is determined from the first valid row (more rigorously, an average integration time should be computed). Default settings for the missing fields of *T0* are as in the first example.\n",
    "\n",
    " \n",
    "\n",
    "*timerange=\\'T0+dT\\'*: Select all time stamps starting from T0 and ending with time stamp *T0+dT*. For example:\n",
    "\n",
    "```\n",
    "timerange = '23:41:00+01:00:00'\n",
    "```\n",
    "\n",
    "picks an hour-long chunk of time.\n",
    "\n",
    "Defaults of *T0* are set as usual. Defaults for *dT* are set from the time corresponding to *MJD=0*. Thus, *dT* is a specification of length of time from the assumed nominal \\\"start of time\\\".\n",
    "\n",
    " \n",
    "\n",
    "*timerange=\\'\\>T0\\'*: Select all times greater than *T0*. For example:\n",
    "\n",
    "```\n",
    "timerange = '>2007/10/09/23:41:00'\n",
    "timerange = '>23:41:00'                   #Same thing without day specification\n",
    "```\n",
    "\n",
    "Default settings for *T0* are as above.\n",
    "\n",
    "timerange=\\'\\<T1\\': Select all times less than *T1*. For example:\n",
    "\n",
    "```\n",
    "timerange = '<2007/10/09/23:41:00'\n",
    "```\n",
    "\n",
    "Default settings for *T1* are as above.\n",
    "\n",
    " \n",
    "\n",
    "An ultra-conservative selection might be:\n",
    "\n",
    "```\n",
    "timerange = '1960/01/01/00:00:00~2020/12/31/23:59:59'\n",
    "```\n",
    "\n",
    "which would choose all possible data!\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**[**Time Selection**](http://casacore.github.io/casacore-notes/263.html#x1-80002) - Expression for selection data along time axisTime Selection (CASAcore docs) **\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The uvrange Parameter \n",
    "\n",
    " Rows in the MS can also be selected based on the uv-distance or physical baseline length that the visibilities in each row correspond to. This *uvrange* can be specified in various formats.\n",
    "\n",
    "[The basic building block of uv-distance specification is a valid number with optional units in the format *N\\[UNIT\\]* (the unit in square brackets is optional). We refer to this basic building block as ]{*UVDIST*. The default unit is meter. Units of length (such as *'m'** *and *'km'*) select physical baseline distances (independent of wavelength). The other allowed units are in wavelengths (such as *'lambda', 'klambda'* and *'Mlambda'* and are true uv-plane radii\n",
    "\n",
    "$$UVDIST=\\sqrt{u^2+v^2}$$\n",
    "\n",
    " \n",
    "\n",
    "If only a single *UVDIST* is specified, all rows, the uv-distance of which exactly matches the given *UVDIST*, are selected.\n",
    "\n",
    "*[UVDIST*[ can be specified as a range in the format *\\'N0\\~N1\\[UNIT\\]\\'* ]{(where *N0* and *N1* are valid numbers). All rows corresponding to uv-distance between *N0* and *N1* (inclusive) when converted the specified units are selected.]{\n",
    "\n",
    "*UVDIST* can also be selected via comparison operators. When specified in the format *'\\>UVDIST'*, all visibilities with uv-distances greater than the given *UVDIST* are selected. Likewise, when specified in the format *'\\<UVDIST'*, all rows with uv-distances less than the given *UVDIST* are selected.\n",
    "\n",
    "Any number of above mentioned uv-distance specifications can be given as a comma-separated list.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```\n",
    "uvrange = '100~200km'                              #an annulus in physical baseline length\n",
    "uvrange = '24~35Mlambda, 40~45Mlambda' #two annuli in units of mega-wavelengths\n",
    "uvrange = '< 45klambda'                             #less than 45 kilolambda\n",
    "uvrange = '> 0lambda'                                #greater than zero length (no auto-corrs)\n",
    "uvrange = '100km'                                      #baselines of length 100km\n",
    " uvrange = '100klambda'                              #uv-radius 100 kilolambda\n",
    "\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[**UV-distance Selection**](http://casacore.github.io/casacore-notes/263.html#x1-210005 \"UV-distance Selection\") - Expression for selection based on uv-distance (CASAcore docs)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  The *correlation* Parameter \n",
    "\n",
    "The *correlation* parameter will select between different correlation products. They can be either the correlation *ID* or values such as *'XX', 'YY', 'XY', 'YX', 'RR', 'LL', 'RL', 'LR'*.\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[[**Polarization Selection**](http://casacore.github.io/casacore-notes/263.html#x1-310007 \"Polarization Selection\") - Expression for selection along the polarization axis (CASAcore docs) ]{\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  The *intent* Parameter \n",
    "\n",
    "*intent* is the scan intent that was specified when the observations were set up. They typically describe what was intended with a specific scan, i.e. a flux or phase calibration, a bandpass, a pointing, an observation of your target, or something else or a combination. The format for the scan intents of your observations are listed in the logger when you run listobs. Minimum matching with wildcards will work, like *'\\*BANDPASS\\*'*. This is especially useful when multiple intents are attached to scans.\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "[[**'Scan Intent' based selection**](http://casacore.github.io/casacore-notes/263.html#x1-320008 \"'Scan Intent' based Selection\") - Selection by intent (CASAcore docs)]{\n",
    "</div>\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *observation* Parameter \n",
    "\n",
    "The *observation* parameter can select between different observation *IDs*. They will be assigned to parts of a combined data set during a run of concat. Each input MS will receive its own observation id in the process.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *feed* Parameter \n",
    "\n",
    "The *feed* parameter can select between different feeds, e.g. for different feeds in a single dish multibeam array.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The *msselect* Parameter \n",
    "\n",
    "More complicated selections within the MS structure are possible using the Table Query Language (TaQL). This is accessed through the *msselect* parameter.\n",
    "\n",
    "[Note that the TaQL syntax does not follow the rules given in above for our other selection strings. TaQL is explained in more detail in CASAcore [NOTE 199 --- [Table Query Language](https://casacore.github.io/casacore-notes/199.html)]{[. The specific columns of the MS are given in the most recent [MS specification document](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/measurement-set).]{]{\n",
    "\n",
    "Most selection can be carried out using the other selection parameters. However, these are merely shortcuts to the underlying TaQL selection. For example, field and spectral window selection can be done using msselect rather than through field or spw:\n",
    "\n",
    "```\n",
    "msselect='FIELD_ID == 0'                  #Field id 0 only\n",
    "msselect='FIELD_ID <= 1'                  #Field id 0 and 1\n",
    "msselect='FIELD_ID IN [1,2]'              #Field id 1 and 2\n",
    "msselect='FIELD_ID==0 && DATA_DESC_ID==3' #Field id 0 in spw id 3 only\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "ALERT: The *msselect* \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Examination/Editing \n",
    "\n",
    "Plotting and flagging visibility data in CASA\n",
    "\n",
    "This chapter discusses how to plot and flag visibility and calibration data in CASA.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visibility Information \n",
    "\n",
    "Summary of tasks for handling MeasurementSet data and metadata\n",
    "\n",
    "There are tasks provided for basic listing and manipulation of MeasurementSet data and metadata. These includ the following tasks, which are described in more detail in the subsequent pages.\n",
    "\n",
    "-   **listsdm** --- summarize the contents of an SDM\n",
    "-   **listobs** --- summarize the contents of a MS \n",
    "-   **listpartition** --- list the partition structure of a Multi-MS\n",
    "-   **vishead** --- list and change the metadata contents of a MS\n",
    "-   **visstat** --- statistics on data in a MS \n",
    "-   **plotants** --- plotting antenna locations\n",
    "-   **plotms** --- plotting uv-coverages\n",
    "-   **plotweather** --- VLA weather statistics, calculation of opacities\n",
    "-   **browsetable** --- examining an MS\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeasurementSet Summary \n",
    "\n",
    "Summarizing MS or MMS data\n",
    "\n",
    "The MeasurementSet is the way CASA stores visibility data (the [MS definition](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/measurement-set) can be found in the [Reference Material](https://casa.nrao.edu/casadocs-devel/stable/memo-series/reference-material) section).  This page describes theree tasks to gain access to information stored in the MS: **listobs** displays observational details such as spatial (field), spectral (spectral window), temporal (scans), and polarization setup of an MS; **listpartition** provides information on how a MS was subdivided by the **partition** task (used for parallelized processing); **listvis** prints out the visibility values themselves. \n",
    "\n",
    " \n",
    "\n",
    "##### Summarizing your MS (**listobs**)\n",
    "\n",
    "An observational summary of the MS contents can be displayed with the **listobs** task. The inputs are:\n",
    "\n",
    "```\n",
    "vis                 = 'day2_TDEM0003_10s_norx' #Name of input visibility file (MS)\n",
    "selectdata          =       True        #Data selection parameters\n",
    "     field          =         ''        #Field names or field index\n",
    "                                        #numbers: '' ==>all, field='0~2,3C286'\n",
    "     spw            =         ''        #spectral-window/frequency/channel\n",
    "     antenna        =         ''        #antenna/baselines: ''==>all, antenna ='3,VA04'\n",
    "     timerange      =         ''        #time range: ''==>all,timerange='09:14:0~09:54:0'\n",
    "     correlation    =         ''        #Select data based on correlation\n",
    "     scan           =         ''        #scan numbers: ''==>all\n",
    "     intent         =         ''        #Select data based on observation intent: ''==>all\n",
    "     feed           =         ''        #multi-feed numbers: Not yet implemented\n",
    "     array          =         ''        #(sub)array numbers: ''==>all\n",
    "     uvrange        =         ''        #uv range: ''==>all; uvrange\n",
    "                                        #='0~100klambda', default units=meters\n",
    "     observation    =         ''        #Select data based on observation ID: ''==>all\n",
    "\n",
    "verbose             =       True        \n",
    "listfile            =         ''        #Name of disk file to write output: ''==>to terminal\n",
    "listunfl            =      False        #List unflagged row counts?\n",
    "                                        #If true, it can have significant negative performance\n",
    "                                        #impact\n",
    "```\n",
    "\n",
    "The summary (of the selected data) will be written to the logger, to the casapy-YYYYMMDD-HHMMSS.log file, and optionally to a file specified in the *listfile* parameter. For example,\n",
    "\n",
    "```\n",
    "listobs('n5921.ms')\n",
    "```\n",
    "\n",
    "results in a logger message like the following (also the format if a \\'listfile\\' text file is requested):\n",
    "\n",
    "```python\n",
    "listobs(vis=\"day2_TDEM0003_10s_norx\",selectdata=True,spw=\"\",field=\"\",\n",
    "        antenna=\"\",uvrange=\"\",timerange=\"\",correlation=\"\",scan=\"\",\n",
    "        intent=\"\",feed=\"\",array=\"\",observation=\"\",verbose=True,\n",
    "        listfile=\"\",listunfl=False)\n",
    "================================================================================\n",
    "           MeasurementSet Name:  /Users/jott/casa/casatest/casa4.0/irc/day2_TDEM0003_10s_norx      MS Version 2\n",
    "================================================================================\n",
    "   Observer: Mark J. Mark Claussen     Project: T.B.D.  \n",
    "Observation: EVLA\n",
    "Data records: 290218       Total integration time = 10016 seconds\n",
    "   Observed from   26-Apr-2010/03:21:56.0   to   26-Apr-2010/06:08:52.0 (UTC)\n",
    "   \n",
    "   ObservationID = 0         ArrayID = 0\n",
    "  Date        Timerange (UTC)          Scan  FldId FieldName             nRows     SpwIds   Average Interval(s)    ScanIntent\n",
    "  26-Apr-2010/03:21:51.0 - 03:23:21.0     5      2 J0954+1743                2720  [0, 1]  [10, 10]\n",
    "              03:23:39.0 - 03:28:25.0     6      3 IRC+10216                 9918  [0, 1]  [10, 10]\n",
    "              03:28:38.0 - 03:29:54.0     7      2 J0954+1743                2700  [0, 1]  [10, 10]\n",
    "              03:30:08.0 - 03:34:53.5     8      3 IRC+10216                 9918  [0, 1]  [10, 10]\n",
    "...\n",
    "           (nRows = Total number of rows per scan)\n",
    "Fields: 4\n",
    "  ID   Code Name                RA               Decl           Epoch   SrcId      nRows\n",
    "  2    D    J0954+1743          09:54:56.823626 +17.43.31.22243 J2000   2          65326\n",
    "  3    NONE IRC+10216           09:47:57.382000 +13.16.40.65999 J2000   3         208242\n",
    "  5    F    J1229+0203          12:29:06.699729 +02.03.08.59820 J2000   5          10836\n",
    "  7    E    J1331+3030          13:31:08.287984 +30.30.32.95886 J2000   7           5814\n",
    "Spectral Windows:  (2 unique spectral windows and 1 unique polarization setups)\n",
    "  SpwID  Name      #Chans   Frame   Ch1(MHz)  ChanWid(kHz)  TotBW(kHz)  Corrs          \n",
    "  0      Subband:0     64   TOPO   36387.229       125.000      8000.0  RR  RL  LR  LL\n",
    "  1      Subband:0     64   TOPO   36304.542       125.000      8000.0  RR  RL  LR  LL\n",
    "Sources: 10\n",
    "  ID   Name                SpwId RestFreq(MHz)  SysVel(km/s)\n",
    "  0    J1008+0730          0     0.03639232     -0.026       \n",
    "  0    J1008+0730          1     0.03639232     -0.026       \n",
    "  2    J0954+1743          0     0.03639232     -0.026       \n",
    "  2    J0954+1743          1     0.03639232     -0.026       \n",
    "  3    IRC+10216           0     0.03639232     -0.026       \n",
    "  3    IRC+10216           1     0.03639232     -0.026       \n",
    "  5    J1229+0203          0     0.03639232     -0.026       \n",
    "  5    J1229+0203          1     0.03639232     -0.026       \n",
    "  7    J1331+3030          0     0.03639232     -0.026       \n",
    "  7    J1331+3030          1     0.03639232     -0.026       \n",
    "Antennas: 19:\n",
    "  ID   Name  Station   Diam.    Long.         Lat.                Offset from array center (m)                ITRF Geocentric coordinates (m)        \n",
    "                                                                     East         North     Elevation               x               y               z\n",
    "  0    ea01  W09       25.0 m   -107.37.25.2  +33.53.51.0       -521.9407     -332.7782       -1.1977 -1601710.017000 -5042006.928200  3554602.355600\n",
    "  1    ea02  E02       25.0 m   -107.37.04.4  +33.54.01.1          9.8247      -20.4292       -2.7808 -1601150.059500 -5042000.619800  3554860.729400\n",
    "  2    ea03  E09       25.0 m   -107.36.45.1  +33.53.53.6        506.0591     -251.8666       -3.5832 -1600715.948000 -5042273.187000  3554668.184500\n",
    "  3    ea04  W01       25.0 m   -107.37.05.9  +33.54.00.5        -27.3562      -41.3030       -2.7418 -1601189.030140 -5042000.493300  3554843.425700\n",
    "  4    ea05  W08       25.0 m   -107.37.21.6  +33.53.53.0       -432.1158     -272.1493       -1.5032 -1601614.091000 -5042001.655700  3554652.509300\n",
    "  5    ea07  N06       25.0 m   -107.37.06.9  +33.54.10.3        -54.0667      263.8720       -4.2292 -1601162.593200 -5041829.000000  3555095.890500\n",
    "  6    ea08  N01       25.0 m   -107.37.06.0  +33.54.01.8        -30.8810       -1.4664       -2.8597 -1601185.634945 -5041978.156586  3554876.424700\n",
    "  7    ea09  E06       25.0 m   -107.36.55.6  +33.53.57.7        236.9058     -126.3369       -2.4443 -1600951.588000 -5042125.911000  3554773.012300\n",
    "  8    ea12  E08       25.0 m   -107.36.48.9  +33.53.55.1        407.8394     -206.0057       -3.2252 -1600801.916000 -5042219.371000  3554706.449900\n",
    "  9    ea15  W06       25.0 m   -107.37.15.6  +33.53.56.4       -275.8288     -166.7451       -2.0590 -1601447.198000 -5041992.502500  3554739.687600\n",
    "  10   ea19  W04       25.0 m   -107.37.10.8  +33.53.59.1       -152.8599      -83.8054       -2.4614 -1601315.893000 -5041985.320170  3554808.304600\n",
    "  11   ea20  N05       25.0 m   -107.37.06.7  +33.54.08.0        -47.8454      192.6015       -3.8723 -1601168.786100 -5041869.054000  3555036.936000\n",
    "  12   ea21  E01       25.0 m   -107.37.05.7  +33.53.59.2        -23.8638      -81.1510       -2.5851 -1601192.467800 -5042022.856800  3554810.438800\n",
    "  13   ea22  N04       25.0 m   -107.37.06.5  +33.54.06.1        -42.5986      132.8623       -3.5431 -1601173.953700 -5041902.660400  3554987.536500\n",
    "  14   ea23  E07       25.0 m   -107.36.52.4  +33.53.56.5        318.0523     -164.1848       -2.6960 -1600880.570000 -5042170.388000  3554741.457400\n",
    "  15   ea24  W05       25.0 m   -107.37.13.0  +33.53.57.8       -210.0944     -122.3885       -2.2581 -1601377.008000 -5041988.665500  3554776.393400\n",
    "  16   ea25  N02       25.0 m   -107.37.06.2  +33.54.03.5        -35.6245       53.1806       -3.1345 -1601180.861480 -5041947.453400  3554921.628700\n",
    "  17   ea27  E03       25.0 m   -107.37.02.8  +33.54.00.5         50.6647      -39.4832       -2.7249 -1601114.365500 -5042023.153700  3554844.945600\n",
    "  18   ea28  N08       25.0 m   -107.37.07.5  +33.54.15.8        -68.9057      433.1889       -5.0602 -1601147.940400 -5041733.837000  3555235.956000\n",
    "```\n",
    "\n",
    "**listobs** shows information on the project itself like project code, observer and telescope, followed by the sequence of scans with start/stop times, integration times, and scan intents, a list of all fields with name and coordinates, available spectral windows and their shapes, a list of sources (field/spw combination), and finally the location of all antennas that are used in the observation. A row is an MS entry for a given time stamp and baseline (rows can be accessed e.g. via **browsetable**). \n",
    "\n",
    "*verbose=False* would not show the complete list, in particular no information on the scans. \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "##### MMS summary (**listpartition**)\n",
    "\n",
    "**listobs** can also be used for Multi MeasurementSets (MMSs). In addition, the task **listpartition** will provide additional information how the data is structured in preparation for parallelized processing (e.g. using the **partition** task). The inputs are:\n",
    "\n",
    " \n",
    "\n",
    "```\n",
    "#listpartition :: List the summary of a Multi-MS data set in the logger or in a file\n",
    "vis                 =         ''        #Name of Multi-MS or normal MS.\n",
    "createdict          =      False        #Create and return a dictionary with\n",
    "                                        #Sub-MS information\n",
    "listfile            =         ''        #Name of ASCII file to save output:\n",
    "                                        #''==>to terminal\n",
    "```\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "listpartition('n5921.mms')\n",
    "```\n",
    "\n",
    "results in the logger messages:\n",
    "\n",
    "```python\n",
    "This is a multi-MS with separation axis = scan,spw\n",
    "Sub-MS               Scan  Spw    Nchan  Nrows   Size  \n",
    "ngc5921.mms.0000.ms  2     [0]    [63]   1890    27M   \n",
    "                     4     [0]    [63]   756           \n",
    "                     5     [0]    [63]   1134          \n",
    "                     6     [0]    [63]   6804          \n",
    "ngc5921.mms.0001.ms  1     [0]    [63]   4509    28M   \n",
    "                     3     [0]    [63]   6048          \n",
    "                     7     [0]    [63]   1512       \n",
    "```\n",
    "\n",
    "The output can also be redirected to a [python dictionary](http://casa.nrao.edu/casadocs/stable/usingcasa/python-and-casa#figid-casapythondictionaries) through the *createdict* parameter. \n",
    "\n",
    " \n",
    "\n",
    "##### Listing MS data (**listvis**)\n",
    "\n",
    "The **listvis** prints a list of the visibility data in an MS to the terminal or a textfile. The inputs are:\n",
    "\n",
    "```\n",
    "#listvis :: List MeasurementSet visibilities.\n",
    "vis                 =         ''        #Name of input visibility file\n",
    "options             =       'ap'        #List options: ap only\n",
    "datacolumn          =     'data'        #Column to list: data, float_data, corrected, model,\n",
    "                                        #residual\n",
    "field               =         ''        #Field names or index to be listed: ''==>all\n",
    "spw                 =        '*'        #Spectral window:channels: '*'==>all, spw='1:5~57'\n",
    "selectdata          =      False        #Other data selection parameters\n",
    "observation         =         ''        #Select by observation ID(s)\n",
    "average             =         ''        #Averaging mode: ==>none (Not yet implemented)\n",
    "showflags           =      False        #Show flagged data (Not yet implemented)\n",
    "pagerows            =         50        #Rows per page\n",
    "listfile            =         ''        #Output file\n",
    "```\n",
    "\n",
    "For example,\n",
    "\n",
    "```python\n",
    "Units of columns are: Date/Time(YYMMDD/HH:MM:SS UT), UVDist(wavelength), Phase(deg), UVW(m)\n",
    "WEIGHT: 7\n",
    "FIELD: 2\n",
    "SPW: 0\n",
    "Date/Time:                           RR:                 RL:                 LR:                 LL:                                             \n",
    "2010/04/26/      Intrf UVDist  Chn    Amp     Phs  Wt F   Amp     Phs  Wt F   Amp     Phs  Wt F   Amp     Phs  Wt F         U         V         W\n",
    "------------|---------|------|----|--------------------|-------------------|-------------------|-------------------|---------|---------|---------|\n",
    "  03:21:56.0 ea01-ea02  72363    0: 0.005  -124.5   7   0.005    25.7   7   0.001   104.6   7   0.000    23.4   7     -501.93   -321.75    157.78\n",
    "  03:21:56.0 ea01-ea02  72363    1: 0.001    -4.7   7   0.001  -135.1   7   0.004   -14.6   7   0.001    19.9   7     -501.93   -321.75    157.78\n",
    "  03:21:56.0 ea01-ea02  72363    2: 0.002    17.8   7   0.002    34.3   7   0.005  -114.3   7   0.005  -149.7   7     -501.93   -321.75    157.78\n",
    "  03:21:56.0 ea01-ea02  72363    3: 0.004   -19.4   7   0.003   -79.2   7   0.002   -89.0   7   0.004    31.3   7     -501.93   -321.75    157.78\n",
    "  03:21:56.0 ea01-ea02  72363    4: 0.001   -16.8   7   0.004  -141.5   7   0.005   114.9   7   0.006   105.2   7     -501.93   -321.75    157.78\n",
    "  03:21:56.0 ea01-ea02  72363    5: 0.001   -29.8   7   0.009   -96.4   7   0.002  -125.0   7   0.002   -64.5   7     -501.93   -321.75    157.78\n",
    "...\n",
    "Type Q to quit, A to toggle long/short list, or RETURN to continue [continue]:\n",
    "```\n",
    "\n",
    "columns are:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    COLUMN NAME       DESCRIPTION\n",
    "    -----------       -----------\n",
    "    Date/Time     Time stamp of data sample (YYMMDD/HH:MM:SS UT)\n",
    "    Intrf                Interferometer baseline (antenna names)\n",
    "    UVDist            uv-distance (units of wavelength)\n",
    "    Fld                  Field ID (if more than 1)\n",
    "    SpW               Spectral Window ID (if more than 1)\n",
    "    Chn                Channel number (if more than 1)\n",
    "    (Correlated          Correlated polarizations (eg: RR, LL, XY)\n",
    "      polarization)     Sub-columns are: Amp, Phs, Wt, F\n",
    "    Amp               Visibility amplitude\n",
    "    Phs                 Visibility phase (deg)\n",
    "    Wt                  Weight of visibility measurement\n",
    "    F                     Flag: 'F' = flagged datum; ' ' = unflagged\n",
    "    UVW               UVW coordinates (meters)\n",
    "</div>\n",
    "\n",
    "Note that MS listings can be very large. Use selectdata=True and subselect the data to obtain the desired information as much as possible.  \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDM Summary \n",
    "\n",
    "About listsdm\n",
    "\n",
    "The task **listsdm** summarizes the content of archival data in the format that is used by ALMA and the VLA for visibility data transport and archiving (the [Science Data Model](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/the-science-data-model), known as ASDM for ALMA). The output in the casalog is very similar to that of **listobs**, which reads the metadata after conversion to a MeasurementSet (see next section). **listsdm** therefore does not require the SDM to be filled into an MS. The output of **listsdm** is also returned as a dictionary.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MS Metadata List/Change \n",
    "\n",
    "Using vishead\n",
    "\n",
    " \n",
    "\n",
    "The **vishead** task is provided to access keyword information in the MeasurementSet. The default inputs are:\n",
    "\n",
    "```\n",
    "#vishead :: List, get, and put metadata in a MeasurementSet\n",
    "vis = '' #Name of input visibility file\n",
    "mode = 'list' #options: list, summary, get, put\n",
    "listitems = [] #items to list ([] for all)\n",
    "```\n",
    "\n",
    "The *mode = 'summary'* option just gives the same output as **listobs**.\n",
    "\n",
    "For *mode = 'list'* the default options are: *'telescope', 'observer', 'project', 'field', 'freq_group_name', 'spw_name', 'schedule', 'schedule_type', 'release_date'.* To obtain other options, put *mode = 'list'* and *listitems = \\[\\]*; see [vishead task pages](https://casa.nrao.edu/casadocs-devel/stable/global-task-list/task_vishead) for a description of these additional options.\n",
    "\n",
    "```\n",
    "CASA <29>: vishead('ngc5921.demo.ms',mode='list',listitems=[])\n",
    "  Out[29]:\n",
    "{'cal_grp': (array([-1, -1, -1], dtype=int32), {}),\n",
    " 'field': (array(['1331+30500002_0', '1445+09900002_0', 'N5921_2'],\n",
    "      dtype='|S16'),\n",
    "           {}),\n",
    " 'fld_code': (array(['C', 'A', ''],\n",
    "      dtype='|S2'), {}),\n",
    " 'freq_group_name': (array(['none'],\n",
    "      dtype='|S5'), {}),\n",
    " 'log': ({'r1': False}, {}),\n",
    " 'observer': (array(['TEST'],\n",
    "      dtype='|S5'), {}),\n",
    " 'project': (array([''],\n",
    "      dtype='|S1'), {}),\n",
    " 'ptcs': ({'r1': array([[[-2.74392758]],\n",
    "\n",
    "       [[ 0.53248521]]]),\n",
    "           'r2': array([[[-2.42044692]],\n",
    "\n",
    "       [[ 0.17412604]]]),\n",
    "           'r3': array([[[-2.26020138]],\n",
    "\n",
    "       [[ 0.08843002]]])},\n",
    "          {'MEASINFO': {'Ref': 'J2000', 'type': 'direction'},\n",
    "           'QuantumUnits': array(['rad', 'rad'],\n",
    "      dtype='|S4')}),\n",
    " 'release_date': (array([  4.30444800e+09]),\n",
    "                  {'MEASINFO': {'Ref': 'TAI', 'type': 'epoch'},\n",
    "                   'QuantumUnits': array(['s'],\n",
    "      dtype='|S2')}),\n",
    " 'schedule': ({'r1': False}, {}),\n",
    " 'schedule_type': (array([''],\n",
    "      dtype='|S1'), {}),\n",
    " 'source_name': (array(['1331+30500002_0', '1445+09900002_0', 'N5921_2'],\n",
    "      dtype='|S16'),\n",
    "                 {}),\n",
    " 'spw_name': (array(['none'],\n",
    "      dtype='|S5'), {}),\n",
    " 'telescope': (array(['VLA'],\n",
    "      dtype='|S4'), {})}\n",
    "```\n",
    "\n",
    "You can use *mode='get'* to retrieve the values of specific keywords, and likewise *mode='put'* to change them. The inputs are:\n",
    "\n",
    "```\n",
    "mode           =      'get'    #options: list, summary, get, put\n",
    "hdkey          =       ''      #keyword to get/put\n",
    "hdindex        =       ''      #keyword index to get/put, counting from zero. ==>all\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```\n",
    "#vishead :: List, summary, get, and put metadata in a MeasurementSet\n",
    "mode           =      'put'    #options: list, summary, get, put\n",
    "hdkey          =         ''    #keyword to get/put\n",
    "hdindex        =         ''    #keyword index to get/put, counting from zero. ==>all\n",
    "hdvalue        =         ''    #value of hdkey\n",
    "```\n",
    "\n",
    "For example, a common operation is to change the Telescope name (e.g. if it is unrecognized), e.g.\n",
    "\n",
    "```\n",
    "CASA <36>: vishead('ngc5921.demo.ms',mode='get',hdkey='telescope')\n",
    "  Out[36]:\n",
    "  (array(['VLA'],\n",
    "      dtype='|S4'), {})\n",
    "\n",
    "CASA <37>: vishead('ngc5921.demo.ms',mode='put',hdkey='telescope',hdvalue='JVLA')\n",
    "\n",
    "CASA <38>: vishead('ngc5921.demo.ms',mode='get',hdkey='telescope')\n",
    "  Out[38]:\n",
    "  (array(['JVLA'],\n",
    "      dtype='|S5'), {})\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visibility Statistics \n",
    "\n",
    "Using visstat\n",
    "\n",
    "###### MS statistics (visstat) \n",
    "\n",
    "The **visstat** task is provided to obtain simple statistics for a MeasurementSet, useful in regression tests.\n",
    "\n",
    "The inputs are:\n",
    "\n",
    "```\n",
    "#visstat :: Displays statistical information from a MeasurementSet, or from a Multi-MS\n",
    "\n",
    "vis            =     ''            #Name of MeasurementSet or Multi-MS\n",
    "axis           =     'real'        #Which values to use\n",
    "     datacolumn     =     'data'        #Which data column to use (data, corrected, model, float_data)\n",
    "\n",
    "useflags       =      False        #Take flagging into account?\n",
    "spw            =         ''        #spectral-window/frequency/channel\n",
    "field          =        '1'        #Field names or field index numbers: ''==>all, field='0~2,3C286'\n",
    "selectdata     =       True        #More data selection parameters (antenna, timerange etc)\n",
    "     antenna        =         ''        #antenna/baselines: ''==>all, antenna = '3,VA04'\n",
    "     timerange      =         ''        #time range: ''==>all, timerange='09:14:0~09:54:0'\n",
    "     correlation    =       'RR'        #Select data based on correlation\n",
    "     scan           =         ''        #scan numbers: ''==>all\n",
    "     array          =         ''        #(sub)array numbers: ''==>all\n",
    "     observation    =         ''        #observation ID number(s): '' = all\n",
    "     uvrange        =         ''        #uv range: ''==>all; uvrange = '0~100klambda', default units=meters\n",
    "\n",
    "timeaverage    =      False        #Average data in time.\n",
    "intent         =         ''        #Select data by scan intent.\n",
    "reportingaxes  =     'ddid'        #Which reporting axis to use (ddid, field, integration)\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Running this task returns a record (Python dictionary) with the statistics, which can be captured in a Python variable. For example,\n",
    "\n",
    "```python\n",
    "CASA <54>: mystat=visstat(vis='data/regression/unittest/setjy/ngc5921.ms', axis='amp', datacolumn='data', useflags=False, spw='', field='', selectdata=True, correlation='RR', timeaverage=False, intent='', reportingaxes='ddid')\n",
    "\n",
    "CASA <55>: mystat\n",
    "Out[55]:\n",
    "{'DATA_DESC_ID=0': {'firstquartile': 0.023732144385576248,\n",
    "  'isMasked': False,\n",
    "  'isWeighted': False,\n",
    "  'max': 73.75,\n",
    "  'maxDatasetIndex': 12,\n",
    "  'maxIndex': 1204,\n",
    "  'mean': 4.511831488357214,\n",
    "  'medabsdevmed': 0.0432449858635664,\n",
    "  'median': 0.051963627338409424,\n",
    "  'min': 2.2130521756480448e-05,\n",
    "  'minDatasetIndex': 54,\n",
    "  'minIndex': 4346,\n",
    "  'npts': 1427139.0,\n",
    "  'rms': 16.42971891790897,\n",
    "  'stddev': 15.798076313999745,\n",
    "  'sum': 6439010.678462409,\n",
    "  'sumOfWeights': 1427139.0,\n",
    "  'sumsq': 385235713.187832,\n",
    "  'thirdquartile': 0.3004012107849121,\n",
    "  'variance': 249.57921522295976}}\n",
    "\n",
    "CASA <56>: mystat['DATA_DESC_ID=0']['stddev']\n",
    "Out[56]: 15.798076313999745\n",
    "```\n",
    "\n",
    "``` {.verbatim}\n",
    "The options for axis are:\n",
    "```\n",
    "\n",
    "```\n",
    "axis='amplitude' #or ('amp') axis='phase' axis='imag' (or 'imaginary') axis='real'\n",
    "```\n",
    "\n",
    "The phase of a complex number is in radians with range (−π, π).\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Antenna Positions \n",
    "\n",
    "Plotting antenna positions\n",
    "\n",
    "This task is a simple plotting interface to produce plots of the antenna positions (taken from the ANTENNA sub-table of the MS). The location of the antennas in the MS will be plotted with X-toward local east, Y-toward local north.\n",
    "\n",
    "The inputs to **plotants** are:\n",
    "\n",
    "```\n",
    " #plotants :: Plot the antenna distribution in the local reference frame:\n",
    "vis              =   ''       #Name of input visibility file (MS)\n",
    "figfile          =   ''       #Save the plotted figure to this file\n",
    "antindex         =   False    #Label antennas with name and antenna ID\n",
    "logpos           =   False    #Whether to plot logarithmic positions\n",
    "exclude          =   ''       #Antenna name/id selection to exclude from plot\n",
    "checkbaselines   =   False    #Whether to check baselines in the main table.\n",
    "title            =   ''       #Title for the plot.\n",
    "showgui          =   True     #Show plot on gui.\n",
    "\n",
    "```\n",
    "\n",
    "For most telescopes, the default X/Y plot is in meters.  For VLBA antenna plots, latitude vs. longitude (degrees) is plotted instead.\n",
    "\n",
    "Supported format extensions for the *figfile* include emf, eps, pdf, png, ps, raw, rgba, svg, and svgz, depending on which python modules are installed on your system. Formats currently available in a downloaded CASA package include all but emf (enhanced metafile).\n",
    "\n",
    "Each antenna position is labeled with the antenna name. VLBA antenna plots label the positions with \\\"name @ station\\\" format, e.g. \\\"2\\@FD\\\" for the Fort Davis, Texas, antenna. To add the antenna ID to the name, set *antindex=True* as shown in Figure 1.\n",
    "\n",
    "![0913b01badcfd68e003cece8d0ff8c658c936262](media/0913b01badcfd68e003cece8d0ff8c658c936262.png){.image-inline width=\"638\" height=\"480\"}\n",
    "\n",
    ">ALMA antenna positions with *antindex=True*.\n",
    "  \n",
    "\n",
    "By default, **plotants** plots the positions of all antennas in the ANTENNA subtable. However, the user has the option to exclude certain antennas with the *exclude* parameter. Its value is a string to select which antennas to exclude, using the same syntax as the antenna parameter in [MeasurementSet selection](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset). For example, *exclude=\\\"5\\~6\\\"* would exclude the PM antennas from the plot in Figure 1.\n",
    "\n",
    "To plot only those antennas which appear in the MAIN table (e.g. after a split, which retains the entire ANTENNA subtable in the dataset), set *checkbaselines=True*. This parameter would have automatically removed antenna 7 (DV10) from the plot in Figure 1, as it does not appear in the main table of this dataset.\n",
    "\n",
    "To plot logarithmic positions instead of X/Y positions, set *logpos=True* as shown in Figure 2:\n",
    "\n",
    "![5933a270bc2321a65052a7f5b39f6e0e8b0879d5](media/5933a270bc2321a65052a7f5b39f6e0e8b0879d5.png){.image-inline width=\"519\" height=\"463\"}\n",
    "\n",
    ">Antenna positions with *logpos=True*\n",
    "  \n",
    "\n",
    "The default title for the plot is \\\"Antenna Positions for \\\" the MS name (*vis* argument), as shown in all figures on this page. To set a custom title, set the *title* parameter to the desired string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The plotants GUI\n",
    "\n",
    "By default, the plotants GUI will be shown when the task is used.  If the GUI is not needed, as in scripting mode to produce a *figfile*, set *showgui=False*. When casa flags are set to avoid starting GUI tools or to run without the matplotlib \\'tkagg\\' backend (*\\--nogui, \\--pipeline,* or *\\--agg*), the plotants GUI will not be shown regardless of the value of the *showgui* parameter.\n",
    "\n",
    "The antennas will be plotted in a plotter window as shown below. Several tool buttons are available to manipulate and save the plot:\n",
    "\n",
    "-   The \\'Home\\' button (leftmost house icon) is used to return to the first, default view after panning or zooming.\n",
    "-   The \\'Forward\\' and \\'Back\\' buttons (left- and right-arrow icons) are used to navigate between previous plot views after pan/zoom actions.\n",
    "-   The \\'Pan/Zoom\\' button (crossed blue arrows, fourth icon) is used to drag the plot to a new position by pressing and holding the mouse button.\n",
    "-   The \\'Zoom-to-rectangle\\' button (magnifier icon, fifth from left) is used to mark a rectangular region with the mouse in order to zoom in on the plot.\n",
    "-   The \\'Subplot-configuration\\' button (sixth icon) can be used to stretch or compress the left, right, top, or bottom of the plot, as well as the ability to reset the plot to the original shape after manipulation before exiting the configuration dialog.\n",
    "-   The \\'Save\\' button (rightmost icon) is used to export the plot. A file save dialog is launched to select a location, name, and format (default png) for the file.\n",
    "\n",
    "![f05dc15d6cf9628b4e2f819d7e5530c7f27d3bd2](media/f05dc15d6cf9628b4e2f819d7e5530c7f27d3bd2.png){.image-inline}\n",
    "\n",
    ">**plotants** GUI for a VLA dataset with *antindex=True*. Note the tool buttons at the bottom of the window.\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VLA Weather Information \n",
    "\n",
    "About plotweather\n",
    "\n",
    "Weather data for the VLA can be displayed with the task **plotweather**. This task will also calculate opacities based on the weather data taken at the time of the observation, or from a seasonal model. \n",
    "\n",
    "Inputs are: \n",
    "\n",
    "```\n",
    "#plotweather :: Plot elements of the weather table; estimate opacity.\n",
    "vis = ''              #MS name\n",
    "seasonal_weight = 0.5 #weight of the seasonal model\n",
    "doPlot = True         #set this to True to create a plot\n",
    "plotName = ''         #(Optional) the name of the plot file\n",
    "```\n",
    "\n",
    "The amount of seasonal data can be set by the parameter *seasonal_weight*, where a value of 1 will only use the seasonal model and a value of 0 will only use the actual weather data to calculate opacities. \n",
    "\n",
    "Typical output of **plotweather** looks like below:\n",
    "\n",
    "![a36812b09ef65bbf1d85a367204f1070b66a1a2b](media/a36812b09ef65bbf1d85a367204f1070b66a1a2b.png){.image-inline}\n",
    "\n",
    ">Typical output from plotweather. The panel at the top displays the following properties as a fiunction of time across the observation: elevation of the sun, wind speed and direction, temperature and dew point, and precipitable water vapor (pwv). The bottom panel shows the calculated zenith opacity as a function of  frequency. The opacities calculated from the actual weather data, from a seasonal model and the specified mix of both are shown in the PWV and Tau plots. \n",
    "  \n",
    "\n",
    "The methods used in this task are described [EVLA Memo 143](http://library.nrao.edu/public/memos/evla/EVLAM_143.pdf), [VLA Test Memo 232](http://library.nrao.edu/public/memos/vla/test/VLAT_232.pdf), and [VLA Scientific Memo 176](http://library.nrao.edu/public/memos/vla/sci/VLAS_176.pdf).  The wind direction aligns with the meteorological definition, i.e., north is up (0deg) with the angle increasing clockwise E, S, W (e.g., a vector pointing to the right indicates westerly winds with an angle of 270deg).   \n",
    "\n",
    " \n",
    "\n",
    "Allowed output plot formats are those supported by matplotlib, currently emf, eps, pdf, png, ps, raw, rgba, svg, and svgz.\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Alert: **plotweather** accesses the WEATHER table in the MS. The task may therefore also work for non-VLA data as long as such a table is present. The plots and calculations, however, have been tailored for the VLA, so non-VLA data may or may not be interpreted correctly.   \n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Browse MS/Calibration Tables \n",
    "\n",
    "Browse a table (MeasurementSet, calibration table, image)\n",
    "\n",
    "The browsetable task is available for viewing data directly.  It handles all CASA tables, including MeasurementSets, calibration tables, and images. This task brings up a CASA Qt table browser, which can be launched from outside CASA using **casabrowser**.\n",
    "\n",
    "browsetable is not required for normal data reduction but is useful for troubleshooting or for identifying table column names and formats. If you want to edit a long column or extract data for manipulation outside CASA (e.g. the uv data), see flagdata and the table tools in the [Global Tool List](https://casa.nrao.edu/casadocs-devel/stable/global-tool-list).  The MeasurementSet columns and subtables are described [here](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/measurement-set).\n",
    "\n",
    "The default inputs for the CASA browsetable task are:\n",
    "\n",
    "```\n",
    " #In CASA\n",
    "#browsetable :: Browse a table (MS, calibration table, image)\n",
    "tablename = ''             #Name of input table\n",
    "```\n",
    "\n",
    "Once the tablename is specified, available parameters include:\n",
    "\n",
    "```\n",
    "#browsetable :: Browse a table (MS, calibration table, image)\n",
    "tablename      =   'ngc5921_ut.ms' #Name of input table\n",
    "mightedit      =      False        #Warning: the GUI seems to ignore whether the table\n",
    "                                   #tool is opened read-only - just be careful, esp.\n",
    "                                   #if filtering.\n",
    "sortlist       =         ''        #Columns to sort by (ascending)\n",
    "taql           =         ''        #TaQL query string for prefiltering the table.\n",
    "skipcols       =         ''        #Columns to omit\n",
    "\n",
    "```\n",
    "\n",
    "For more information about the Table Query Language (TaQL) string, see [this note](https://casa.nrao.edu/aips2_docs/notes/199/199.html).\n",
    "\n",
    "Example with *tablename* argument:\n",
    "\n",
    "```\n",
    "browsetable('ngc5921_ut.ms')\n",
    "```\n",
    "\n",
    "For an MS, as in this example, the table browser will display the MAIN table (Figure 1). To look at subtables, use the *table keywords* tab along the left side to bring up a panel with the subtables listed (Figure 2), then choose (double-click) a table name (Keyword) to display the subtable in a new tab (Figures 3 and 4). You can double-click on a cell in a table to view the contents (fourth figure below) then use the \\\"Close\\\" or \\\"Close All\\\" buttons at the bottom of the contents display to close one or all displayed values.\n",
    "\n",
    "> \n",
    ">\n",
    "> ------------------------------------------------------------------------\n",
    "> \n",
    ">\n",
    "> \n",
    "> [ ![d0c7a9d86a5f770b9aa1fa566b76946d3adb5a89](media/d0c7a9d86a5f770b9aa1fa566b76946d3adb5a89.jpg){.image-inline}]{\n",
    "> \n",
    ">\n",
    "> \n",
    ">>The browser displays the MAIN table within a frame. You can scroll through the data with the sliders at right and bottom, and step through the pages with the \\\"\\<\\<\\\" and \\\"\\>\\>\\\" buttons or using \\\"First\\\" and \\\"Last\\\" to quickly advance to the beginning or end.  To go to a specific page, input the page number in the text box then click \\\"Go\\\".  By default, 1000 rows of the table are loaded at a time, but you can specify this setting in the \\\"Loading \\... rows\\\" text box.\n",
    ">   \n",
    "> \n",
    ">\n",
    "> \n",
    ">  \n",
    "> \n",
    ">\n",
    "> \n",
    "> \n",
    ">  \n",
    "> \n",
    "> \n",
    ">\n",
    "> [ ![67577de1448a9f6ad7255d62b04c81092f74397f](media/67577de1448a9f6ad7255d62b04c81092f74397f.jpg){.image-inline}]{\n",
    "\n",
    ">>Use the \\\"table keywords\\\" tab to look at other tables within an MS. Double-click on a table name to view its contents in a new tab, as shown in the following figures.\n",
    ">   \n",
    "\n",
    "> \n",
    "> ![df2199ec1cbdc1efd54f633fd2ba0fbfdc464420](media/df2199ec1cbdc1efd54f633fd2ba0fbfdc464420.jpg){.image-inline} \n",
    "> \n",
    "\n",
    ">>Viewing the *ANTENNA* table of the MS.\n",
    ">   \n",
    "\n",
    "> <div>\n",
    ">\n",
    ">  ![1beb9b315d682d18e4a9793ed3bdf0a5d181dc87](media/1beb9b315d682d18e4a9793ed3bdf0a5d181dc87.jpg){.image-inline}\n",
    ">\n",
    ">>The *POLARIZATION* table shows the number and types of correlations.  The *CORR_TYPE* integer array indicates the Stokes type as defined in the Stokes class enumeration.  Common types include RR (5), RL (6), LR (7), and LL (8) for circular polarization, and XX (9), XY (10), YX (11), and YY (12) for linear polarization.\n",
    ">   \n",
    ">\n",
    "> ![123552363d6f2b9035519e8a13276f75935c1f7a](media/123552363d6f2b9035519e8a13276f75935c1f7a.jpg){.image-inline}>\n",
    ">>Double-click a cell in the table or sub-table to see its value displayed to the right.  Here, the *DATA* column cell (top right) contains a \\[2,63\\] array of complex numbers.  The *WEIGHT_SPECTRUM* for this data is shown below it as a \\[2,63\\] array of float values.  Use the sliders to see other values in the arrays, and click \\\"Close\\\" to close the cell contents display or \\\"Close All\\\" to close all contents displays.\n",
    ">   \n",
    ">\n",
    "> </div>\n",
    "\n",
    "Many options are available on the browsetable toolbar and menus:\n",
    "\n",
    "-   To open a table, click the \\\"Open Table\\\" button or use the **File \\> Open Table** menu to open a file browser dialog box.\n",
    "-   To close a table, click the \\\"Close Table\\\" button to close the table in the active tab, or use the options on the \\\"File\\\" menu to close the table in the active tab (\\\"Close Table\\\"), to select an open table to close (\\\"Close\\...\\\"), or to close all tables (\\\"Close All\\\").  You can also \\\"Close All and Exit\\\" the table browser.\n",
    "-   To edit the table and its contents, click the \\\"Edit Table\\\" button or use the **Edit \\> Edit Table** menu.  You can also use the \\\"Edit**\\\"** menu to add a row to the table.  Be careful with this, and make a backup copy of the table before editing!\n",
    "-   To view table information, click the \\\"Table Information\\\" (blue ***\\\"i\\\"*** button) or use the **View** **\\> Table Information** menu.  You can also hover the mouse pointer over the table name tab to get a popup with information.\n",
    "-   To set a TaQL filter, click the \\\"Filter on Fields\\\" button or use the **View \\> Filter on Fields** menu.  This will open a \\\"Filter Rules\\\" dialog box within the table browser in which to set the filter.  Another option is to use the *taql* parameter in the browsetable() call.\n",
    "-   To choose which columns to display, use **View \\> Columns** to select the columns from a list, which you can select individually or toggle with \\\"Show All Columns\\\" or \\\"Hide All Columns\\\".  Another option is to use the *skipcols* parameter in the browsetable() call.\n",
    "-   To format the contents of the column cells, use **View \\> Format Display** to select a column then choose its formatting (depending on its type).  For example, for numerical values you can set the precision and choose to use scientific format, or set the font and color for negative and nonnegative values.\n",
    "-   To find data using filter rules, click the \\\"Find\\\" button or use **Tools \\> Find** to open a Search Rules dialog box.\n",
    "-   To sort the table, click the \\\"Sort\\\" button, use the **Tools \\> Sort** menu to open a Table Sorter dialog box in which you can select the sort columns,or just click on the column name.  Another option is to use the *sortlist* parameter in the browsetable() call.\n",
    "-   To plot table data, click the \\\"Plot 2D\\\" button or use the **Tools \\> Plot 2D** menu to open a Plot Options dialog box where you can select the rows and axes to plot, along with plot display options.  Click  \\\"Overplot\\\" or \\\"Clear and Plot\\\" to make the plot in the Table Browser Plotter window.  There is also an option to export the plot; select PNG or JPG format and click Go.\n",
    "-   Currently, **Export \\> VOTable** results in a Fatal IO Error and kills the table browser.\n",
    "-   The default display is 1000 rows, but this can be set in the input box at the lower right.  To page through the table, use the PAGE NAVIGATION buttons to advance forward or backward one page, or go directly to the First or Last page.  You can also enter a page number and click Go.\n",
    "-   To exit the table browser, use **File \\> Exit** or click the Close \\\"X\\\" button at the upper right of the window.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** You are likely to find that browsetable needs to get a table lock before proceeding. Use the **clearstat** command to clear the lock status in this case.  You may also be unable to use other tasks on the table while it is open in the table browser.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot/Flag Visibilities \n",
    "\n",
    "Summary of tasks for plotting and flagging visibility data\n",
    "\n",
    "A number of CASA tasks handle the plotting and flagging of visibilities. The following subsections describe the usage of the relevant tasks:\n",
    "\n",
    "-   **plotms** \\-\\-- create X-Y plots of data in MS and calibration tables, flag data\n",
    "-   **flagdata** \\-\\-- data flagging\n",
    "-   **flagcmd** \\-\\-- manipulate and apply flags using FLAG_CMD table\n",
    "-   **flagmanager** \\-\\-- manage versions of data flags\n",
    "-   **msview** \\-\\-- two-dimensional viewer used for manipulating visibilities\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot/Edit using plotms \n",
    "\n",
    "Using plotms to plot and edit visibilities and calibration tables\n",
    "\n",
    "**plotms** is a GUI-\n",
    "title               =         ''        #Title written along top of plot\n",
    "titlefont           =          0        #Font for plot title\n",
    "xlabel              =         ''        #Text for horizontal axis. Blank for default.\n",
    "xaxisfont           =          0        #Font for plot x-axis\n",
    "ylabel              =         ''        #Text for vertical axis. Blank for default.\n",
    "yaxisfont           =          0        #Font for plot y-axis.\n",
    "showmajorgrid       =      False        #Show major grid lines (horiz and vert.)\n",
    "showminorgrid       =      False        #Show minor grid lines (horiz and vert.)\n",
    "showlegend          =      False        #Show a legend on the plot.\n",
    "plotfile            =         ''        #Name of plot file to save automatically.\n",
    "showgui             =       True        #Show GUI\n",
    "     clearplots     =       True        #Remove any existing plots so new ones can replace\n",
    "                                        #them.\n",
    "[callib              =       ['']        #Calibration library string or filename for on-the-]{\n",
    "                                        #fly calibration.\n",
    "headeritems         =         ''        #Comma-separated list of pre-defined\n",
    "                                        #page header items. \n",
    "showatm             =     False         #Compute and overlay the atmospheric\n",
    "                                        #transmission curve.\n",
    "showtsky            =     False         #Compute and overlay the sky\n",
    "                                        #temperature curve.\n",
    "showimage           =     False         #Compute and overlay the image\n",
    "                                        #sideband curve.\n",
    "```\n",
    "\n",
    "Note that when some parameters are set or are True, their subparameters are displayed by inp( ).  By default, selectdata, averagedata, and showgui are True and their subparameters are shown above.  Other parameters with subparameters include:\n",
    "\n",
    "```\n",
    "[[[xaxis               =     'real'        #plot x-axis (blank for default/current)         \n",
    "     xdatacolumn    =         ''        #data column to use for x-axis (blank for        \n",
    "                                        #default/current)                               \n",
    "\n",
    "yaxis               =     'imag'        #plot y-axis (blank for default/current)\n",
    "     ydatacolumn    =         ''        #data column to use for y-axis (blank for\n",
    "                                        #default/current)\n",
    "     yaxislocation  =      'left'       #yaxis is to the left of the plot\n",
    "transform           =       True        #transform data in various ways?\n",
    "     freqframe      =         ''        #the frame in which to render frequency and velocity\n",
    "                                        #axes\n",
    "     restfreq       =         ''        #Rest frequency to use for velocity conversions\n",
    "     veldef         =    'RADIO'        #the definition in which to render velocity\n",
    "     shift          = [0.0, 0.0]        #Adjust phases by this approximate phase center\n",
    "                                        #shift [dx,dy] (arcsec)\n",
    "\n",
    "extendflag          =       True        #have flagging extend to other data points?\n",
    "     extcorr        =      False        #extend flags based on correlation?\n",
    "     extchannel     =      False        #extend flags based on channel?\n",
    "iteraxis            = 'baseline'        #the axis over which to iterate\n",
    "     xselfscale     =      False        #When true, iterated plots have a common\n",
    "                                        #x-axis range (scale).\n",
    "     yselfscale     =      False        #When true, iterated plots have a common\n",
    "                                        #y-axis range (scale).\n",
    "     xsharedaxis    =      False        #Enables iterated plots on a grid to share a                                         #common external x-axis per column. Must also set                                          #xselfscale=True and gridrows>1.\n",
    "     ysharedaxis    =      False        #Enables iterated plots on a grid to share a                                          #common external y-axis per row. Must also set                                          #yselfscale=True and gridcols>1.\n",
    "\n",
    "customsymbol        =       True        #set a custom symbol(s) for unflagged points\n",
    "     symbolshape    = 'autoscaling'     #shape of plotted unflagged symbols\n",
    "     symbolsize     =          2        #size of plotted unflagged symbols\n",
    "     symbolcolor    =   '0000ff'        #color of plotted unflagged symbols\n",
    "     symbolfill     =     'fill'        #fill type of plotted unflagged symbols\n",
    "     symboloutline  =      False        #selects outlining plotted unflagged points\n",
    "\n",
    "customflaggedsymbol =       True        #set a custom plot symbol for flagged points\n",
    "     flaggedsymbolshape = 'nosymbol'    #shape of plotted flagged symbols\n",
    "     flaggedsymbolsize =          2     #size of plotted flagged symbols\n",
    "     flaggedsymbolcolor =   'ff0000'    #color of plotted flagged symbols\n",
    "     flaggedsymbolfill =     'fill'     #fill type of plotted flagged symbols\n",
    "     flaggedsymboloutline =      False  #selects outlining plotted flagged points\n",
    "\n",
    "showmajorgrid       =       True        #Show major grid lines (horiz and vert.)\n",
    "     majorwidth     =          0        #Line width in pixels of major grid lines\n",
    "     major]{]{\n",
    "```\n",
    "\n",
    "Note that if the *vis* parameter is set to the name of a MeasurementSet here, when you start **plotms** the *entire* MeasurementSet will be plotted, which can be time consuming.  You may want to set selection or averaging parameters first.\n",
    "\n",
    "To start a \\\"blank\\\" **plotms** window then enter your selections interactively in the GUI, use these commands:\n",
    "\n",
    "```\n",
    "default plotms\n",
    "plotms\n",
    "```\n",
    "\n",
    " Alternatively, they can be specified as task parameters in a **plotms** call, for scripting:\n",
    "\n",
    "```\n",
    "plotms(vis1, yaxis='phase', ydatacolumn='corrected', xaxis='frequency', coloraxis='spw', antenna='1', spw='0:3~10', corr='RR', avgtime='1e8', plotfile='vis1.jpg')\n",
    "\n",
    "```\n",
    "\n",
    "[Note that subsequent **plotms** calls will return any unspecified parameters in that call to their default values.  See also the [Examples](https://casa.nrao.edu/casadocs-devel/stable/global-task-list/task_plotms/examples) tab in the **plotms** task for **plotms** calls using many of the parameters.]{\n",
    "\n",
    "The **plotms** GUI will be described in the following sections, along with the corresponding parameters for the task interface or scripting.  For non-interactive scripting, set *showgui=False* and export the plot into an image specified by *plotfile.*\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. The Plot Tab\n",
    "\n",
    "##### 1.1 Loading, Selecting, and Averaging Data: the Plot Data Tab\n",
    "\n",
    "![947bd4c094887ae05fd3452bda5a4fb6db71314e](media/947bd4c094887ae05fd3452bda5a4fb6db71314e.png){.image-inline}\n",
    "\n",
    ">The plotms window starts on the *Plot \\> Data* tab.  No parameters have been set.\n",
    "  \n",
    "\n",
    "###### 1.1.1 File Selection\n",
    "\n",
    "When **plotms** is first started, by default it will display the *Plot* tab (as chosen from the tabs at the top of the **plotms** window) and its *Data* subtab (as chosen from the tabs on the left side) as shown in Figure 1. First, a MeasurementSet or calibration table should be loaded by clicking on *Browse* in the *File* section and selecting a MeasurementSet directory (just select the directory itself; do not descend into it).\n",
    "\n",
    "[A plot can now be made of the MeasurementSet by clicking on the *Plot* button, but you may want to set selection or averaging parameters first rather than plot the entire dataset.  By default, **plotms** will plot Amplitude versus Time for a MeasurementSet; see this [section on [selecting axes](#1-3-1-selecting-axes) ]{for axis options.  The default axes change for calibration tables depending on the table type.  **plotms** self-scales axes and the symbol size. For a very large range, this can hide points close to zero; see the sections below for information on setting [axes ranges](#1-3-4-axes-ranges) and [symbol sizes](#1-6-2-customizing-your-symbols).]{\n",
    "\n",
    "The **plotms** task parameter for file selection is *vis.*\n",
    "\n",
    "######  1.1.2 Data Selection\n",
    "\n",
    "The options for data selection are:\n",
    "\n",
    "-   field\n",
    "-   spw\n",
    "-   timerange\n",
    "-   uvrange\n",
    "-   antenna\n",
    "-   scan\n",
    "-   corr (correlated polarizations)\n",
    "-   array\n",
    "-   observation\n",
    "-   intent\n",
    "-   feed\n",
    "-   msselect\n",
    "\n",
    "[Note that, unlike when setting data selection parameters from the CASA command line, no quotation marks are needed around strings in the GUI.  For more information on data selection strings, see the documentation [here](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset).  To view information about your data in order to make your selection, see the [Summary](#5-3-summary-menu--information-about-your-dataset) section below or use the listobs task.]{\n",
    "\n",
    "Calibration table selection differs from MeasurementSet selection.  The *antenna* selection selects baselines which contain the selected antennas in MeasurementSets, but selects antenna1 only for calibration tables.  Spectral window selection (*spw*) is used to select spw only (channel selection is ignored) in calibration tables.  *corr* may be used to select cal table polarizations, including \\\"/\\\" for a ratio plot.\n",
    "\n",
    "The **plotms** parameter for data selection is *selectdata* (default is True, but no selection occurs unless one or more subparameters is set).  Its subparameters include *field, spw, timerange. uvrange, antenna, scan, correlation, array, observation, intent, feed,* and *msselect.*  These should be set to string values.\n",
    "\n",
    "###### 1.1.3 Averaging Data\n",
    "\n",
    "**plotms** enables averaging of the data in order to increase signal-to-noise of the plotted points or to increase plotting speed.  Averaging is currently not supported for\n",
    "\n",
    "-   calibration tables\n",
    "-   *Ant-Ra*, Ant*-Dec* axes    \n",
    "\n",
    "and will result in a warning in the log, then the unaveraged data will be plotted.\n",
    "\n",
    "The options for averaging in the *Plot \\> Data* tab include:\n",
    "\n",
    "-   channel\n",
    "-   time (optionally over scans or fields)    \n",
    "-   all baselines or per antenna\n",
    "-   all spectral windows\n",
    "-   vector (default) or scalar\n",
    "\n",
    "The box next to a given averaging mode needs to be checked for that averaging to take effect.  The Weight and Sigma axes are not supported in some averaging modes.  Note that the \\\"average weight\\\" is actually the weight *sum* accumulated when performing the average; i.e., the net weight of a weighted-averaged datum is the sum of the weights going into the average.\n",
    "\n",
    "When averaging, **plotms** will prefer unflagged data.  If an averaging bin contains any unflagged data at all, only the average of the unflagged will be shown. For averaging bins that contain *only* unflagged data, the average of that unflagged data will be shown. When flagging on a plot of averaged data, the flags will be applied to the unaveraged data in the MS.\n",
    "\n",
    "The **plotms** task parameter for averaging is *averagedata* (default is True, but no averaging occurs unless one or more subparameters are set).  It subparameters include *avgchannel* and *avgtime* (set to a string value in channels or seconds, default \\\"\\\"), and boolean parameters *avgscan, avgfield, avgbaseline, avgantenna, avgspw, and scalar* (True/False, default False).  Invalid combinations of averaging will result in an error message (e.g. *avgbaseline=True, avgantenna=True)* or will be ignored (e.g. *avgscan=True* but *avgtime* has not been set).\n",
    "\n",
    "###### Channel Averaging:\n",
    "\n",
    "For example, to average n channels together, the user would click on the box next to *Channel* so that an \"X\" appears in it, and then type the number n in the empty box. When the user next clicks on *Plot*, every n channels will then be averaged together and plotted against the average channel numbers. The total number of channels plotted will be decreased by a factor of n.\n",
    "\n",
    "Warning: If a complex channel selection is made e.g. of continuum in the presense of multiple lines, channel averaging is unlikely to produce a meaningful plot.\n",
    "\n",
    "###### Time Averaging:\n",
    "\n",
    "Time averaging is a little trickier, as it is controlled by three fields. If the checkbox next to *Time* is checked, a blank box with units of seconds will become active, along with two additional checkboxes: *Scan* and *Field*. If averaging is desired over a relatively short interval (say, 30 seconds, shorter than the scan length), a number can simply be entered into the blank box and, when the data are replotted, the data will be time averaged. Clicking on the *Scan* or *Field* checkbox in this case will have no impact on the time averaging.  These checkboxes become relevant if averaging over a relatively long time---say the entire observation, which consists of multiple scans---is desired. Regardless of how large a number is set in the *Time* averaging box, only data within individual scans will be averaged together. In order to average data across scan boundaries, the *Scan* checkbox must be checked and the data replotted. Finally, clicking on the *Field* checkbox enables the averaging of multiple fields together in time.\n",
    "\n",
    "###### Averaging All Baselines/Per Antenna:\n",
    "\n",
    "Clicking on the *All Baselines* checkbox will average all baselines in the array together. Alternatively, the *Per Antenna* box may be checked, which will average all baselines for a given antenna together. In this case, all baselines are represented twice; baseline 3-24 will contribute to the averages for both antenna 3 and antenna 24. This can produce some rather strange-looking plots if the user also selects on antenna---say, if the user requests to plot only antenna 0 and then averages *Per Antenna*, In this case, an average of all baselines including antenna 0 will be plotted, but each individual baseline including antenna 0 will also be plotted (because the presence of baselines 0-1, 0-2, 0-3, etc. trigger *Per Antenna* averaging to compute averages for antennae 1, 2, 3, etc. Therefore, baseline 0-1 will contribute to the average for antenna 0, but it will also singlehandedly be the average for antenna 1.)  These averaging modes currently do not support the Weight and Sigma axes.\n",
    "\n",
    "###### Averaging All Spectral Windows:\n",
    "\n",
    "Spectral windows can be averaged together by checking the box next to *All Spectral Windows*. This will result in, for a given channel n, all channels n from the individual spectral windows being averaged together.  This averaging mode currently does not support the Weight and Sigma axes.\n",
    "\n",
    "###### Vector/Scalar Averaging:\n",
    "\n",
    "Finally, the default mode is vector averaging, where the complex average is formed by averaging the real and imaginary parts of the relevant visibilities. If *Scalar* is chosen, then the amplitude of the average is formed by a scalar average of the individual visibility amplitudes.\n",
    "\n",
    "###### 1.1.4 A Brief Note Regarding plotms Memory Usage\n",
    "\n",
    "In order to provide a wide range of flexible interactive plotting options while minimizing the I/O burden and speeding up the plotting, **plotms** caches the data values for the plot (along with a subset of relevant meta-info) in as efficient a manner as possible.  Sometimes, however, the data changes on disk, for example when other data processing tasks are applied. To force plotms to reload the data, check the *Reload* box next to the *Plot* button or press the SHIFT key while clicking the *Plot* button.\n",
    "\n",
    "For plots of large numbers of points, the total memory requirement can be quite large. **plotms** attempts to predict the memory it will require (typically 5 or 6 bytes per plotted point when only one axis is a data axis, depending upon the data shapes involved), and will complain if it believes there is insufficient memory to support the requested plot. For most practical interactive purposes (plots that load and draw in less than a few or a few 10s of minutes), there is usually not a problem on typical modern workstations.  Attempts to plot large datasets on small laptops might be more likely to encounter problems here.\n",
    "\n",
    "The absolute upper limit on the number of simultaneously plotted points is currently set by the ability to index the points in the cache. For modern 64 bit machines, this is about 4.29 billion points (requiring around 25GB of memory). Such plots are not especially useful interactively, since the I/O and draw become prohibitive.In general, it is usually most efficient to plot data in modest chunks of no more than a few hundred million points or less, either using selection or averaging. Note that all iterations are (currently) cached simultaneously for iterated plots, so iteration is not a way to manage memory use. A few hundred million points tends to be the practical limit of interactive **plotms** use with respect to information content and utility in the resulting plots, especially when you consider the number of available pixels on your screen.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.2 On-The-Fly Calibration: the Plot Calibration Tab\n",
    "\n",
    "[![b94c97ec8e973a5049417474e6255ba5b02936c7](media/b94c97ec8e973a5049417474e6255ba5b02936c7.png){.image-inline}]{\n",
    "\n",
    ">The plotms Calibration tab.  This MeasurementSet has no *CORRECTED_DATA* column. A calibration library file was selected with the file browser and applied on the fly.\n",
    "  \n",
    "\n",
    "[One can apply calibration tables to the uncalibrated data on the fly, i.e. without a run of applycal beforehand, by specifying a calibration library and selecting the *corrected* Data Column for the plotted axes.  See the [Cal Library Syntax](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax) documentation for more information on specifying calibration in a string or file.]{\n",
    "\n",
    "The *Calibration* tab on the left hand side contains a field to specify a calibration library file, or use *Browse* to open a file selection dialog.  You can also specify the calibration library commands directly in a string.  There is a switch to apply the calibration library to produce the corrected data (*Calibration On*) or to show an existing *CORRECTED_DATA* column (*Calibration Off*).  If the *corrected* Data Column is requested but the column is not present in the MS and the calibration library is not set or enabled, **plotms** issues a warning and plots the *DATA* column instead.\n",
    "\n",
    "The **plotms** task parameter *'callib'* can be used to provide a calibration library file or a string containing the cal library commands.  It is enabled by default when the parameter is set.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.3 Selecting Plot Axes: The Plot Axes Tab \n",
    "\n",
    "![38b1324df723df2ffee435444a27346ea9ecd248](media/38b1324df723df2ffee435444a27346ea9ecd248.png){.image-inline}\n",
    "\n",
    " \n",
    "\n",
    ">The plotms *Plot* *\\> Axes* tab, used here to make a plot of Amp **vs.** Channel.\n",
    "  \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "###### 1.3.1 Selecting Axes\n",
    "\n",
    "The X and Y axes of a plot are selected by clicking on the *Plot \\> Axes* tab and choosing an entry from the drop-down menus below *X Axis* and *Y Axis*. The axes are grouped by type and listed in this order:\n",
    "\n",
    "-   **MeasurementSet metadata:**\n",
    "    -   **Scan** --- The scan number, as listed by listobs or the **plotms** summary\n",
    "    -   **Field ---** The field number, as listed by listobs or the **plotms** summary\n",
    "    -   **Time ---**The time at which the visibility was observed, given in terms of calendar year (yyyy/mm/dd/hh:mm:ss.s).\n",
    "    -   **Interval ---** The integration time in seconds.\n",
    "    -   **Spw** --- The spectral window number. The characteristics of each spectral window are listed in listobs or the **plotms** summary.\n",
    "    -   **Channel** --- The spectral channel number.\n",
    "    -   **Frequency** --- Frequency in units of GHz. The frame for the frequency (e.g., topocentric, barycentric, LSRK) can be set in the Plots \\> Transform tab.\n",
    "    -   **Velocity** --- Velocity in units of km s−1, as defined by the Frame, Velocity Defn, and Rest Freq parameters in the Plots \\> Transform tab.\n",
    "    -   **Corr** --- Correlations which have been assigned integer IDs, including RR (5), RL (6), LR (7), LL (8), XX (9), XY (10), YX (11), and YY (12).  The axis values are these IDs, as listed by listobs or the **plotms** summary.        \n",
    "    -   **Antenna1** --- The first antenna in a baseline pair; for example, for baseline 2-4, Antenna1= 2. Antennae are numbered according to the antenna IDs listed in listobs or the **plotms** summary.\n",
    "    -   **Antenna2** --- The second antenna in a baseline pair; for baseline 2-4, Antenna2 = 4. Antennae are numbered according to the antenna IDs listed in listobs or the **plotms** summary.\n",
    "    -   **Antenna** --- Antenna ID for plotting antenna-based quantities. Antennae are numbered according to the antenna IDs listed in listobs or the **plotms** summary.\n",
    "    -   **Baseline** --- The baseline number.\n",
    "    -   **Row** --- The MS data row number. A row number corresponds to a unique timestamp, baseline, and spectral window in the MeasurementSet.\n",
    "    -   **Observation ---** The observation ID (index)\n",
    "    -   **Intent** --- The intent ID (index)\n",
    "    -   **Feed1** --- The first feed number, most useful for single-dish data.        \n",
    "    -   **Feed2** --- The second feed number, most useful for single-dish data.\n",
    "-   **Visibility values and flags:**\n",
    "    -   **Amp** --- Data amplitudes in units which are proportional to Jansky (for data which are fully calibrated, the units should be in Jy).\n",
    "    -   **Phase** --- Data phases in units of degrees.\n",
    "    -   **Real** and **Imag** --- The real and imaginary parts of the visibility in units which are proportional to Jansky (for data which are fully calibrated, the units should be Jy).\n",
    "    -   **Wt and **Wt\\*Amp**** --- the weight of the visibility and the product of the weight and the amplitude.\n",
    "    -   **WtSp** --- WEIGHT_SPECTRUM column, i.e. a weight per channel.\n",
    "    -   **Sigma** --- the SIGMA column of the visibilities\n",
    "    -   **SigmaSp** --- SIGMA_SPECTRUM column, i.e. a sigma per channel\n",
    "    -   **Flag** --- Data which are flagged have Flag = 1, whereas unflagged data are set to Flag = 0.  Note that, to display flagged data, you will have to click on the Plots \\> Display tab and choose a Flagged Points Symbol.\n",
    "    -   **FlagRow** --- In some tasks, if a whole data row is flagged, then FlagRow will be set to 1 for that row. Unflagged rows have FlagRow = 0. However, note that some tasks (like **plotms**) may flag a row, but not set FlagRow = 1. It is probably better to plot Flag than FlagRow for most applications.\n",
    "-   **Observational geometry:**\n",
    "    -   **UVdist** --- Projected baseline separations in units of meters. Note that UVDist is not a function of frequency.\n",
    "\n",
    "    -   **UVwave ---** Projected baseline separations in units of the observing wavelength (lambda, not kilolambda). UVwave is a function of frequency, and therefore, there will be a different data point for each frequency channel.\n",
    "\n",
    "    -   **U, **V**,** and ****W** ---** u, v, and w in units of meters.\n",
    "\n",
    "    -   **Uwave**, **Vwave**, and **Wwave** --- u, v, and w in units of wavelengths lambda.\n",
    "\n",
    "    -   **Azimuth** and **Ant-Azimuth** --- Azimuth in units of degrees. Azimuth plots a fiducial value for the entire array, while Ant-Azimuth plots the azimuth for each individual antenna (their azimuths will differ depending on each antenna\\'s longitude, latitude, and elevation).\n",
    "\n",
    "    -   \n",
    "        **Elevation** and **Ant-Elevation** --- Elevation in units of degrees. Elevation is a representative value for the entire array, while Ant-Elevation is the elevation for each individual antenna (their elevations will differ depending on each antenna\\'s longitude, latitude, and elevation).\n",
    "        \n",
    "\n",
    "    -   **Ant-Ra** and **Ant-Dec** --- Longitude and latitude of the direction to which the first antenna of a baseline points at data-taking timestamps.        \n",
    "\n",
    "    -   \n",
    "        **HourAngle** --- Hour angle in units of hours. This is a fiducial value for the entire array.\n",
    "        \n",
    "\n",
    "    -   **ParAngle** and **Ant-ParAng** --- Parallactic angle in units of degrees. ParAngle is the fiducial parallactic angle for all antennae in the array, while Ant-ParAng plots the parallactic angle for each individual antenna (their parallactic angles will differ depending on each antenna\\'s longitude, latitude, and elevation).\n",
    "-   **Calibration:**\n",
    "    -   **GainAmp, **GainPhase**, **GainReal**, **GainImag**** --- the amplitude, phase, real and imaginary part of the calibration tables for regular complex gain tables.\n",
    "    -   **Delay** --- The delay of a delay calibration table.\n",
    "    -   **SwPower** --- Switched Power values for VLA switched power calibration tables.\n",
    "    -   **Tsys** --- Tsys for Tsys calibration tables.\n",
    "    -   **Opac** --- Opacity values of a Opacity calibration table.\n",
    "    -   **SNR** --- Signal-to-Noise Ratio of a calibration table.\n",
    "    -   **TEC** --- Total Electron Content of an ionosphere correction calibration table.\n",
    "-   **Ephemeris:**\n",
    "    -   **Radial Velocity** --- for an ephemeris source, in km/s.\n",
    "    -   **Distance (rho)** --- for an ephemeris source, in km.\n",
    "-   \n",
    "\n",
    "If the data axis selected from the drop-down menu is already stored in the cache (therefore implying that plotting will proceed relatively quickly), an \"X\" will appear in the checkbox next to *Cached*.   To reload the data from disk, the *Reload* checkmark should be set at the bottom of this display.\n",
    "\n",
    "The **plotms** task parameters used to select the axes are *xaxis* and *yaxis*.  Valid options include \\'scan\\', \\'field\\', \\'time\\', \\'interval\\', \\'spw\\', \\'chan\\' (or \\'channel\\'), \\'freq\\' (or \\'frequency\\'), \\'vel\\' (or \\'velocity\\'), \\'corr\\' (or \\'correlation), \\'ant1\\' (or \\'antenna1\\'), \\'ant2\\' (or \\'antenna2\\'), \\'baseline\\', \\'row\\', \\'observation\\', \\'intent\\', \\'feed1\\', \\'feed2\\', \\'amp\\' (or \\'amplitude\\'), \\'phase\\', \\'real\\', \\'imag\\', \\'wt\\' (or \\'weight\\'), \\'wtsp\\' (or \\'weightspectrum\\'), \\'flag\\', \\'flagrow\\', \\'uvdist\\', \\'uvwave\\' (or \\'uvdistl\\'), \\'u\\', \\'v\\', \\'w\\', \\'uwave\\', \\'vwave\\', \\'wwave\\', \\'azimuth\\', \\'elevation\\', \\'hourang\\' (or \\'hourangle\\'), \\'parang\\' (or \\'parangle\\'), \\'ant\\' (or \\'antenna\\'), \\'ant-azimuth\\', \\'ant-elevation\\', \\'ant-ra\\', \\'ant-dec\\', \\'ant-parang\\' (or \\'ant-parangle\\'), \\'gainamp\\' (or \\'gamp\\'), \\'gainphase\\' (or \\'gphase\\'), \\'gainreal\\' (or \\'greal\\'), \\'gainimag\\' (or \\'gimag\\'), \\'delay\\' (or \\'del\\'), \\'swpower\\' (or \\'swp\\' or \\'spgain\\'), \\'tsys\\', \\'opacity\\' (or \\'opac\\'), \\'snr\\', \\'tec\\', \\'radialvelocity\\', \\'distance\\' (or \\'rho\\').\n",
    "\n",
    "When left as the default empty strings (\\\"\\\"), the axes for a MeasurementSet will be Amp vs. Time.  The default axes for a calibration table depend on the type.\n",
    "\n",
    "###### 1.3.2 Setting Axes Parameters \n",
    "\n",
    "###### 1.3.2.1 Data Columns \n",
    "\n",
    "For relevant data axes like Amp and Phase, the user will be presented with the option to plot raw data or calibrated data. This can be selected via a *Data Column* drop-down menu, located directly under the drop-down menu for *X Axis* or *Y Axis* selection. To plot raw data, select \"data\"; to plot calibrated data, select \"corrected\". Note that this choice will only have an impact on a plot if a calibration table has been applied to the MeasurementSet or a calibration library is set and enabled.\n",
    "\n",
    "If a data model is present in the MeasurementSet (e.g., created by setjy, clean, or ft), it can be plotted by selecting \"model\" from the *Data Column* menu. For MeasurementSets with float data instead of complex data, common in singledish datasets, select the \\\"float\\\" datacolumn.\n",
    "\n",
    "Residuals can be plotted via \\\"corrected-model_vector\\\", \\\"corrected-model_scalar\\\", \\\"data-model_vector\\\", data-model_scalar\\\", \\\"corrected/model_vector\\\", \\\"corrected/model_scalar\\\", \\\"data/model_vector\\\", and \\\"data/model_scalar\\\".  The vector and scalar options distinguish between versions where values like amp, phase, etc. are calculated before (scalar) or after (vector) the subtraction or division.\n",
    "\n",
    "The **plotms** task parameters used to select the data columns are *xdatacolumn* and *ydatacolumn*.  Valid options include \\'data\\', corrected\\', \\'model\\', \\'float\\', \\'corrected-model\\' (vector implied), \\'corrected-model_vector\\', \\'corrected-model_scalar\\', \\'data-model\\' (vector implied), \\'data-model_vector\\', \\'data-model_scalar\\', \\'corrected/model\\' (vector implied), \\'corrected/model_vector\\', \\'corrected/model_scalar\\', \\'data/model\\' (vector implied), \\'data/model_vector\\', and \\'data/model_scalar\\'.  The implied vector residual datacolumns were kept for backwards compatibility.  Default data columns for x and y are both \\'data\\'.\n",
    "\n",
    "###### 1.3.2.2 Antenna Pointing Direction Parameters  \n",
    "\n",
    "Ant-Ra, Ant-Dec axes are the longitude and the latitude of the direction to which the first antenna of a baseline points at data-taking timestamps. Their value is computed by\n",
    "\n",
    "-   interpolating with a user-supplied method the direction of that antenna at that data-taking timestamp, from the known directions pointed by that antenna at pointing-direction-recording timestamps, recorded in MeasurementSet\\'s POINTING table\n",
    "-   converting the result to a user-specified output reference frame    \n",
    "\n",
    "The **plotms** task parameters to set ant-ra and ant-dec axes parameters are:\n",
    "\n",
    "-   xinterp: interpolation method to use when xaxis=\\'ant-ra\\' or xaxis=\\'ant-dec\\'\n",
    "-   xframe: output reference frame to use when xaxis=\\'ant-ra\\' or xaxis=\\'ant-dec\\'\n",
    "-   yinterp: interpolation method to use when yaxis=\\'ant-ra\\' or yaxis=\\'ant-dec\\'\n",
    "-   yframe: output reference frame to use when yaxis=\\'ant-ra\\' or yaxis=\\'ant-dec\\'\n",
    "\n",
    "Valid values for xframe and yframe are: \\'icrs\\', \\'j2000\\', \\'b1950\\', \\'galactic\\', \\'azelgeo\\' (default \\\"\\\" == \\'icrs\\') \n",
    "\n",
    "Valid values for xinterp and yinterp are: \\'nearest\\', \\'cubic spline\\', \\'spline\\' (default \\\"\\\" == \\'cubic spline\\') \n",
    "\n",
    "Note:\n",
    "\n",
    "-   \\'spline\\' is a synonym for \\'cubic spline\\'\n",
    "-   when the interpolation method is set to \\'nearest\\', reference frame conversion is performed at the nearest pointing-recording timestamp, not at the data-taking timestamp\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "WARNING: plotting antennas pointing directions with the Ant-Ra / Ant-Dec axes has only been implemented for ALMA, ASTE, and NRO data.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "###### 1.3.3 Axis Locations \n",
    "\n",
    "The location of the x-axis and y-axis can be set using the radio buttons in the GUI, where the x-axis can be located at the *Bottom* (default) or *Top*, and the y-axis can be located at the *Left* (default) or *Right.*\n",
    "\n",
    "The **plotms** task parameter to set the y-axis location is *yaxislocation. * There is no parameter to set the x-axis location.  Valid values for this parameter include \\'left\\' and \\'right\\' (default \\\"\\\" == \\'left\\').\n",
    "\n",
    "###### 1.3.4 Axes Ranges \n",
    "\n",
    "The X and Y ranges of the plot can be set manually or automatically. By default, the circle next to *Automatic* will be checked, and the ranges will be auto-scaled. To define the range, click on the circle below *Automatic* and enter a minimum and maximum value in the blank boxes. Note that if identical values are placed in the blank boxes (xmin=xmax and/or ymin=ymax), then the values will be ignored and a best guess will be made to auto-range that axis.\n",
    "\n",
    "[The **plotms** task parameter used to set the axes ranges is *plotrange*, and its value is a list of numbers in the format \\[xmin, xmax, ymin, ymax\\] (default \\[ \\], automatic range).]{\n",
    "\n",
    "###### 1.3.5 Plotting Multiple Y-Axes \n",
    "\n",
    "[Different values of the same dataset can be shown at the same time. To add a second y-axis, press the *Add Y Axis Data* button at the bottom of the *Axes* tab. Then select the parameters for the newly created axis by selecting from the new \"Y Axis Data\" drop-down menu. If the two y-axes have the same units, they can be displayed both on the same axis. If they are different (or their ranges are dissimilar), e.g. Amplitude and Elevation (both versus Time; see Figure 4 below), one axis should be attached to the left and the other to the right hand side of the plot. Using more than a single y-axis data is also reflected in the *Display* tab where a drop-down menu appears in order to select multiple y-axis options; here you may colorize each axis differently.  See the [[section below[[ to learn more about [symbol properties](#1-6-2-customizing-your-symbols)]{.]{]{ To remove the additional y-axis, click *Delete Y Axis Data* at the bottom of the *Axes* tab.]{]{\n",
    "\n",
    "[[![6ea1a2b82d3016d25f772e89ef08d716ed1ff364](media/6ea1a2b82d3016d25f772e89ef08d716ed1ff364.png)]{]{\n",
    "\n",
    ">Overplotting in plotms: Two different y-axes for the same dataset have been chosen for this plot, amplitude and elevation.\n",
    "  \n",
    "\n",
    "The **plotms** task parameters used to plot multiple y-axes are the same as for a single y-axis: *yaxis* and *yaxislocation*; multiple y-axes can be specified as a list of strings if you are specifying the **plotms** command in the terminal. The values for *yaxis* and *yaxislocation* should be set to lists of the same length:\n",
    "\n",
    "```\n",
    "[plotms(vis='ngc5921.ms', yaxis=['amp','elevation'], yaxislocation=['left','right'])]{\n",
    "```\n",
    "\n",
    "###### 1.3.6 Atmospheric Curve Overlays  \n",
    "\n",
    "The ability to compute and overlay an atmospheric transmission curve or a sky temperature curve, available in plotbandpass, has been added to **plotms**.  For this feature, the x-axis must be Channel or Frequency; if another axis is chosen, a warning is issued and the plot continues without the overlay.\n",
    "\n",
    "[**plotms** uses the dataset\\'s subtables to compute the mean weather values: pressure, humidity, temperature, and precipitable water vapor (pwv).  If these subtables are not found, reasonable defaults are used instead and reported in a log message.  The [atmosphere tool](https://casa.nrao.edu/casadocs-devel/stable/global-tool-list/tool_atmosphere) is then used by **plotms** to calculate dry and wet opacities to produce the requested overlay curve, corrected by the airmass based on elevation.]{\n",
    "\n",
    "[![fbf2f683de008d52ef2db218adad4d151c72c4a9](media/fbf2f683de008d52ef2db218adad4d151c72c4a9.png){.image-inline}]{\n",
    "\n",
    ">Amp vs. Frequency plot with a Tsky overlay.  The Tsky y-axis is automatically added on the right, and the curve is plotted in magenta.  The Plot \\> Axes tab shows the radio buttons to select the Overlay: None, Atm, or Tsky.\n",
    "  \n",
    "\n",
    "The **plotms** task parameters used to plot the overlays are *showatm* and *showtsky*.  These take boolean values and their defaults are False.  Only one overlay can be selected; if both are set to True, only the atmospheric curve (*showatm*) will be displayed.\n",
    "\n",
    "```\n",
    "plotms(vis=myvis, yaxis='amp', xaxis='freq', showatm=True)\n",
    "```\n",
    "\n",
    "The image sideband curve may also be shown in **plotms** when the atmospheric transmission or sky temperature curves are plotted.  In order to do this, the MS (or associated MS for a calibration table) cannot have reindexed spectral window IDs as a result of a split, and must have an ASDM_RECEIVER table in order to read the LO frequencies.  If these conditions are not met, a warning is issued and only the atm/tsky curves are calculated and plotted.\n",
    "\n",
    "[![06d13146ca57d00a107fef7873643a317b22505c](media/06d13146ca57d00a107fef7873643a317b22505c.png){.image-inline}]{\n",
    "\n",
    ">Gain Amp vs. Frequency plot for a bandpass calibration table with the Atm Transmission (magenta) and Image Sideband (black) overlays, colorized by spw and one antenna selected.  The Plot \\> Axes tab shows the checkbox to select the image sideband curve, enabled only when the Overlay is Atm or Tsky.\n",
    "  \n",
    "\n",
    "The **plotms** task parameter used to plot the image sideband curve overlay is *showimage*.  This takes a boolean value and its default is False.  If *showatm=False* and *showtsky=False*, a warning is issued and the curve will not be calculated and plotted.\n",
    "\n",
    "```\n",
    "plotms(vis=mycaltable, yaxis='amp', xaxis='freq', antenna='0', coloraxis='spw', showatm=True, showimage=True)\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.4 Iteration and Page Header : The Plot Page Tab\n",
    "\n",
    "######  ![1f43767491c56766199057350f36b7e6b69384a4](media/1f43767491c56766199057350f36b7e6b69384a4.png)\n",
    "\n",
    ">Plot Page Tab\n",
    "  \n",
    "\n",
    "###### 1.4.1 Iteration\n",
    "\n",
    "In many cases, it is desirable to iterate through the data that were selected in the Data tab. A typical example is to display a single baseline in an amplitude vs. time plot and then proceed to the next baselines step by step. This can be done via the *Plot \\> Page* tab.  A drop-down menu allows you to select the axis to be iterated on, with options *None, Scan, Field, Spw, Baseline, Antenna, Time,* and *Corr*.  Press the *Plot* button after changing your selection.  Each plot will be autoscaled according to its iteration value range unless a *Range* is specified in the *Axis* tab.\n",
    "\n",
    "The current iteration is indicated in the plot title of the displayed plot. To proceed to the next plot use the green arrow buttons below the main panel. The different button symbols let you to proceed panel by panel (single arrow symbols) or to jump to the first or last panel directly (double arrow symbols).\n",
    "\n",
    "[The number of plots per page can be selected under *Options \\> Grid*, the last of the top row of tabs, as described in the section on [plotting on a grid](#4-1-plotting-on-a-grid).  There are two scaling options for the iterated axes in a grid, set in this tab: Global and Shared. Global will use a common axis range based on data loaded with the selection criteria specified in the Data tab. Shared displays one set of x-axes and y-axes for the page rather than per-plot.  When left unchecked, *Global *and *Shared *results in plots with axes scaling to the data for each individual panel of the iteration.  See Figure 9 in [section 4.1.1](#4-1-1-plotting-iterations-on-a-grid) for an example of global shared x-axes and y-axes.]{\n",
    "\n",
    "The **plotms** task parameter used to select an iteration axis is *iteraxis*.  The options include \\'scan\\', \\'field\\', \\'spw\\', \\'baseline\\', \\'antenna\\', \\'time\\', and \\'corr\\'.\n",
    "\n",
    "To use a global axis range for iterated plots, set parameters *xselfscale=True* and/or *yselfscale=True*.  To use a shared external x-axis per column on a grid, set *xsharedaxis=True* (must also set *xselfscale=True* and *gridrows* greater than 1).  To use a shared external y-axis per row on a grid, set *ysharedaxis=True* (must also set *yselfscale=True* and *gridcols* greater than 1).\n",
    "\n",
    "###### 1.4.2 Page Header\n",
    "\n",
    "It is sometimes useful to display above the plots a page header showing some metadata information. To do so, select in the lower list the header items you want to display, and press the antenna-shaped \\\"arrow\\\" pointing up. This will move the items you selected to the upper list showing the header contents, without updating the page header. Press the Plot button to update the page header.\n",
    "\n",
    "Multiple items can be selected at once by pressing the Shift or the Control key, Control+A selects all items.\n",
    "\n",
    "Items displayed in the Contents list are laid out on 2 columns in the page header, in \\\"Z\\\" order.\n",
    "\n",
    "To remove items from the Contents list, select in that list the items to remove and press  the antenna-shaped \\\"arrow\\\" pointing down.\n",
    "\n",
    "Antennas blink red when clicked while their corresponding selection is empty, green otherwise.\n",
    "\n",
    "Header items from multiple plots can be displayed in the page header. In that case items from the first plot are laid out first, items from the second plot are then laid out starting from the first empty row, and so on.\n",
    "\n",
    "The contents of the header is common to all pages.\n",
    "\n",
    "The **plotms** task parameter used to specify header items is *headeritems*. Legal value is a string whose value can be any comma-separated combination of the following pre-defined keywords: \n",
    "\n",
    "-   \\'filename\\', \\'projid\\',\\'telescope\\',\\'observer\\',\\'obsdate\\',\\'obstime\\',\\'targname\\',\\'targdir\\',\\'ycolumn\\'\n",
    "\n",
    "When selected data leaves room for multiple candidates (e.g when selected data spans multiple observations or include multiple fields or sources), the first selected row in MeasurementSet\\'s Main table is used as a starting point for looking up a single \\\"first\\\" candidate in  MeasurementSet\\'s auxiliary tables.\n",
    "\n",
    "Observation Start Date and Observation Start Time are looked up in MeasurementSet\\'s Observation table, and therefore differ from the output of listobs task.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.5 Transforming the Velocity Frame or Phase Center: The Plot Transform Tab \n",
    "\n",
    "###### 1.5.1 Frequency Frame\n",
    "\n",
    "If the user plans to plot frequency, the reference frame must be defined. By default, **plotms** selects the frame keyword (if any) present in the data, usually the frame observed at the telescope unless modified during previous processing. However, transformations can be made by choosing a *Frame* from the drop-down menu in the *Plot \\> Transform* tab. Frequency reference frames can be chosen to be:\n",
    "\n",
    "-   LSRK --- local standard of rest (kinematic)\n",
    "-   LSRD --- local standard of rest (dynamic)\n",
    "-   BARY --- barycentric\n",
    "-   GEO --- geocentric\n",
    "-   TOPO --- topocentric\n",
    "-   GALACTO --- galactocentric\n",
    "-   LGROUP --- local group\n",
    "-   CMB --- cosmic microwave background dipole\n",
    "\n",
    "The **plotms** task parameter used to select frequency frame is *freqframe.*  Valid options include those listed above (strings with all caps).  The default empty string \\\"\\\" results in no frame transformation.\n",
    "\n",
    "###### 1.5.2 Velocity\n",
    "\n",
    "If Velocity is selected as an axis, by default the transformation from frequency uses the parameters in the MS metadata, or, if absent, using the central frequency and TOPO frame. The user can change this by using the *Frame, Velocity Defn,* and *Rest Freq* options in the Transform tab*. * The velocity definition is chosen from the *Velocity Defn* drop-down menu, offering selections of *Radio, True* (Relativistic)*,* or *Optical.*\n",
    "\n",
    "For more information on frequency frames and spectral coordinate systems, see the paper by Greisen et al. (A&A, 446, 747, 2006) [(Also at[ [[http://www.aoc.nrao.edu/\\~egreisen/scs.ps](http://www.aoc.nrao.edu/%7Eegreisen/scs.ps)]{)]{]{^^\n",
    "\n",
    "Finally, the spectral line's rest frequency in units of MHz should be typed into the *Rest Freq* input box next[. You can use the [slsearch](https://casa.nrao.edu/casadocs-devel/stable/global-task-list/task_slsearch) task to search a spectral line table, or the ]{me.spectralline tool method to turn transition names into frequencies:\n",
    "\n",
    "```\n",
    "CASA <16>: me.spectralline('HI')\n",
    "[ Out[17]: ]{\n",
    "{'m0': {'unit': 'Hz', 'value': 1420405751.786},\n",
    " 'refer': 'REST',\n",
    " 'type': 'frequency'}\n",
    "```\n",
    "\n",
    "For a list of known lines in the CASA measures system, use the toolkit command me.linelist(). For example:\n",
    "\n",
    "```\n",
    "CASA <21>: me.linelist()\n",
    "[ Out[21]: 'HI H186A H185A H184A H183A H182A H181A H180A H179A H178A H177A H176A H175A ]{\n",
    "H174A H173A H172A H171A H170A H169A H168A H167A H166A H165A H164A H163A H162A H161A H160A... \n",
    "He182A He181A He180A He179A He178A He177A He176A He175A He174A He173A He172A He171A He170A \n",
    "He169A He168A He167A He166A He165A He164A He163A He162A He161A He160A He159A He158A He157A...\n",
    "C186A C185A C184A C183A C182A C181A C180A C179A C178A C177A C176A C175A C174A C173A C172A \n",
    "C171A C170A C169A C168A C167A C166A C165A C164A C163A C162A C161A C160A C159A C158A C157A... \n",
    "NH3_11 NH3_22 NH3_33 NH3_44 NH3_55 NH3_66 NH3_77 NH3_88 NH3_99 NH3_1010 NH3_1111 NH3_1212 \n",
    "OH1612 OH1665 OH1667 OH1720 OH4660 OH4750 OH4765 OH5523 OH6016 OH6030 OH6035 OH6049 OH13433 \n",
    "OH13434 OH13441 OH13442 OH23817 OH23826 CH3OH6.7 CH3OH44 H2O22 H2CO4.8 CO_1_0 CO_2_1 CO_3_2 \n",
    "CO_4_3 CO_5_4 CO_6_5 CO_7_6 CO_8_7 13CO_1_0 13CO_2_1 13CO_3_2 13CO_4_3 13CO_5_4 13CO_6_5 \n",
    "13CO_7_6 13CO_8_7 13CO_9_8 C18O_1_0 C18O_2_1 C18O_3_2 C18O_4_3 C18O_5_4 C18O_6_5 C18O_7_6 \n",
    "C18O_8_7 C18O_9_8 CS_1_0 CS_2_1 CS_3_2 CS_4_3 CS_5_4 CS_6_5 CS_7_6 CS_8_7 CS_9_8 CS_10_9 \n",
    "CS_11_10 CS_12_11 CS_13_12 CS_14_13 CS_15_14 CS_16_15 CS_17_16 CS_18_17 CS_19_18 CS_12_19 \n",
    "SiO_1_0 SiO_2_1 SiO_3_2 SiO_4_3 SiO_5_4 SiO_6_5 SiO_7_6 SiO_8_7 SiO_9_8 SiO_10_9 SiO_11_10 \n",
    "SiO_12_11 SiO_13_12 SiO_14_13 SiO_15_14 SiO_16_15 SiO_17_16 SiO_18_17 SiO_19_18 SiO_20_19 \n",
    "SiO_21_20 SiO_22_21 SiO_23_22'\n",
    "```\n",
    "\n",
    "The **plotms** task parameters used to set velocity definition and rest frequency are *veldef* and *restfreq.*  Valid options for *veldef* are \\'RADIO\\', \\'TRUE\\', or \\'OPTICAL\\' (default is \\'RADIO\\').  *restfreq* should be in a string in MHz, for example \\'22235.08MHz\\'.\n",
    "\n",
    "###### 1.5.3 Shifting the Phase Center\n",
    "\n",
    "The plot's phase center can be shifted in the *Plot \\> Transform* tab. This will allow coherent vector averaging of visibility amplitudes far from the phase tracking center.  Enter the X and Y shifts in units of arcseconds in the *dX* and *dY* boxes under *Phase center shift*.\n",
    "\n",
    "[The **plotms** task parameter used to shift the phase center is *shift*.  Its value should be a list in the format \\[dx,dy\\] in arcsec (default \\[0.0, 0.0\\]).]{\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.6 Display Options for Plots: The Plot Display Tab\n",
    "\n",
    "###### 1.6.1 Colorizing Your Data \n",
    "\n",
    "Data points can be given informative symbol colors using the *Colorize* option in the *Plot \\> Display* tab. By checking the box next to *Colorize* and selecting a data axis from the drop-down menu, the data will be plotted with colors that vary along that axis. For example, if \"corr\" is chosen from the *Colorize* menu, \"RR\", \"LL\", \"RL\", and \"LR\" data will each be plotted with a different color. Note that *Colorize* while plotting flagged data will override the default flagged red symbol color.\n",
    "\n",
    "The **plotms** task parameter used to colorize data is *coloraxis*.  Options include \\'scan\\', \\'field\\', \\'spw\\', \\'antenna1\\', \\'antenna2\\', \\'baseline\\', \\'channel\\', \\'corr\\', \\'time\\', \\'observation\\', and \\'intent\\'.\n",
    "\n",
    "###### 1.6.2 Customizing Your Symbols\n",
    "\n",
    "Unflagged and flagged plot symbols can be customized in the *Plot \\> Display* tab. Most fundamentally, the user can choose to plot unflagged data and/or flagged data. By default, unflagged data is plotted (the circle next to *Default* is checked under *Unflagged Points Symbol*), and flagged data is not plotted (the circle next to *None* is checked under *Flagged Points Symbol*). We note here that plotting flagged data on an averaged plot is undertaken at the user's own risk, as the distinction between flagged points and unflagged points becomes blurred if data are averaged over a dimension that is partially flagged. Take, for example, a plot of Amplitude vs. Time where all channels are averaged together, but some channels have been flagged due to RFI spikes. In creating the average, **plotms** will skip over the flagged channels and only use the unflagged ones. The averaged points will be considered unflagged, and the flagged data will not appear on the plot at all.\n",
    "\n",
    "Symbol options include:\n",
    "\n",
    "-   None --- no data points\n",
    "-   Default --- data points which are small circles (blue for unflagged data and red for flagged data)\n",
    "-   Custom --- allows the user to define a plot symbol\n",
    "\n",
    "If *Custom* plot symbols are chosen, the user can determine:\n",
    "\n",
    "1.  **Size**, by typing a number in the blank box next to *px* or by clicking on the adjacent up or down arrows.\n",
    "2.  **Shape**, chosen from the drop-down menu; options include *circle, square, diamond*, *pixel*, or *autoscaling. * Note that pixel only has one possible size.  *autoscaling* attempts to adjust the size of the points from dots to circles of different sizes, depending on how many points are plotted.*    *\n",
    "3.  **Color**, chosen by typing a hex color code in the *Fill* input box or by clicking on the \\... button and selecting a color from the pop-up GUI.\n",
    "4.  **Fill**, using the adjacent drop-down menu for how heavily the plot symbol is shaded with this color, from heaviest to lightest; options include *fill, mesh1, mesh2, mesh3*, and *no fill*.\n",
    "5.  **Outline**, by selecting *None* (no outline) or *Default *(outlined in black)\n",
    "\n",
    "Note that if \"no fill\" and *Outline: None* are selected, the plot symbols will be invisible.\n",
    "\n",
    "The **plotms** task parameter and subparameters used to customize unflagged symbols include:\n",
    "\n",
    "-   *customsymbol* (True/False, default False) - must be True for subparameters to take effect    \n",
    "-   *symbolshape* (\\'autoscaling\\', \\'circle\\', \\'square\\', \\'diamond\\', \\'pixel\\', \\'nosymbol\\', default \\'autoscaling\\')\n",
    "-   *symbolsize* (in number of pixels, default 2)\n",
    "-   *symbolcolor* (RGB hex code e.g. \\'aa55ff\\' or string color name e.g. \\'purple\\', default \\'0000ff\\' blue)\n",
    "-   *symbolfill* (\\'fill\\', \\'mesh1\\', \\'mesh2\\', \\'mesh3\\', \\'no fill\\', default \\'fill\\'*)*    \n",
    "-   *symboloutline* (True/False, default False)\n",
    "\n",
    "The **plotms** task parameters used to customize flagged symbols include *customflaggedsymbol* (default False) with subparameters *flaggedsymbolshape* (default \\'nosymbol\\'), flaggedsymbolsize (default 2), *flaggedsymbolcolor* (default \\'ff0000\\' red), *flaggedsymbolfill* (default \\'fill\\'), and *flaggedsymboloutline* (default False).  Supported values are the same as for unflagged symbols.\n",
    "\n",
    "###### 1.6.3 Symbols for Multiple Y-Axes \n",
    "\n",
    "If you have added an additional y-axis in the *Plot \\> Axes* tab, you may customize each y-axis individually by selecting the axis in the *Y Axis Data* pull-down menu at the top of the *Plot \\> Display* tab and then customizing the symbols for that axis.\n",
    "\n",
    "To set multiple symbols in the **plotms** task, set the symbol parameters as a list:\n",
    "\n",
    "```\n",
    "[plotms(vis='ngc5921.ms', yaxis=['amp','elevation'], yaxislocation=['left','right'], customsymbol=[True,True], symbolcolor=['purple','green'])\n",
    "]{\n",
    "```\n",
    "\n",
    "In this plot, the \\'amp\\' axis will be purple, and the \\'elevation\\' axis will be green.\n",
    "\n",
    "###### 1.6.4 Connecting the Points\n",
    "\n",
    "Plotms has the capability to connect points for calibration tables; support for MeasurementSets will be added later.  The points are colorized and connected along the x-axis or time axis by line or step.  Points with the same metadata but varying values of the x-axis or time are connected.  Unflagged points are not connected to flagged points, even when they are not displayed.  The \\\"Colorize\\\" axis will override the connection colorization.\n",
    "\n",
    "[![1cb0ac9d3ca82e6a491a0d9b7ce4e6c219c0886a](media/1cb0ac9d3ca82e6a491a0d9b7ce4e6c219c0886a.png){.image-inline}]{\n",
    "\n",
    ">Plot Display tab showing the Connect Points options for a gain table.  Here, points with the same spw, channel, polarization, and antenna1 are connected along the time axis.\n",
    "  \n",
    "\n",
    "The plotms task parameters used to connect points in a calibration table plot are *xconnector* (default \\\"none\\\", options \\\"line\\\" or \\\"step\\\") and *timeconnector* (default False, or True to connect along time axis instead of x-axis).\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### 1.7 Plot Labels: The Plot Canvas Tab \n",
    "\n",
    "###### 1.7.1 Plot Title \n",
    "\n",
    "Options to change the plot title include *None* (no title), *Default,* and a user-input string.  To set the plot title, under *Title*, click on the circle next to the input box and enter the desired text. This text box shows the grayed-out default string, \\\"%%yaxis%% vs. %%xaxis%%\\\" (to substitute the axis names for \\\"yaxis\\\" and \\\"xaxis\\\").  The user can also choose the size of the title font by checking the *Title Font* checkbox and entering the font size or using the arrows to increase or decrease the value.  The default is to scale the title font depending on the plot size.\n",
    "\n",
    "The **plotms** task parameters used to set the title and its font are *title* (default \\\"\\\" for yaxis vs. xaxis string) and *titlefont* (default is 0 to autoscale).  Set *title=\\'\\\"\\\"* for the default title (Y vs. X) or \\\" \\\" (space) for no title. \n",
    "\n",
    "###### 1.7.2 Legend\n",
    "\n",
    "[A plot symbol legend can be added to the plot by clicking on the checkbox next to *Legend*. For a simple plot, [a symbol legend simply echoes the plot axes (e.g. \\\"Amp vs Time\\\") but is useful when [overplotting data](#7-1-overplotting-multiple-data-sets-on-the-same-plot) with custom colors so that you can identify the data (e.g. \\\"Amp vs Time\\\" in blue and \\\"Phase vs Time\\\" in green on the same plot).]{]{\n",
    "\n",
    "When enabled, a drop-down menu next to *Legend* allows the user to select the legend location either within the plot (Upper Right, Lower Right, Upper Left, Lower Left) or outside the plot (Out Right, Out Left, Out Top, Out Bottom).\n",
    "\n",
    "The **plotms** task parameter used to enable the legend is *showlegend* (default is False).  To select the legend location subparameter, set *legendposition* to \\'upperRight\\', \\'upperLeft\\', \\'lowerRight\\', \\'lowerLeft\\', \\'exteriorRight\\', \\'exteriorLeft\\', \\'exteriorTop\\', or \\'exteriorBottom\\' (default is \\\"\\\" == upperRight).\n",
    "\n",
    "###### 1.7.3 Axis Labels \n",
    "\n",
    "To enable the X- and Y-axis labels, check the *Show Label* checkboxes under *X Axis* and *Y Axis *(default is checked).  As with the plot title, the user may set the label to None (no label), Default (axis name with units),* * or type the desired text in the blank box.  The font size of labels can also be customized by enabling then setting the font size for each axis.  The location of axis labels is determined by the axis location as set in the *Plot \\> Axes*[ tab, as shown in [the section above](#1-3-3-axis-locations).]{\n",
    "\n",
    "The **plotms** task parameters used to set the label text and font are *xlabel and ylabel* (default \\\"\\\" is axis name with units, set to \\' \\' space to disable label) and *xaxisfont* and *yaxisfont* (default 0 == autoscale).\n",
    "\n",
    "###### 1.7.4 Grid Lines \n",
    "\n",
    "A grid of lines can be superimposed on the plot using *Grid Lines* in the *Plot \\> Canvas* tab. \"Major\" grid lines are drawn at the locations of major tick marks, while \"minor\" grid lines are drawn at minor tick marks.\n",
    "\n",
    "Grid line colors, thicknesses, and \n",
    "\n",
    ">The plotms *Flag* tab.  Here the *Extend flags* box has been checked, enabling the *Correlation* and *Channel* options.  The plot shows unflagged data in blue and flagged data in red.\n",
    "  \n",
    "\n",
    "[See the section below on [interactive flagging in plotms.](#8--interactive-flagging)  The options in this tab allows the user to have flagging extend to other data points besides what is marked on the plot.]{\n",
    "\n",
    "When enabled with the *Extend flags* checkbox, the user may choose to extend flags based on correlation or channel by checking the corresponding checkboxes.  Future options for flag extensions are planned.\n",
    "\n",
    "By checking the boxes next to *Extend Flags* and *Correlation**,* flags will be extended beyond the correlations displayed. Currently the only option is to extend to *All* correlations as noted by the radio button, implying that all correlations will be flagged.  For example, with RR displayed, the correlations RR, RL, LR, and LL will all be flagged when this option is enabled.\n",
    "\n",
    "By checking the boxes next to *Extend Flags* and *Channel*, flagging will be extended to other channels in the same spw as the displayed point. For example, if spw='0:0' and channel 0 is displayed, then flagging will extend to all channels in spw 0.\n",
    "\n",
    "The **plotms** task parameter used to extend flags is *extendflag* (True/False, default is False) with subparameters *extcorr* (True/False), and *extchannel* (True/False).  These parameters will enable flag extensions when interactively flagging the plot.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Interactive Tools: The Tools Tab, Annotate Tab, and Tool Icons \n",
    "\n",
    "[![5805a63e175751d3cece5510c839490bd34ec9f4](media/5805a63e175751d3cece5510c839490bd34ec9f4.png){.image-inline}]{\n",
    "\n",
    ">The plotms Tools tab.  Here the Tracker Display tool is showing the (X,Y) coordinates of the cursor position.  A previous position was saved to the text box by pressing the SPACE bar.\n",
    "  \n",
    "\n",
    "Various interactive GUI tools are selectable with the radio buttons in the *Hand Tools* section of the *Tools *tab at the top of the **plotms** window.  They are also available as icon buttons at the bottom of the **plotms** window.  These tools can be used to zoom, pan, annotate, flag/unflag, and locate data.  Described below are the bottom icon buttons in order.\n",
    "\n",
    "[![30e7cfa63b3a09d8c6ed179f5c955109348d9360](media/30e7cfa63b3a09d8c6ed179f5c955109348d9360.png){.image-inline}]{\n",
    "\n",
    "-   \n",
    "    **Zoom** --- The \"magnifying glass\" button (1st on left) lets you draw a box around a region of the plot (left-click on one corner of the box, and drag the mouse to the opposite corner of the desired box), and then zooms in on this box.\n",
    "    \n",
    "\n",
    "-   \n",
    "    **Pan** --- The \"four-arrow\" button (2nd from left) lets you pan around a zoomed plot.\n",
    "    \n",
    "\n",
    "-   \n",
    "    **Annotate** --- The 3rd button from the left is chosen from a drop-down menu to either *Annotate Text* (\"T with a green diamond\" button) or *Annotate Rectangle* (\"pencil\" button). With *Annotate Text* activated, click on a location in the plot where text is desired; a window will pop up, allowing you to type text in it. When you click the OK button, this text will appear on the plot. *Annotate Rectangle* simply lets you draw a box on the plot by left-clicking and dragging the mouse. By clicking on the *Annotate* tab near the top of the **plotms** window, different fonts, colors, line \n",
    "\n",
    "-   \n",
    "    [**Flag** --- Click on the \"flag\" button (11th from left) to flag all points in the marked regions.  See the section below on [Interactive Flagging](#8--interactive-flagging).    ]{\n",
    "    \n",
    "\n",
    "-   \n",
    "    **Unflag** --- Click on the \"crossed-out flag\" button (12th from left) to unflag any flagged points in the marked regions (even if not displayed).\n",
    "    \n",
    "\n",
    "-   [**Flag All** --- Click on the \\\"per-grid flag/unflag\\\" button (13th from left) to enter/leave the \\\"Flag All\\\" mode. See the section below on [Interactive Flagging](#8--interactive-flagging).]{\n",
    "\n",
    "-   **Iteration **--- The next four green arrow buttons (14th through 17th from left) control iteration, with the first and last \\\"double arrow\\\" buttons used to display the first and last iteration, and the center two \\\"single arrow\\\" button to display the previous or next iteration.  If the plots are on a grid, these arrows navigate through the pages of plots which contain multiple iterations.\n",
    "\n",
    "-   \n",
    "    **Hold Drawing** --- If the *Hold Drawing* button (rightmost, or 18th from left) is clicked to activate it, when new plot axes are selected from the *Plot \\> Axes* tab, the new data will be cached but not plotted. When the button is clicked again (de-activated), it will automatically plot the data that was last requested. This can be particularly useful when changing the size of the **plotms** window.\n",
    "    \n",
    "\n",
    "The *Tools* tab also contains *Tracker* tools including *Hover* and *Display.*  When *Hover* is selected and the mouse is moved over the plot, the pointer\\'s position is displayed on the plot in (X, Y) format.  When *Display* is selected, the (X, Y) position is displayed in the text box under the *Display* checkbox.\n",
    "\n",
    "To record various tracked positions, enable *Display* then click on the plot to activate it.  As usual, moving the pointer displays the position in the small display text box.  Pressing the *SPACE* bar will copy the displayed line into the larger white box below it. This can be repeated many times and a log of positions and values will be created. The content in the box can then be easily copied and pasted into any other application that is used for data analysis. The *Clear* button wipes out the content of the box for a fresh start into new scientific adventures.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Miscellaneous Options: The Options Tab \n",
    "\n",
    "A few miscellaneous per-page plot options and GUI options are available in the *Options* tab, the last tab at the top of the **plotms** window.\n",
    "\n",
    "##### 4.1 Plotting on a Grid\n",
    "\n",
    "The layout of the page is set on the **plotms** *Options* tab. For multiple plots per page, set the grid layout, the number of rows and columns that determine the number of sub-plots.  When set, click \\\"Update\\\" to activate the grid changes.\n",
    "\n",
    "###### 4.1.1 Plotting Iterations on a Grid\n",
    "\n",
    " \n",
    "\n",
    "![43c10660168c9492aad849d60db2bf97d08411c0](media/43c10660168c9492aad849d60db2bf97d08411c0.png){.image-inline} \n",
    "\n",
    ">The plotms Options tab.  Here a 2x2 grid has been created with iteration on the \\'antenna\\' axis.\n",
    "  \n",
    "\n",
    "[If [iteration](#1-4-iteration--the-plot-page-tab) is enabled in the *Plot \\> Page* tab, the grid will be filled automatically with each iterated plot.  The *Plot \\> Page* tab is also where common axis scales and shared axes will be set; they are enabled for the plot in Figure 9.  These axis options are only available for iterated plots in a grid.]{\n",
    "\n",
    "The **plotms** task parameters used to create a grid with iteration include *gridrows and gridcols* (default is 1)*.* To create the plot shown in Figure 9, the **plotms** command would be:\n",
    "\n",
    "```\n",
    "plotms('ngc5921_ut.ms', xaxis='freq', iteraxis='antenna', gridrows=2, gridcols=2, xsharedaxis=True, xselfscale=True, ysharedaxis=True, yselfscale=True)\n",
    "```\n",
    "\n",
    "###### 4.1.2 Plotting Multiple Data on a Grid\n",
    "\n",
    "[We note here that plotting multiple datasets or axes on a grid is possible in **plotms** but covered separately in the [[[section below](#6-2-plotting-multiple-datasets-or-axes-on-a-grid), as this involves many settings in the GUI or multiple **plotms** task commands.  Since the grid affects all of the plots, its settings are in the *Options* tab rather than the *Plot* tab.]{]{]{\n",
    "\n",
    "##### 4.2 Tool Button Style \n",
    "\n",
    "The *Tool Button Style* drop-down menu determines the format of the tool buttons at the bottom of the **plotms** window. The options include *Icon Only, Text Only, Text Beside Icon, and Text Under* Icon.  In *Icon Only* mode (default), hovering the cursor over each icon will give a text description of the icon.\n",
    "\n",
    "[[To hide the bottom icons, see the description of the [View menu](#5-2-view-menu). The tools can also be accessed in the *Tools* tab.]{]{\n",
    "\n",
    "##### 4.3 Log Events \n",
    "\n",
    "This drop-down menu shows a checklist of events and **plotms** functions so that you can customize how verbose **plotms** is in documenting its actions.\n",
    "\n",
    "##### 4.4 Clear Regions and Annotations \n",
    "\n",
    "The *When changing plot axes, clear any existing regions or annotations* checkbox determines when regions and annotation are deleted from the plot. By default, this is enabled.\n",
    "\n",
    "##### 4.5 Cached Images \n",
    "\n",
    "A useful option is the *Use* *fixed size for cached image* checkbox. It determines how large the dots in the panel are with respect to the screen resolution. The values influence how the data is redrawn on the panel. When *Screen resolution* is selected, the **plotms** window can be resized without redrawing on the canvas -- a considerable speedup for large data sets. The penalty is that the dots of the data points are the size of a pixel on the screen, which may be very small for high resolution monitors.  By default, this feature is not enabled.\n",
    "\n",
    "##### 4.6 File Chooser History Limit \n",
    "\n",
    "This setting allows the user to limit how many remembered filepaths are displayed in file chooser dialogs produced by clicking *Browse* in the *Plot \\> Data* tab to select a MeasurementSet or calibration table and in the *Plot \\> Calibration* tab to select a calibration library.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. The plotms Menus  \n",
    "\n",
    "##### 5.1 File Menu: Quit \n",
    "\n",
    "The *File* menu in the top menu bar allows you to *Quit* **plotms**, or you can click the *X in the upper right corner of the window.*\n",
    "\n",
    "##### 5.2 Export Menu: Saving Your Plot \n",
    "\n",
    "You can save a copy of a plot to file with the *Export* menu, which produces an *Export Plots* dialog box with many settings.\n",
    "\n",
    "-   **Filename**: Click the *Browse* button for a GUI-based selection of the directory and filename to which the plot will be saved, or click the *Insert MS Name* button to minimize typing. You may also just type in a file name. The file format can be determined in this GUI by the suffix given to the filename: .png, .jpg, .ps, .pdf, and txt. \n",
    "    <div class=\"alert alert-warning\">\n",
    "    If a file already exists with the given filename, it will be overwritten without warning!\n",
    "    </div>\n",
    "-   **Format**: Alternatively, the file format can be selected from the *Format*[ drop-down menu, with these options: \\[by file extension\\], PNG, JPG, PS, PDF, and TEXT]{. For the first option, if your filename is \\\"test.jpg\\\" the plot will be exported in JPG format.  For the other formats, **plotms** will use the filename as given and **not** add a suffix to indicate its format. See below for an example of TEXT format; the header will include the name of the visibility and other specified parameters including selection, averaging, transformations, etc.    \n",
    "-   **Verbose**: When a text export is selected, the output can be verbose (include metadata).  When this checkbox is unchecked, the text export will include x and y values only.  This parameter is ignored for other formats.\n",
    "-   **Range**: When iteration is chosen, producing multiple plots, you may select to export only the *Current Page* or A*ll Pages***.**  Each saved plot will have the name of the iteration appended to the given filename before the extension.  For example, with filename \\\"ngc5921_ut.jpg\\\" and iteration on antenna, the first plot will be named \\\"ngc5921_ut_Antenna1\\@VLA:N7.jpg\\\".  This is so the exported plots can be identified without viewing them.  Be warned that if you are plotting iterations on a grid, the filenames will have all of the iterations on the page appended, which can lead to a very long filename. Filenames exceeding 255 characters in length will be automatically shortened upon export. One plotfile per page is produced; multipage pdf exports are not currently supported.    \n",
    "-   **High Resolution:** Exporting to images in screen resolution is currently not working, so plot exports are always high resolution.  A notice is issued in the console/log.\n",
    "-   **DPI, Size**: Use the text boxes or up/down arrows to set the output DPI or size (in pixels) of the exported plot.\n",
    "-   **Export**: When settings are complete, click *Export* to create your plotfile.\n",
    "\n",
    "Note: The plot files produced by the PS and PDF options can be large and time-consuming to export. The JPG is the smallest.\n",
    "\n",
    "The TEXT format will not save an image but all of the data points themselves. This allows one to dump the current plot into a file that is used in other programs for further processing. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT**: The exported TEXT file can be quite large and take some time to create.  Using averaging, selection, etc. is recommended to keep the file size manageable.  If a region is marked as described in section 3, only those points are exported to the text file.\n",
    "\n",
    "</div>\n",
    "\n",
    "The reported data is the same as when using the *L**ocate* button in **plotms**, with the following format (when *verbose=True*):\n",
    "\n",
    "```python\n",
    "#vis: ngc5921_ut.ms\n",
    "#scan: 4\n",
    "#channel average: 63\n",
    "#time average: None\n",
    "#From plot 0\n",
    "#x y chan scan field ant1 ant2 ant1name ant2name time freq spw corr obs\n",
    "#Time Amp None None None None None None None MJD(seconds) GHz None None None\n",
    "4304483429.999 62.7219 0 4 1 1 1 2@VLA:W1 2@VLA:W1 4304483429.999 1.413332233 0 RR 0\n",
    "4304483429.999 59.0717 0 4 1 1 1 2@VLA:W1 2@VLA:W1 4304483429.999 1.413332233 0 LL 0\n",
    "4304483429.999 59.0252 0 4 1 27 27 28@VLA:W7 28@VLA:W7 4304483429.999 1.413332233 0 RR 0\n",
    "4304483429.999 60.8603 0 4 1 27 27 28@VLA:W7 28@VLA:W7 4304483429.999 1.413332233 0 LL 0\n",
    "4304483429.999 57.4048 0 4 1 7 7 8@VLA:W8 8@VLA:W8 4304483429.999 1.413332233 0 RR 0\n",
    "etc.\n",
    "```\n",
    "\n",
    "where x and y are the two plotted axes and the other columns contain additional information such as the baselines and frequencies, with an additional line for units.  The header for the file includes the name of the visibility and other parameters such as selection, averaging, etc.\n",
    "\n",
    "The **plotms** task parameter used to export plots is *plotfile.*  Unlike the Export Plots dialog box in the GUI, **plotms** will issue an error if this file exists unless *overwrite=True*.  Its subparameters include:\n",
    "\n",
    "-    *expformat* (\\'jpg\\', \\'png\\', \\'pdf\\', \\'ps\\', \\'txt\\') - select the format if no extension is included in the *plotfile*. If there is no *plotfile* extension and no *expformat* set, the plot will be exported as a PNG.    \n",
    "-   verbose (True/False, default is True) - include metadata in text export; ignored for other formats.\n",
    "-   *exprange *(\\'current\\', \\'all\\'; defaults to current)    \n",
    "-   *highres* (True/False, default is False)    \n",
    "-   *dpi*\n",
    "-   *width* (in pixels)\n",
    "-   *height* (in pixels)\n",
    "-   *overwrite* (True/False, default is False)\n",
    "\n",
    "##### 5.3 Summary Menu: Information About Your Dataset \n",
    "\n",
    "Information about the MeasurementSet can be obtained from within **plotms** by clicking on the *Summary* menu in the top menu bar. If *All* is chosen from the pull-down menu next to *Type*, listobs-\n",
    "\n",
    "[![459e57c04e9d444fff7936b9bef64eb0ac3c652d](media/459e57c04e9d444fff7936b9bef64eb0ac3c652d.png){.image-inline}]{\n",
    "\n",
    ">Plotting multiple data sets on a 2x1 grid.  Here, the MS is plotted in grid location (1,1).  Then the *Add Plot* button was used to select its bandpass calibration table and plot it in grid location (2,1).\n",
    "  \n",
    "\n",
    "The process is similar to the one above, except that you specify the grid  and each plot\\'s location:\n",
    "\n",
    "1.  Set up your first plot as described above.\n",
    "2.  Use the *Options* tab to set up a grid by incrementing the number of rows and/or columns.  By default the plot you set up in step 1 will be in row 0, column 0.\n",
    "3.  Use the *Add Plot* button to set up the second plot\\'s parameters. Pay particular attention to the new dataset\\'s *Page* tab, where you can set the *Grid Location* (row and column number) of the new plot.  This section appears only when a grid is set up.\n",
    "4.  Unlike iteration, you cannot share axes among the plots.\n",
    "5.  Add as many plots as you desire to fill your grid, then click *Plot.*\n",
    "\n",
    "Several **plotms** task parameters are used to create a grid and specify a plot location.\n",
    "\n",
    "-   gridcols and gridrows define the number of plots on the screen.\n",
    "-   colindex and rowindex (0-based) set the location of an individual plot\n",
    "-   plotindex (0-based) must be incremented by 1 for each **plotms** call\n",
    "-   *clearplots* is set to False to keep previous plots\n",
    "\n",
    "Here is an example of multiple **plotms** calls to set up two plots on a grid and export the plot page; note the defaults on the first call are *rowindex=0, colindex=0, plotindex=0* so just set up the grid.  On each subsequent **plotms** call set *clearplots=False* and increment the *plotindex* by 1*. * To save the gridded plot, set a *plotfile* on the final plot.\n",
    "\n",
    "```\n",
    "plotms(vis='test1.ms', yaxis='field', gridrows=2, gridcols=1)\n",
    "plotms(vis='test2.ms', yaxis='field', gridrows=2, gridcols=1, rowindex=1, colindex=0, plotindex=1, clearplots=False, plotfile='fields.jpg')\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Interactive Flagging\n",
    "\n",
    "Interactive flagging, on the principle of \"see it --- flag it\", is possible on the X-Y display of the data plotted by **plotms**[. Use the cursor to mark one or more regions, and then flag, unflag, or list ([*Locate*](#3--interactive-tools--the-tools-tab--annotate-tab--and-tool-icons)) the data that falls in these regions of the display.]{\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Do not attempt to flag data while another task is accessing the same data set.\n",
    "</div>\n",
    "\n",
    "For plotting, **plotms** opens the MeasurementSet read-only, so there should be no problem if another task accesses the same dataset, unless the other task locks the file.  When this happens, you can wait for the lock to be released, cancel cache-loading in the **plotms** dialog box, type *go clearstat* at the prompt, or exit **plotms.** Do not attempt to flag data in **plotms** while another task is accessing the same data set, as in this case **plotms** must open the MeasurementSet with a file lock for writing.\n",
    "\n",
    "Using the row of icons at the bottom of the **plotms** window, click on the *Mark Regions* button, then mark a region by left-clicking and dragging the mouse.  Each click and drag will mark an additional region. You can remove all of your marked regions by clicking on the *Clear Regions* button. Once regions are marked, you can then click on one of the other buttons to take action:\n",
    "\n",
    "1.  Flag --- flag all of the points in the region(s),\n",
    "2.  Unflag --- unflag flagged points in the region(s),\n",
    "3.  Locate --- list information (X and Y value, scan, field, baseline, frequency, etc.) about the points in the region(s) to the command line or log (Warning: this could be a long list!).\n",
    "\n",
    "Note that if you mark a region with flagged and unflagged values and *Flag* it, using *Unflag* will not return the data to its previous state but will unflag **all** of the data in the marked region.\n",
    "\n",
    "The following figure shows an example of marking regions and then clicking the *Flag* button. Whenever you click on a button, that action occurs without requiring an explicit disk-write. If you quit **plotms** and re-enter, you will see your previous edits because your flag changes were written to the MeasurementSet on disk.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "[![552927ba046380032eabbec06584e6ff325f72fa](media/552927ba046380032eabbec06584e6ff325f72fa.png)![a8a4487709d848f87a6f179713f2e352e6e9629e](media/a8a4487709d848f87a6f179713f2e352e6e9629e.png)]{\n",
    "\n",
    ">Plot of amplitude versus time, before (top) and after (bottom) flagging two marked regions. Note that flagged data is not displayed so these regions are hidden after flagging.  To unflag these regions, mark the two same regions and click the *Unflag* button.\n",
    "  \n",
    "\n",
    " \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "New interactive flagging is available in CASA 5.5 and later. You have a new button **Flag All**, which is located next to the **Unflag **button, and can turn on and off \\\"Flag all/Unflag all\\\" mode by clicking it. Instead of flag/unflag operation on selected region, the \\\"Flag all/Unflag all\\\" mode allows you to flag/unflag whole data associated with the grid. The usage of this mode is as follows:\n",
    "\n",
    "1.  Press the **Flag All** button \\-- You now enter the \\\"Flag all/Unflag all\\\" mode. Background color of completely flagged grids will become yellow.    ![3b74be06ff6033999651a736383d8c89a40d4764](media/3b74be06ff6033999651a736383d8c89a40d4764.png){.image-inline}2.  Select grids to flag/unflag \\-- You can click each grid to select for flag/unflag when the mode is active. Unflag is selected for the grids where all data are already flagged, otherwise flag is selected. The background color of the grids selected for flag will change to yellow while the grids selected for unflag will change to the default color.        ![d41e5bbb0ae5ed277f736d63ba4cc3f3aee5d0e5](media/d41e5bbb0ae5ed277f736d63ba4cc3f3aee5d0e5.png){.image-inline}3.  Press the **Flag All** button again \\-- You now leave the \\\"Flag all/Unflag all\\\" mode. At this moment, flag/unflag operations are applied to the data of the currently displayed grids selected in the previous step, and each grid is updated accordingly.     ![b917ed2b75f2a0f8cf8451329a2360ba613c9dda](media/b917ed2b75f2a0f8cf8451329a2360ba613c9dda.png){#__mcenew .image-inline}\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**WARNING:**  On macOS, the \"Flag all/Unflag all\" mode doesn't work as expected!\n",
    "</div>\n",
    "\n",
    "On macOS, background color of grids doesn\\'t yet change properly although flag/unflag operations work fine. It is not recommended to use this mode on macOS.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**WARNING:**  You cannot \"undo\" flagging to a previous state!\n",
    "</div>\n",
    "\n",
    "**plotms** does not automatically create flag backups in the \\<msname\\>.flagversions file. It is thus recommended to save the initial flags with the flagmanager task before starting **plotms** interactive flagging. Important intermediate flagging stages may also be saved during **plotms** flagging in the same fashion.  Flagging can also be performed using the interactive msview task or scripted with the flagdata or flagcmd tasks.\n",
    "\n",
    "Flags can also be extended with options in the *[Flag* tab;](#2--flag-extensions--the-flag-tab) see this section for a more detailed description of these options. Flag extension enables the user to plot a subset of the data and extend the flagging to a wider set. In this release, the only functional extensions are over correlation and channel.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "WARNING:  Use of flag extensions may lead to deletion of much more data than desired. Be careful!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "WARNING:  Interactive flagging doesn't support a collaboration with **Iteration** buttons! \n",
    "</div>\n",
    "\n",
    "The flag/unflag operations are applied to currently displayed grids only, although you can move to other iterations in the \\\"Flag all/Unflag all\\\" mode.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Scripting With No GUI\n",
    "\n",
    "When scripting to produce exported plotfiles, you may want to set the **plotms** parameter *showgui=False* to suppress the GUI and pop-up dialog boxes.  The default is True.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Exiting **plotms** \n",
    "\n",
    "To exit the **plotms** GUI, select *Quit* from the *File* menu at the top of the **plotms** window. You can also dismiss the window by killing it with the \"X\" on the frame.\n",
    "\n",
    "Alternatively, you can just leave it alone, and **plotms** will keep running in the background and update with each subsequent **plotms** call. If the data file changes in the background while you are using other tasks, you can force reloading the data via the *Reload* checkbox next to the *Plot* button, or press SHIFT while clicking on *Plot* for the same purpose.\n",
    "\n",
    "If started in a casa session, **plotms** will automatically quit when the session is ended.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag using flagdata \n",
    "\n",
    "Flagging MeasurementSets and calibration tables\n",
    "\n",
    "**flagdata** is the main flagging task in CASA. **flagdata** can flag MeasurementSets and calibration tables with an elaborate selection syntax. It also contains auto-flagging routines.\n",
    "\n",
    " \n",
    "\n",
    "Other tasks related to flagging are **flagmanager** to save the existing flags before adding more, and  **plotms** and **msview** for interactive flagging. In addition, optionally, data for which calibration solutions have failed will be flagged when these solutions are applied.\n",
    "\n",
    " \n",
    "\n",
    "The inputs to **flagdata** are:\n",
    "\n",
    "```\n",
    "#In CASA\n",
    "CASA<1>: inp flagdata\n",
    "#flagdata :: All-purpose flagging task based on data-selections and flagging modes/algorithms.\n",
    "vis              = ''          #Name of MS file or calibration table to flag\n",
    "mode             = 'manual'    #Flagging mode\n",
    "     field       = ''          #Field names or field index numbers: '' ==> all, field='0~2,3C286'\n",
    "     spw         = ''          #Spectral-window/frequency/channel: '' ==> all, spw='0:17~19'\n",
    "     antenna     = ''          #Antenna/baselines: '' ==> all, antenna ='3,VA04'\n",
    "     timerange   = ''          #Time range: '' ==> all,timerange='09:14:0~09:54:0'\n",
    "     correlation = ''          #Correlation: '' ==> all, correlation='XX,YY'\n",
    "     scan        = ''          #Scan numbers: '' ==> all\n",
    "     intent      = ''          #Observation intent: '' ==> all, intent='CAL*POINT*'\n",
    "     array       = ''          #(Sub)array numbers: '' ==> all\n",
    "     uvrange     = ''          #UV range: '' ==> all; uvrange ='0~100klambda', default units=meters\n",
    "     observation = ''          #Observation ID: '' ==> all\n",
    "     feed        = ''          #Multi-feed numbers: Not yet implemented\n",
    "     autocorr    = False       #Flag auto-correlations\n",
    "\n",
    "action           = 'apply'     #Action to perform in MS and/or in inpfile (none/apply/calculate)\n",
    "     display     = ''          #Display data and/or end-of-MS reports at runtime (data/report/both).\n",
    "     flagbackup  = True        #Back up the state of flags before the run\n",
    "\n",
    "savepars         = False       #Save the current parameters to the FLAG_CMD table or to a file\n",
    "```\n",
    "\n",
    "vis can take a MeasurementSet or calibration table. Data selection for calibration tables is limited to field, scan, time, antenna, spw, and observation. See section at end about which parameters are applicable for calibration tables. Since calibration tables do not have a *FLAG_CMD* table, parameter settings, if requested, can only be saved in external files. \n",
    "\n",
    "\n",
    "##### The *mode* parameter \n",
    "\n",
    "The mode parameter selects the flagging algorithm and the following are available:\n",
    "\n",
    "``` {.verbatim}\n",
    "list        = list of flagging commands to apply to MS\n",
    "manual      = flagging based on specific selection parameters\n",
    "clip        = clip data according to values\n",
    "quack       = remove/keep specific time range at scan beginning/end\n",
    "shadow      = remove antenna-shadowed data\n",
    "elevation   = remove data below/above given elevations\n",
    "tfcrop      = automatic identification of outliers on the time-freq plane\n",
    "rflag       = automatic detection of outliers based on sliding-window RMS filters\n",
    "antint      = flag integrations if all baselines to a specified antenna are flagged\n",
    "extend      = extend and/or grow flags beyond what the basic algorithms detect\n",
    "summary     = report the amount of flagged data\n",
    "unflag      = unflag the specified data\n",
    "```\n",
    "\n",
    "these are described in detail lower down.\n",
    "\n",
    "Flagging will only be applied to the data selection that is performed with the usual selection parameters. The dataset is iterated-through in chunks (small pieces of data) consisting of one field, one spw, and a user-defined timerange (default is one scan). In addition to the typical antenna, spw, timerange, etc. selections, we would like to point out some addition of the correlation syntax for modes clip, tfcrop, and  rflag. One can combine correlation products with simple mathematical expressions \n",
    "\n",
    "``` {.verbatim}\n",
    "'ABS', 'ARG', 'RE', 'IM', 'NORM' \n",
    "```\n",
    "\n",
    "where *ABS* is the absolute value, *RE*, the real and *IM* the imaginary part. *NORM* and *ARG* refer to the amplitude and phase. This parameter is followed by the polarization products (using an underscore in between \"\\_\" )\n",
    "\n",
    "``` {.verbatim}\n",
    "'ALL', 'I', 'XX', 'YY', 'RR', 'LL', 'WVR' \n",
    "```\n",
    "\n",
    "'WVR' refers to the water vapour radiometer of ALMA data. Note that the operators ABS,ARG,RE, etc. are written only once as the first value. if more than one correlation is given, the operator will be applied to all of them. An example would be \n",
    "\n",
    "```\n",
    "correlation = 'RE_XX, XY'\n",
    "```\n",
    "\n",
    "which would select all real XX and XY polarization for flagging. \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### The *action* parameter \n",
    "\n",
    "The parameter action controls whether the actual flagging commands will be applied or not and the options are the empty string \", 'apply' and 'calculate'.\n",
    "\n",
    "apply is likely the most popular one as it applies the flags to the MS:\n",
    "\n",
    "```\n",
    "#In CASA:\n",
    "action = 'apply' #Action to perform in MS and/or in inpfile\n",
    "#(none/apply/calculate)\n",
    "display = '' #Display data and/or end-of-MS reports at runtime\n",
    "#(data/report/both).\n",
    "flagbackup = True #Back up the state of flags before the run\n",
    "```\n",
    "\n",
    "flagbackup specifies if a backup of the current flags should be saved in the \"\\*.flagversions\" file. display can be  \", 'data', 'report', 'both' where the empty string \" will report no individual flagging statistics, whereas 'data' launches an interactive GUI to display data and flags for each chunk to browse through. The plots are time-frequency planes and both old and new flags are being overlaid for all correlations per baseline. In the GUI, one can step though all chunks for inspection and if the flagging is unsatisfactory, one can exit without applying the flags. If the flagging is acceptable, it is also possible to continue flagging without viewing all chunks (the number of chunks can be very large for typical JVLA and ALMA data sets. display='report' lists the flagging statistics at the end of the procedure on the screen and  both starts the GUI and reports all statistics at the end.\n",
    "\n",
    "action='calculate' calculates the flags but does not write them to the MS or calibration table. This is useful if one would like to inspect the computed flags in the GUI without a straight application:\n",
    "\n",
    "```\n",
    "action  = 'calculate' #Action to perform in MS and/or in inpfile (none/apply/calculate)\n",
    "display = ''          #Display data and/or end-of-MS reports at runtime (data/report/both).\n",
    "```\n",
    "\n",
    "The empty string action=\" will do nothing and is useful when the commands themselves shall only be written to the FLAG_CMD sub-table or to an external file using the savepars parameter to specify the filename.\n",
    "\n",
    "savepars will save the flagging commands to a file that can be later used for input in flagdata via mode='list'. It also shares the flagcmd syntax and can be used there. The file name is specified by outfile and, if empty, the FLAG_CMD table in the MS will be populated. A REASON can be given by the  reason parameter which may be useful for bookkeeping as well as for unflagging data that are marked by specific REASON parameters. The overwrite parameter will control overwriting an existing file when saving the flag commands.\n",
    "\n",
    "\n",
    "##### Flagging Modes \n",
    "\n",
    "###### Manual Flag/Unflag \n",
    "\n",
    "```\n",
    "mode = 'manual' #Flagging mode (list/manual/clip/shadow/quack/el\n",
    "#evation/tfcrop/rflag/extend/unflag/summary)\n",
    "field = '' #Field names or field index numbers: '' ==> all,\n",
    "#field='0~2,3C286'\n",
    "spw = '' #Spectral-window/frequency/channel: '' ==> all,\n",
    "#spw='0:17~19'\n",
    "antenna = '' #Antenna/baselines: '' ==> all, antenna\n",
    "#='3,VA04'\n",
    "timerange = '' #Time range: '' ==>\n",
    "#all,timerange='09:14:0~09:54:0'\n",
    "correlation = '' #Correlation: '' ==> all, correlation='XX,YY'\n",
    "scan = '' #Scan numbers: '' ==> all\n",
    "intent = '' #Observation intent: '' ==> all,\n",
    "#intent='CAL*POINT*'\n",
    "array = '' #(Sub)array numbers: '' ==> all\n",
    "uvrange = '' #UV range: '' ==> all; uvrange ='0~100klambda',\n",
    "#default units=meters\n",
    "observation = '' #Observation ID: '' ==> all\n",
    "feed = '' #Multi-feed numbers: Not yet implemented\n",
    "autocorr = False #Flag auto-correlations\n",
    "```\n",
    "\n",
    "The 'manual' mode is the most straight-forward of all modes. All visibilities that are selected by the various data selection parameters will be flagged or unflagged, depending on the  action parameter. autocorr is a shorthand for  antenna='\\*&&&' to flag all auto correlations in the data.\n",
    "\n",
    " \n",
    "\n",
    "###### List \n",
    "\n",
    "```\n",
    "mode = 'list' #Flagging mode (list/manual/clip/shadow/quack/el\n",
    "#evation/tfcrop/rflag/extend/unflag/summary)\n",
    "inpfile = '' #Input ASCII file, list of\n",
    "#files or Python list of strings with\n",
    "\n",
    "#flag commands.\n",
    "reason = 'any' #Select by REASON types\n",
    "```\n",
    "\n",
    "A list of flag commands can be provided through a file or a list of files, specified by the inpfile parameter. Each input line may contain a flagging mode with data selection parameters as well as parameters that are specific to that mode. All parameters that are not set will be reset to their default values (default  mode is 'manual'). Each line of this file or list of strings will be taken as a command to the flagdata task. This  mode='list' is similar to the task flagcmd with the  inpmode='list' option.\n",
    "\n",
    "An example for such a file would be: \n",
    "\n",
    "``` {.verbatim}\n",
    "mode='shadow'\n",
    "mode='clip' clipminmax=[0,5] correlation='ABS_ALL'\n",
    "mode='quack' quackmode='end' quackinterval=1.0\n",
    "antenna='ea01' timerange='00:00:00~01:00:00'\n",
    "antenna='ea11' timerange='00:00:00~03:00:00' spw='0~4'\n",
    "```\n",
    "\n",
    "Alternatively, this can be issued in the task directly like:\n",
    "\n",
    "```\n",
    "#In CASA:\n",
    "CASA<1>: flagdata(vis='vis',mode='list',\n",
    "inpfile=[\"mode='shadow'\",\n",
    "\"mode='clip' clipminmax=[0,5] correlation='ABS_ALL'\",\n",
    "\"mode='quack' quackmode='end' quackinterval=1.0\"'\n",
    "\"antenna='ea01' timerange='00:00:00~01:00:00'\",\n",
    "\"antenna='ea11' timerange='00:00:00~03:00:00' spw='0~4'\"])\n",
    "```\n",
    "\n",
    "  or via a variable \n",
    "\n",
    "```\n",
    "#In CASA:\n",
    "CASA<1>:cmds=[\"mode='shadow',\n",
    "\"mode='clip' clipminmax=[0,5] correlation='ABS_ALL'\",\n",
    "\"mode='quack' quackmode='end' quackinterval=1.0\",\n",
    "\"antenna='ea01' timerange='00:00:00~01:00:00'\",\n",
    "\"antenna='ea11' timerange='00:00:00~03:00:00' spw='0~4'\"]\n",
    "\n",
    "CASA<2>: flagdata(vis='vis',mode='list', inpfile=cmds)\n",
    "```\n",
    "\n",
    "The syntax needs to be written with quotes e.g. mode='manual' antenna='ea10'. There should be no space between key=value. Spaces are used to separate pairs of parameters, not commas.\n",
    "\n",
    " \n",
    "\n",
    "###### Clip \n",
    "\n",
    "```\n",
    "mode = 'clip' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary)\n",
    "...\n",
    "datacolumn = 'DATA' #Data column on which to operate\n",
    "#(data,corrected,model,residual)\n",
    "clipminmax = [] #Range to use for clipping\n",
    "clipoutside = True #Clip outside the range, or within it\n",
    "channelavg = False #Average over channels (scalar average)\n",
    "timeavg = False #Average over time ranges\n",
    "timebin = '' #Bin width for time averaging.\n",
    "clipzeros = False #Clip zero-value data\n",
    "```\n",
    "\n",
    "in addition to the regular selection parameters, mode='clip' also has an option to select between a number of scratch columns in datacolumn. This includes the usual DATA, CORRECTED, etc., and also clipping based on data weights WEIGHT,  WEIGHT_SPECTRUM as well as other MS columns. clipminmax selects the range of values to be clipped -- usually this is combined with  clipoutside=True to clip everything but the values covered in clipminmax. The data can also be averaged over the selected  spw channel ranges by setting channelavg=True, or time averages via timeavg=True and setting of timebin. clip will also flag 'NaN', 'inf', and '-inf' values by default and can flag exact zero values (these are sometimes produced by the JVLA correlator) using the clipzeros parameter.\n",
    "\n",
    "Note : For modes clip, tfcrop and rflag, channel-ranges can be excluded from flagging by selecting ranges such as  spw='0:05;1063'. This is a way to protect known spectral-lines from being flagged by the autoflag algorithms.\n",
    "\n",
    " \n",
    "\n",
    "###### Shadow \n",
    "\n",
    "```\n",
    "mode = 'shadow' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary)\n",
    "...\n",
    "tolerance = 0.0 #Amount of shadow allowed (in meters)\n",
    "addantenna = '' #File name or dictionary with additional antenna names,\n",
    "#positions and diameters\n",
    "```\n",
    "\n",
    "This option flags shadowed antennas, i.e. when one antenna blocks part of the aperture of a second antenna that is behind the first one. Shadowing can be gradual and the criterion for a shadow flag is when a baseline is shorter than radius~1~ + radius~2~ − tolerance (where the radii of the antennae are taken from the MS antenna subtable); see the figure below. addantenna may be used to account for shadowing when antennas are not listed in the MS but are physically present. Please read the flagdata inline help for the syntax of this option.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "[ ![1549b953275f8856b049cd09f60d19c320b125b8](media/1549b953275f8856b049cd09f60d19c320b125b8.png)]{\n",
    "\n",
    "  -------------------------------------------------------------------------------------------------\n",
    "  This figure shows the geometry used to compute shadowed antennas.\n",
    "  -------------------------------------------------------------------------------------------------\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "###### Quack\n",
    "\n",
    "```\n",
    "mode = 'quack' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary)\n",
    "...\n",
    "quackinterval = 0.0 #Quack n seconds from scan beginning or end\n",
    "quackmode = 'beg' #flag an interval at the beginning of scan\n",
    "'endb' #flag an interval at the end of scan\n",
    "'tail' #flag all but an interval at the beginning of\n",
    "scan\n",
    "'end' #flag all but an interval at end of scan\n",
    "\n",
    "quackincrement = False #Flag incrementally in time?\n",
    "```\n",
    "\n",
    "quack is used to remove data at scan boundaries.  quackinterval specifies the time in seconds to be flagged, and  quackmode can be 'beg' to flag the quackinterval at the beginning of each selected scan, 'endb' at the end of scan.  'tail' flags all but the beginning of scan and 'end' all but the end of scan. The quackincrement is either True or  False, depending if one wishes to flag the quackinterval from the first unflagged data in the scan, or from the scan boundaries independent of data being already flagged or not.\n",
    "\n",
    " \n",
    "\n",
    "Because *quackincrement=True* needs to know the state of the previous flags in order to know which is the first unflagged data, it cannot be used in \\'list\\' mode, unless it is the first command of the list.\n",
    "\n",
    "```python\n",
    "Visual representation of quack mode when flagging a scan\n",
    "with 1s duration. The following diagram shows what is flagged\n",
    "for each quack mode when quackinterval is set to 0.25s.\n",
    "The flagged part is represented by crosses (+++++++++)\n",
    "\n",
    "scan with 1s duration\n",
    "\n",
    "--------------------------------------------\n",
    "beg\n",
    "+++++++++++---------------------------------\n",
    "endb\n",
    "---------------------------------+++++++++++\n",
    "tail\n",
    "-----------+++++++++++++++++++++++++++++++++\n",
    "end\n",
    "+++++++++++++++++++++++++++++++++-----------\n",
    "```\n",
    "\n",
    "\n",
    "###### Elevation \n",
    "\n",
    "```\n",
    "mode = 'elevation' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary)\n",
    "...\n",
    "lowerlimit = 0.0 #Lower limiting elevation (in degrees)\n",
    "upperlimit = 90.0 #Upper limiting elevation (in degrees)\n",
    "```\n",
    "\n",
    "Flagging based on the elevation of the antennae. This may be useful to avoid data taken at very low elevations or close to transit and the lowerlimit and upperlimit parameters specify the range of good elevations.\n",
    "\n",
    "\n",
    "###### Tfcrop \n",
    "\n",
    "```\n",
    "mode = 'tfcrop' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary\n",
    "#)\n",
    "...\n",
    "ntime = 'scan' #Time-range to use for each chunk (in seconds\n",
    "#or minutes)\n",
    "combinescans = False #Accumulate data across scans.\n",
    "datacolumn = 'DATA' #Data column on which to operate\n",
    "#(data,corrected,model,residual)\n",
    "timecutoff = 4.0 #Flagging thresholds in units of deviation\n",
    "#from the fit\n",
    "freqcutoff = 3.0 #Flagging thresholds in units of deviation\n",
    "#from the fit\n",
    "timefit = 'line' #Fitting function for the time direction\n",
    "#(poly/line)\n",
    "freqfit = 'poly' #Fitting function for the frequency direction\n",
    "#(poly/line)\n",
    "maxnpieces = 7 #Number of pieces in the polynomial-fits (for\n",
    "#'freqfit' or 'timefit' = 'poly')\n",
    "flagdimension = 'freqtime' #Dimensions along which to calculate fits\n",
    "#(freq/time/freqtime/timefreq)\n",
    "usewindowstats = 'none' #Calculate additional flags using sliding\n",
    "#window statistics (none,sum,std,both)\n",
    "halfwin = 1 #Half-width of sliding window to use with\n",
    "#'usewindowstats' (1,2,3).\n",
    "extendflags = True #Extend flags along time,\n",
    "#frequency and correlation.\n",
    "channelavg = False #Pre-average data across channels before\n",
    "#analyzing visibilities for flagging.\n",
    "chanbin = False #Bin width for channel average in\n",
    "#number of input channels.\n",
    "timeavg = False #Pre-average data across time before\n",
    "#analyzing visibilities for flagging\n",
    "timebin = False #Bin width for time average in seconds\n",
    "```\n",
    "\n",
    "TFCrop is an autoflag algorithm that detects outliers on the 2D time-frequency plane, and can operate on un-calibrated data (non bandpass-corrected). The original implementation of this algorithm is described in NCRA Technical Report 202 (Oct 2003).\n",
    "\n",
    "The algorithm iterates through the data in chunks of time. For each chunk, the result of user-specified visibility-expressions are organized as 2D time-frequency planes, one for each baseline and correlation-expression result, and the following steps are performed.\n",
    "\n",
    "As of CASA 4.6 the data can also be pre-averaged over the selected spw channel ranges by setting channelavg=True and chanbin to the desired bin (in number of channels), or time averaged over the selected time ranges by setting timeavg=True and timebin to the desired time range (in seconds). This averaging is independent from the tfcrop time/channel average, and allows to specify custom time/channel average bins, instead of averaging all data across time and/or channel direction.\n",
    "\n",
    "1.  Calculate a bandshape template : Average the data across time, to construct an average bandpass. Construct an estimate of a clean bandpass (without RFI) via a robust piece-wise polynomial fit to the average bandpass shape.\n",
    "\n",
    "    Note : A robust fit is computed in up to 5 iterations. It begins with a straight line fit across the full range, and gradually increases to 'maxnpieces' number of pieces with third-order polynomials in each piece. At each iteration, the stddev between the data and the fit is computed, values beyond N-stddev are flagged, and the fit and stddev are re-calculated with the remaining points. This stddev calculation is adaptive, and converges to a value that reflects only the data and no RFI. At each iteration, the same relative threshold is applied to detect flags, and this results in a varying set of flagging thresholds, that allows deep flagging only when the fit represents the true data best. Iterations stop when the stddev changes by less than 10%, or when 5 iterations are completed.\n",
    "\n",
    "    The resulting clean bandpass is a fit across the base of RFI spikes.\n",
    "\n",
    "2.  Divide out this clean bandpass function from all timesteps in the current chunk. Now, any data points that deviate from a mean of 1 can be considered RFI. This step helps to separate narrow-band RFI spikes from a smooth but varying bandpass, in situations where a simple range-based clipping will flag good sections of the bandpass.\n",
    "\n",
    "3.  Perform iterative flagging (robust flagging) of points deviating from a value of 1.\n",
    "\n",
    "    Flagging is done in up to 5 iterations. In each iteration, for every timestep, calculate the stddev of the bandpass-flattened data, flag all points further than N times stddev from the fit, and recalculate the stddev. At each iteration, the same relative threshold is applied to detect flags. Optionally, use sliding-window based statistics to calculate additional flags.\n",
    "\n",
    "4.  Repeat steps 1 and 3, but in the other direction (i.e. average the data across frequency, calculate a piece-wise polynomial fit to the average time-series, and find flags based on deviations w.r.to this fit.)\n",
    "\n",
    "The default parameters of the tfcrop implementation are optimized for strong narrow-band RFI (see the example figure below). With broad-band RFI, the piece-wise polynomial can sometimes model it as part of the band-shape, and therefore not detect it as RFI. In this case, reducing the maximum number of pieces in the polynomial can help. This algorithm usually has trouble with noisy RFI that is also extended in time of frequency, and additional statistics-based flagging is recommended (via the 'usewindowstats' parameter). It is often required to set up parameters separately for each spectral-window.\n",
    "\n",
    "If frequency ranges of known astronomical spectral lines are known  a-priori , they can be protected from automatic flagging by de-selecting those frequency-ranges via the 'spw' data-selection parameter.\n",
    "\n",
    "The extendflag parameter will clean up small portions of data between flagged data points along time and/or frequency when more than 50% of all timeranges or 80% of all channels are already flagged. It will also extend the flags to the other polarizations. Alternatively, mode='extend' can be used (see section below).\n",
    "\n",
    " \n",
    "\n",
    "[ ![ab85ff655f50ffc1e9b342b61fa9f82458aaf442](media/ab85ff655f50ffc1e9b342b61fa9f82458aaf442.png)]{\n",
    "\n",
    "  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  This screenshot represents a run where 'tfcrop' was run on a spw='9' with mainly narrow-band RFI. RIGHT : An example of protecting a spectral line (in this case, demonstrated on an RFI spike) by setting the spw-selection to spw='0:0 45;53 63'. In both figures, the top row indicates the data before flagging, and the bottom row after flagging.\n",
    "  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "> \n",
    ">\n",
    "> ------------------------------------------------------------------------\n",
    "> \n",
    "\n",
    "\n",
    "###### Rflag \n",
    "\n",
    "```\n",
    "mode = 'rflag' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary\n",
    "#)\n",
    "...\n",
    "ntime = 'scan' #Time-range to use for each chunk (in seconds\n",
    "#or minutes)\n",
    "combinescans = False #Accumulate data across scans.\n",
    "datacolumn = 'DATA' #Data column on which to operate\n",
    "#(data,corrected,model,residual)\n",
    "winsize = 3 #Number of timesteps in the sliding time\n",
    "#window [aips:fparm(1)]\n",
    "timedev = '' #Time-series noise estimate [aips:noise]\n",
    "freqdev = '' #Spectral noise estimate [aips:scutoff]\n",
    "timedevscale = 5.0 #Threshold scaling for timedev [aips:fparm(9)]\n",
    "freqdevscale = 5.0 #Threshold scaling for freqdev\n",
    "#[aips:fparm(10)]\n",
    "spectralmax = 1000000.0 #Flag whole spectrum if freqdev is greater\n",
    "#than spectralmax [aips:fparm(6)]\n",
    "spectralmin = 0.0 #Flag whole spectrum if freqdev is less than\n",
    "#spectralmin [aips:fparm(5)]\n",
    "extendflags = True #Extend flags along time, frequency and correlation.\n",
    "channelavg = False #Pre-average data across channels before\n",
    "#analyzing visibilities for flagging.\n",
    "chanbin = False #Bin width for channel average in\n",
    "#number of input channels.\n",
    "timeavg = False #Pre-average data across time before\n",
    "#analyzing visibilities for flagging\n",
    "timebin = False #Bin width for time average in seconds\n",
    "```\n",
    "\n",
    "RFlag is an autoflag algorithm based on a sliding window statistical filter. The RFlag algorithm was originally developed by Eric Greisen in AIPS (31DEC11). AIPS documentation : Subsection E.5 of the AIPS cookbook (Appendix E : Special Considerations for JVLA data calibration and imaging in AIPS[](https://casa.nrao.edu/casadocs-devel/docs/cookbook/casa_cookbook004.html#note3){#text3}, [[http://www.aips.nrao.edu/cook.html\\#CEE](http://www.aips.nrao.edu/cook.html#CEE))]{\n",
    "\n",
    "In RFlag, the data is iterated-through in chunks of time, statistics are accumulated across time-chunks, thresholds are calculated at the end, and applied during a second pass through the dataset.\n",
    "\n",
    "The CASA implementation also optionally allows a single-pass operation where statistics and thresholds are computed and also used for flagging, within each time-chunk (defined by 'ntime' and 'combinescans').\n",
    "\n",
    "For each chunk, calculate local statistics, and apply flags based on user supplied (or auto-calculated) thresholds.\n",
    "\n",
    "As of CASA 4.6 the data can also be pre-averaged over the selected spw channel ranges by setting channelavg=True and chanbin to the desired bin (in number of channels), or time averaged over the selected time ranges by setting timeavg=True and timebin to the desired time range (in seconds). This averaging is independent from the rflag time/channel sliding window, as it performs not only an average but also a binning operation (so there is no data overlap between adjacent bins), and allows to specify independent time/channel bins.\n",
    "\n",
    "1.  Time analysis (for each channel) \n",
    "    a.  Calculate local rms of real and imag visibilities, within a sliding time window \n",
    "    b.  Calculate the median rms across time windows, deviations of local rms from this median, and the median deviation \n",
    "    c.  Flag if local rms is larger than timedevscale x (medianRMS + medianDev) \n",
    "2.  Spectral analysis (for each time) \n",
    "    a.  Calculate avg of real and imag visibilities and their rms across channels \n",
    "    b.  Calculate the deviation of each channel from this avg, and the median-deviation \n",
    "    c.  Flag if deviation is larger than freqdevscale x medianDev \n",
    "\n",
    "The extendflags parameter will clean up small portions of data between flagged data points along time and/or frequency when more than 50% of all timeranges or 80% of all channels are already flagged. It will also extend the flags to the other polarizations. Alternatively, mode='extend' can be used.\n",
    "\n",
    "Some examples (see figure below):\n",
    "\n",
    "1.  Calculate thresholds automatically per scan, and use them to find flags. Specify scale-factor for time-analysis thresholds, use default for frequency.\n",
    "    ```\n",
    "    #In CASA:\n",
    "    CASA<1>: flagdata('my.ms', mode='rflag',spw='9',timedevscale=4.0)\n",
    "    ```\n",
    "\n",
    "2.  Supply noise-estimates to be used with default scale-factors.\n",
    "\n",
    "    ```\n",
    "    #In CASA:\n",
    "    CASA<1>: flagdata(vis='my.ms', mode='rflag', spw='9', timedev=0.1, freqdev=0.5);\n",
    "    ```\n",
    "\n",
    "    Two-passes. This replicates the usage pattern in AIPS. \n",
    "\n",
    "    -   The first pass saves commands in an output text files, with auto-calculated thresholds. Thresholds are returned from rflag only when action=\\'calculate\\' (calc-only mode). The user can edit this file before doing the second pass, but the python-dictionary structure must be preserved.\n",
    "    -   The second pass applies these commands (action=\\'apply\\').\n",
    "        ```\n",
    "        #In CASA:\n",
    "        CASA<1>: flagdata(vis='my.ms', mode='rflag', spw='9,10', timedev='tdevfile.txt', freqdev='fdevfile.txt', action='calculate');\n",
    "        CASA<2>: flagdata(vis='my.ms', mode='rflag', spw='9,10', timedev='tdevfile.txt', freqdev='fdevfile.txt', action='apply');\n",
    "        ```\n",
    "\n",
    "        \n",
    "\n",
    "        ------------------------------------------------------------------------\n",
    "        \n",
    "\n",
    "        \n",
    "        [ ![0897c13b6603be6efd68d97c7fc69171bef47cf6](media/0897c13b6603be6efd68d97c7fc69171bef47cf6.png)]{\n",
    "        \n",
    "          --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "          Example of rflag on narrow-band RFI\n",
    "          --------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "\n",
    "> \n",
    ">\n",
    "> ------------------------------------------------------------------------\n",
    "> \n",
    ">\n",
    "> \n",
    "> \n",
    ">  \n",
    "> \n",
    ">\n",
    "> \n",
    ">  \n",
    "> \n",
    "> \n",
    "\n",
    "###### Extend \n",
    "\n",
    "```\n",
    "mode = 'extend' #Flagging mode (list/manual/clip/shadow/quack/el\n",
    "#evation/tfcrop/rflag/extend/unflag/summary)\n",
    "field = '' #Field names or field index numbers: '' ==> all,\n",
    "#field='0~2,3C286'\n",
    "spw = '' #Spectral-window/frequency/channel: '' ==> all,\n",
    "#spw='0:17~19'\n",
    "antenna = '' #Antenna/baselines: '' ==> all, antenna\n",
    "#='3,VA04'\n",
    "timerange = '' #Time range: '' ==>\n",
    "#all,timerange='09:14:0~09:54:0'\n",
    "correlation = '' #Correlation: '' ==> all, correlation='XX,YY'\n",
    "scan = '' #Scan numbers: '' ==> all\n",
    "intent = '' #Observation intent: '' ==> all,\n",
    "#intent='CAL*POINT*'\n",
    "array = '' #(Sub)array numbers: '' ==> all\n",
    "uvrange = '' #UV range: '' ==> all; uvrange ='0~100klambda',\n",
    "#default units=meters\n",
    "observation = '' #Observation ID: '' ==> all\n",
    "feed = '' #Multi-feed numbers: Not yet implemented\n",
    "ntime = 'scan' #Time-range to use for each chunk (in seconds or\n",
    "#minutes)\n",
    "combinescans = False #Accumulate data across scans.\n",
    "extendpols = True #If any correlation is flagged, flag all\n",
    "#correlations\n",
    "growtime = 50.0 #Flag all 'ntime' integrations if more than X%\n",
    "#of the timerange is flagged (0-100)\n",
    "growfreq = 50.0 #Flag all selected channels if more than X% of\n",
    "#the frequency range is flagged(0-100)\n",
    "growaround = False #Flag data based on surrounding flags\n",
    "flagneartime = False #Flag one timestep before and after a flagged\n",
    "#one (True/False)\n",
    "flagnearfreq = False #Flag one channel before and after a flagged one\n",
    "#(True/False)\n",
    "```\n",
    "\n",
    "Although the modes tfcrop and rflag already have  extendflags parameters, some autoflagging algorithms may still leave small islands of unflagged data behind, data that are surrounded by flagged visibilities in the time-frequency space. Although the algorithm may deem these visibilities as good ones, they are frequently affected by low-level RFI that spills from the adjacent, flagged points and one may wish to clean those up.\n",
    "\n",
    "ntime specifies the time ranges over which to clean up, e.g. '1.5min' or 'scan' which checks on all data within a scan. To span time ranges larger than scans, one can set  combinescans to True.\n",
    "\n",
    "extendpols=True would extend all flags to all polarization products when at least one of them is flagged.\n",
    "\n",
    "growtime flags the entire time range for a flagged channel, when a certain fraction of flagged time intervals is exceeded. \n",
    "\n",
    "growfreq is similar but extends the flags in frequency when a given fraction of channels is already flagged.\n",
    "\n",
    "growaround checks for flagged data points in the time-frequency domain that neighbor a datum. The threshold is four data points. If more surrounding points are flagged, the central datum will be flagged, too.\n",
    "\n",
    "flagneartime flags adjacent data points along the time axis, around a flagged datum\n",
    "\n",
    "flagnearfreq flags neighboring channels. \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "[ ![ff49a17852eab157b2326e6879023523c60dba54](media/ff49a17852eab157b2326e6879023523c60dba54.png)]{\n",
    "\n",
    "  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "  This screenshot represents a run where 'tfcrop' was run only on 'ABS_RR' (top row) and followed by an extension along time and correlations (bottom row). \n",
    "  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "###### Unflag \n",
    "\n",
    "```\n",
    "mode = 'unflag' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary\n",
    "#)\n",
    "field = '' #Field names or field index numbers: ''==>all,\n",
    "#field='0~2,3C286'\n",
    "spw = '' #spectral-window/frequency/channel\n",
    "antenna = 'ea01' #antenna/baselines: ''==>all, antenna\n",
    "#='3,VA04'\n",
    "timerange = '' #time range:\n",
    "#''==>all,timerange='09:14:0~09:54:0'\n",
    "correlation = '' #Select data based on correlation\n",
    "scan = '' #scan numbers: ''==>all\n",
    "intent = '' #Select data based on observation intent:\n",
    "#''==>all\n",
    "feed = '' #multi-feed numbers: Not yet implemented\n",
    "array = '' #(sub)array numbers: ''==>all\n",
    "uvrange = '' #uv range: ''==>all; uvrange ='0~100klambda',\n",
    "#default units=meters\n",
    "observation = '' #Select data based on observation ID: ''==>all\n",
    "```\n",
    "\n",
    "The selection data will be unflagged. \n",
    "\n",
    "\n",
    "###### Summary \n",
    "\n",
    "```\n",
    "mode = 'summary' #Flagging mode (list/manual/clip/shadow/quack/\n",
    "#elevation/tfcrop/rflag/extend/unflag/summary\n",
    "#)\n",
    "...\n",
    "minrel = 0.0 #minimum number of flags (relative)\n",
    "maxrel = 1.0 #maximum number of flags (relative)\n",
    "minabs = 0 #minimum number of flags (absolute)\n",
    "maxabs = -1 #maximum number of flags (absolute). Use a\n",
    "#negative value to indicate infinity.\n",
    "spwchan = False #Print summary of channels per spw\n",
    "spwcorr = False #Print summary of correlation per spw\n",
    "basecnt = False #Print summary counts per baseline\n",
    "```\n",
    "\n",
    "This mode reports the number of rows and data points that are flagged. The selection of reported points can be restricted (see inline help for details).\n",
    "\n",
    "mode='summary' can also report back a dictionary if the task is run as \n",
    "\n",
    "```\n",
    "#In CASA:\n",
    "CASA<1>: s = flagdata(..., mode='summary')\n",
    "```\n",
    "\n",
    "with a variable assigned, here 's'.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced: flagdata \n",
    "\n",
    "Advanced Information on flagdata. C++ code infrastructure\\...\n",
    "\n",
    "\\--CASA Developer\\--\n",
    "\n",
    "For advanced information about some parts of flagdata please visit:\n",
    "\n",
    "[http://www.aoc.nrao.edu/\\~rurvashi/FlaggerDocs/FlaggerDocs.html](http://www.aoc.nrao.edu/~rurvashi/FlaggerDocs/FlaggerDocs.html)\n",
    "\n",
    "In progress\\...\n",
    "\n",
    " \n",
    "\n",
    "##### 1.1 C++ Infrastructure\n",
    "\n",
    " \n",
    "\n",
    "###### Main Classes\n",
    "\n",
    "1.  AgentFlagger: The top-level AgentFlagger class that connects all of the following together, and defines the C++ user-interface for the agentflagger. This is the class used by the tool layer.\n",
    "\n",
    "2.  FlagDataHandler : A top level class defining the data handling interface for the flagging module.\n",
    "\n",
    "3.  FlagMSHandler: - TBD\n",
    "\n",
    "4.  FlagCalTableHandler: - TBD\n",
    "\n",
    "5.  FlagAgentBase: base class that defines the behaviour of all flagging agents and contains agent-level data-selection, etc. The main functions to be implemented by derived classes are setAgentParameters(), preProcessBuffer(), computeAntennaPairFlags() or computeRowFlags(), getReport() .\n",
    "\n",
    "    List of available Flag Agents :\n",
    "\n",
    "    1.  FlagAgentManual : Flag/Unflag based on data-selections. The only processing done by this agent is to set the flags for all data it sees to True if the operation is to flag, and to False to unflag. A boolean parameter apply determines whether to flag (apply=True) or unflag (apply=False). By default it is set to True.\n",
    "\n",
    "    2.  FlagAgentQuack : Flag time-ranges at the beginning and/or end of scans. Uses the YYY iteration-mode.\n",
    "\n",
    "    3.  FlagAgentElevation : Flag time-ranges based on source elevation. Uses the YYY iteration-mode.\n",
    "\n",
    "    4.  FlagAgentShadow : For each timestep, flag antennas that are shadowed by any other antenna. Antennas to be flagged are chosen and marked in the preProcess() stage. Rows are flagged in computeRow(), and this agent uses the YYY iteration-mode.\n",
    "\n",
    "    5.  FlagAgentExtension : Read and extend flags along specified axes, within the current chunk. Uses the YYY iteration-mode.\n",
    "\n",
    "    6.  FlagAgentClip : Flag based on a clip threshold and visExpression. Find and flag NaNs and Infs. Uses the YYY iteration-mode.\n",
    "\n",
    "    7.  FlagAgentTimeFreqCrop : The TFCrop algorithm is run per baseline, via FlagAgentTimeFreqCrop::computeAntennaPairFlags()\n",
    "\n",
    "    8.  FlagAgentRFlag : The RFlag algorithm. Implements multiple passes through each chunk via the passIntermediate() and passFinal() mechanism.\n",
    "\n",
    "    9.  FlagAgentSummary : Flag counts are accumulated in computeRow() and packaged into a Record in getResult().\n",
    "\n",
    "    10. FlagAgentDisplay : Visibilities are read and displayed from computeAntennaPair(). Navigation-buttons control the order in which the framework iterates through baselines.\n",
    "\n",
    "    11. FlagAgentAntennaIntegrations - TBD\n",
    "\n",
    "     \n",
    "\n",
    "6.  The FlagReport class allows each flag agent to build and return information (summary counts, reports as plots, etc) to the user (and/or) to the display agent for end-of-MS reports.\n",
    "\n",
    "######  Control Flow\n",
    "\n",
    "![55045d458766e4fad0872ad6a034931be98c7555](media/55045d458766e4fad0872ad6a034931be98c7555.png){.image-inline}\n",
    "\n",
    "###### Performance and Optimizations\n",
    "\n",
    "There are several performance-optimization choices that can be made. Some of these are under the users control, and some have automated heuristics.\n",
    "\n",
    "###### List mode\n",
    "\n",
    "It helps to combine multiple flag commands into a single run ONLY if most of the commands require the same data to be read. The goal is to read data once, apply multiple flag commands, and write flags once.\n",
    "\n",
    "1.  Manual-flag commands read only meta-data.\n",
    "2.  Shadow, elevation read meta-data + processing to calculate uvw, azel.\n",
    "3.  Clip reads visibilities.\n",
    "4.  tfcrop and rflag read visibilities and flags\n",
    "5.  Extend, summary read flags\n",
    "\n",
    "###### Data Pre-selection\n",
    "\n",
    "If only a subset of the Measurement Set is to be traversed for flag-calculation, it helps to pre-select and iterate through only that section of the MS. When flagdata is run in list mode, there is a second level of selection per agent (command) that ensures that each agent sees only its correct subset of the data.\n",
    "\n",
    "###### Asynchronous I/O\n",
    "\n",
    "Asynchronous I/O is a data-access optimization that applies when iterating through the dataset in chunks. It uses multi-threading to pre-read the next chunk of data from disk while the current chunk is being processed.\n",
    "\n",
    "The user has the option of enabling asynchronous I/O by setting the following variables in the **.casarc** file.\n",
    "\n",
    "    VisibilityIterator.async.enabled: true     # if present and set to false then async i/o will work\n",
    "    VisibilityIterator.async.nBuffers: 2       # the default value is two\n",
    "    VisibilityIterator.async.logFile: stderr   # Send async i/o debug log messages to this file\n",
    "                                               # if not present or file is invalid then no logging occurs\n",
    "    VisibilityIterator.async.logLevel: 2       # Level of log messages to output (two is good, too); defaults to 1\n",
    "\n",
    "    FlagDataHandler.asyncio: true              # True : enable async-IO for the flagger (clip,tfcrop,rflag)\n",
    "    FlagDataHandler.slurp: true                # True : enable ??\n",
    "    FlagAgent.background: true                 # True : enable threading mode\n",
    "\n",
    "Asynchronous I/O helps only when data I/O dominates the total cost. For our current list of agents/algorithms, this helps only for agents that read visibilities. Therefore asynchronous I/O is activated only if clip or tfcrop or rflag are present in the flag-command list.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag using flagcmd \n",
    "\n",
    "Flag the visibility data set or calibration table based on a specified list of flagging commands\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** We recommend using task **flagdata** as the preferable and safer way for flagging based on the visitibilites inspection and for many other capabilities. The option to import XML files with online flag in **flagcmd** has largely become obsolete with the deprecation of **importevla**, because the recommended **importasdm** task cannot copy the actual XML tables from the original SDM to the newly created MS (it can only apply the online flags directly, or write them into ascii tables).\n",
    "\n",
    "</div>\n",
    "\n",
    "The task **flagcmd** will flag the visibility data set or calibration table based on a specified set of flagging commands using a flagging syntax. These commands can be input from the *FLAG_CMD* table within the MS, from an ascii file, or from input python strings. Input can also be from an XML table within a VLA SDM, but given that importasdm does not copy XML files (and importevla is deprecated), the *Flag.xml, Antenna.xml* and *SpectralWindow.xml* tables must first be copied manually into the top-level MS directory for use by **flagcmd** (not the recommended approach). Facilities for manipulation, listing, or plotting of these flags are also provided.\n",
    "\n",
    "When doing any flagging with **flagcmd** it is wise to use the *flagbackup=True* parameter to save the current flags into a .flagversions file. See **flagmanager** for more details about this.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert**: The *FLAG_CMD* sub-table is meant only for meta-data selections such as online flags. Using it to save other parameters (from modes such as *clip, quack, shadow,* etc) is possible but carries a risk that in future releases these parameters maybe renamed or changed their default values. There will be no automatic way to rename any parameter that changes in the future.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert**: There is no way to guarantee that a command from the *COMMAND* column has been applied or not to the MS, even if the *APPLIED* column is set to True. If you use other ways to flag such as interactive flagging in plotms, the *FLAG_CMD* will not be updated! Use at your own risk!\n",
    "</div>\n",
    "\n",
    "The inputs to **flagcmd** are: \n",
    "\n",
    "```\n",
    "#flagcmd :: Flagging task based on batches of flag-commands\n",
    "vis                 =      ''          #Name of MS file or calibration table to flag\n",
    "inpmode             =      'table'     #Input mode for flag commands(table/list/xml)\n",
    "inpfile             =      ''          #Source of flag commands\n",
    "[tablerows           =      []          #Rows of inpfile to read]{\n",
    "reason              =      'any'       #Select by REASON types\n",
    "useapplied          =      False       #Select commands whose rows\n",
    "                                       #have APPLIED column set to True\n",
    "action              =      'apply'     #Action to perform in MS and/or in inpfile\n",
    "                                       #(apply/unapply/list/plot/clear/extract)\n",
    "flagbackup          =      True        #Automatically backup the\n",
    "                                       #FLAG column before execution\n",
    "savepars            =      False       #Save flag commands to the MS or to a file\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    " The default input mode is *inpmode='table'* which directs the task to input flag commands from the *FLAG_CMD* internal MS table. Other options include *list* and *xml*, explained below.\n",
    "\n",
    "The default operation mode is action='apply' directing the task to apply relevant flagging commands to the MS data main table. Other options include *\\'unapply\\', \\'list\\', \\'plot\\', \\'clear\\',* and *\\'extract\\'*, explained below.\n",
    "\n",
    "See the Flagging Command Syntax section below for more detail.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** It is possible to flag calibration tables using **flagcmd**, although we recommend using the **flagdata**  task for this in most cases.\n",
    "\n",
    "</div>\n",
    "\n",
    "When using **flagcmd**  to flag calibration tables, only the  apply and list actions are supported. Because calibration tables do not have a *FLAG_CMD* sub-table, the default  inpmode='table' can only be used if an MS is given in the  inpfile parameter so that flags from the MS are applied to the calibration table directly. Otherwise, the flag commands must be given using inpmode='list', either from a file or from a list of strings.\n",
    "\n",
    " \n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### Input modes inpmode:\n",
    "\n",
    "The inpmode parameter selects options for the input mode for the flagging commands.\n",
    "\n",
    "Available inpmode options are: \n",
    "\n",
    "-   'table' --- input from MS table\n",
    "-   'list' --- input from ASCII file or from a list of strings\n",
    "-   'xml' --- input from XML table (largely obsolete with the deprecation of **importevla** in CASA 5.4)    \n",
    "\n",
    "\n",
    "###### Input mode *inpmode=**'table'* \n",
    "\n",
    " The default input mode is inpmode='table' which directs the task to input flag commands from a *FLAG_CMD* MS table. This has the sub-parameters: \n",
    "\n",
    "```\n",
    "inpmode        =      'table'      #Input mode for flag commands(table/list/xml)\n",
    "inpfile        =      ''           #Source of flag commands\n",
    "[tablerows      =      []           #Rows of inpfile to read]{\n",
    "reason         =      'any'        #Select by REASON types\n",
    "useapplied     =      False        #Select commands whose rows\n",
    "                                   #have APPLIED column set to\n",
    "                                   #True\n",
    "```\n",
    "\n",
    "If inpfile = \\'\\' then it will look for the *FLAG_CMD* table in the MS given by vis. You can use this sub-parameter to tell the task to read the *FLAG_CMD* table from another MS and apply then to the MS given in *vis*.\n",
    "\n",
    "The tablerows sub-parameter is a simple Python list of the row numbers of the table to consider in processing flags. The default is all rows. Currently it only takes fully-enumerated integer lists. Use the Python range function to generate ranges, \n",
    "\n",
    "```\n",
    "tablerows = range(0,30) + range(50,55)\n",
    "\n",
    "#Do not use strings such as '0~29,50~54'\n",
    "```\n",
    "\n",
    "The useapplied sub-parameter toggles whether only flag commands marked as not having been applied are considered (the default), or to allow (re)processing using all commands.\n",
    "\n",
    "The reason sub-parameter selects the *reason* type to process. The default 'any' means all commands.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** what is within the string is literally matched, e.g. *reason=''* matches only blank reasons, and *reason = 'FOCUS_ERROR,SUBREFLECTOR_ERROR'* matches this compound reason string only. To flag by either of these reasons alone, run **flagcmd** twice, once with *reason='FOCUS_ERROR'*, and then with the other reason.\n",
    "</div>\n",
    "\n",
    "One use case is to read the flag commands from the *FLAG_CMD* of an MS and apply them to a calibration table given in the parameter vis. Example:\n",
    "\n",
    "```\n",
    "flagcmd(vis='cal-X54.B1', inpmode='table',inpfile='uid___A002_X2a5c2f_X54.ms', action='apply')\n",
    "```\n",
    "\n",
    "###### Input mode *inpmode=**'list'* \n",
    "\n",
    "See **flagdata** help for syntax.\n",
    "\n",
    "This mode allows one to give a list of strings with flagging commands, the name of a file or a list of filenames that contains these commands equivalent to the mode='list' in flagdata. E.g. a file * flags.txt* that contains \n",
    "\n",
    "```\n",
    "scan='1~3' mode='manual'\n",
    "[mode='clip' clipminmax=[0,2] correlation='ABS_XX' clipoutside=False]{\n",
    "spw='9' mode='tfcrop' correlation='ABS_YY' ntime=51.0\n",
    "mode='extend' extendpols=True\n",
    "```\n",
    "\n",
    "can be used via\n",
    "\n",
    "```\n",
    "flagcmd(vis='some.ms',inpmode='list',inpfile='flags.txt')\n",
    "```\n",
    "\n",
    "A list of input files can also be given:\n",
    "\n",
    "```\n",
    "[flagcmd(vis='some.ms',inpmode='list',inpfile=['flags.txt,'userflags.txt'])]{\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Alternatively, the individual flagging commands can be directly provided in the call itself such as:\n",
    "\n",
    "```\n",
    "inpfile=[\"scan='1~3' mode='manual'\",\n",
    "[         \"mode='clip' clipminmax=[0,2] correlation='ABS_XX' clipoutside=False\",]{\n",
    "         \"spw='9' mode='tfcrop' correlation='ABS_YY' ntime=51.0\",\n",
    "[         \"mode='extend' extendpols=True\"]]{\n",
    "```\n",
    "\n",
    "\n",
    "###### Input mode inpmode='xml'\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** With the deprecation of **importevla**, XML files can no longer be imported directly from the original SDM into the newly created MS, but only by manually copying the *Flag.xml*, *Antenna.xml* and *SpectralWindow.xml* tables into the top-level MS directory (not the recommended approach). Also, the XML mode is not available for cal tables, therefore it will not work for ALMA MSs. However, task **importasdm** with *process_flags=True* will copy the flags from the XML files directly to the *FLAG_CMD* sub-table, see **importasdm** help for options. This is the recommend way of dealing with the online flags.\n",
    "</div>\n",
    "\n",
    "The input mode inpmode='xml' tells the task to input flag commands from XML SDM files, which contain the online flags. When set this opens the sub-parameters: \n",
    "\n",
    "```\n",
    "inpmode        =      'xml'        #Input mode for flag commands(table/list/xml)\n",
    "tbuff          =      0.0          #Time buffer (sec) to pad flags\n",
    "ants           =      ''           #Allowed flag antenna names to select by\n",
    "reason         =      'any'        #Select by REASON types\n",
    "```\n",
    "\n",
    "  This mode will look for files called Flag.xml, Antenna.xml and optionally SpectralWindow.xml inside the MS directory specified under vis. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** You can only apply the flags from an XML file. It is not possible to unapply them. For that, transfer the flags to the *FLAG_CMD* table using *action='list'*, then unapply them.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "The tbuff sub-parameter sets a padding buffer (in seconds) to the begin and end times of the online flags in the XML file. The online flag time buffer tbuff is specified in seconds, but in fact should be keyed to the intrinsic online integration time to allow for events (like slewing) that occur within an integration period. This is particularly true for JVLA data, where a tbuff value of 0.5× to 1.5× the integration time is needed. For example, if data were taken with 1-second integrations, then at least tbuff=0.5 should be used, likewise tbuff=5 for 10-second integrations. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Info: For JVLA data you should use 1.5× (e.g. tbuff=15 for 10-second integrations) for data taken in early 2011 or before due to a timing error. We do not yet know what ALMA data will need for padding (if any).\n",
    "</div>\n",
    "\n",
    "The ants sub-parameter selects the antennas from which online flags will be selected (default is all antennas). For example, ants='ea01' is a valid choice for JVLA data.\n",
    "\n",
    "The reason sub-parameter selects by the REASON field in the Flag.xml file. The default 'any' means all commands. Note that reason=\" would only select flags who have a blank REASON field entry.\n",
    "\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### Operation types action \n",
    "\n",
    " The action selects options for operating on the selected flags and possibly the data.\n",
    "\n",
    "Available action options are: \n",
    "\n",
    "-   'apply' --- apply flag commands to data\n",
    "-   'unapply' --- unapply flags in data\n",
    "-   'list' --- list and/or save flag commands\n",
    "-   'plot' --- plot flag commands\n",
    "-   'clear' --- clear rows from FLAG_CMD table\n",
    "-   'extract' --- extract internal flag dictionary\n",
    "\n",
    "###### Apply flags action='apply' \n",
    "\n",
    "The default operation mode is action='apply' directing the task to apply relevant flagging commands to the *vis* data main table.\n",
    "\n",
    "```\n",
    "action         =       'apply'     #Action to perform in MS and/or in inpfile\n",
    "                                   #(apply/unapply/list/plot/clear/extract)\n",
    "flagbackup     =       True        #Automatically backup the\n",
    "                                        #FLAG column before execution\n",
    "```\n",
    "\n",
    "  The flagbackup parameter toggles whether a new copy of the MS FLAG column is written to the .flagversions backup directory for that MS before the requested flagging operation.\n",
    "\n",
    "\n",
    "###### Unapply flags action='unapply' \n",
    "\n",
    "The unapply option allows unflagging of data based on the selected flag commands. This choice opens the sub-parameters: \n",
    "\n",
    "```\n",
    "action = 'unapply' #Action to perform in MS and/or in inpfile\n",
    " #(apply/unapply/list/plot/clear/extract)\n",
    " flagbackup = True #Automatically backup the\n",
    " #FLAG column before execution\n",
    "```\n",
    "\n",
    "As in action='apply', it is possible to make a backup to the \\*.flagversions file by using flagbackup=True. \n",
    "\n",
    " \n",
    "\n",
    "###### List and save flags action='list' \n",
    "\n",
    "The 'list' option will give a listing of the flagging commands. This choice opens the sub-parameters: \n",
    "\n",
    "```\n",
    "action = 'list' #Action to perform in MS and/or in inpfile\n",
    " #(apply/unapply/list/plot/clear/extract)\n",
    " savepars = True #Save flag commands to the MS or to a file\n",
    " outfile = '' #Name of output file to save commands\n",
    " overwrite = True #Overwrite an existing file to save the flag commands\n",
    "```\n",
    "\n",
    "This action lists the commands on the screen without applying them. One can save the flagging script to an file specified in the outfile parameter when savepars=True. If outfile is empty, it will save the commands to a new row in the MS *FLAG_CMD* table given in vis.\n",
    "\n",
    "The format of the listing output depends on the source of the flagging commands. A set of flagging commands specified through inpmode='list' will be listed directly. The flagging commands extracted through inpmode='table' will reflect the columns in the table: \\'*Row*\\', \\'*Timerange*\\', \\'*Reason*\\', \\'*Type*\\', \\'*Applied*\\', \\'*Lev*\\', \\'*Sev*\\', \\'*Command*\\' while commands from inpmode='xml' will be shown with the SDM XML table fields: \\'*Key*\\', \\'*FlagID*\\', \\'*Antenna*\\', \\'*Reason*\\', \\'*Timerange*\\'\n",
    "\n",
    "###### Plot flags action='plot' \n",
    "\n",
    "The 'plot' option will produce a graphical plot of flags of time versus antenna. This choice opens the sub-parameters: \n",
    "\n",
    "```\n",
    "action = 'plot' #Action to perform in MS and/or in inpfile\n",
    " #(apply/unapply/list/plot/clear/extract)\n",
    " plotfile = '' #Name of output file to save plot\n",
    "```\n",
    "\n",
    "  This is only useful for MS. flagcmd is most often used to plot the VLA or ALMA flags generated online using *impmode=\\'table\\'* or *\\'xml\\'* and provided in a *FLAG_CMD* or *Flags.xml* table. Using these tables, only the standard on-line REASONs are recognised. These include *\\'FOCUS\\',\\'SUBREFLECTOR\\', \\'OFF SOURCE\\', \\'NOT IN SUBARRAY\\'* for the VLA and \\'*Calibration_device\\_(ACD)\\_is_not_in_the_correct_position\\',**\\'Mount_is_off_source\\', \\'FrontEnd_LO_Amps_not_optimized\\' \\'Power_levels_are_being_optimized.\\', \\'The_WCA_is_not_locked.\\'* for ALMA\n",
    "\n",
    "If the plotfile sub-parameter is non-blank, then a plotfile will be made with that name instead of appearing in a matplotlib plotter window on the users workstation. There are additional parameters that control the shape of the output file, such as dimensions, and resolution.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** The plotted enumerations are currently only those known to be allowed for JVLA online flags as of 15 April 2011, and include:\n",
    "\n",
    "*'FOCUS', 'SUBREFLECTOR', 'OFF SOURCE', 'NOT IN SUBARRAY'* with all others being plotted as *'Other*'.\n",
    "</div>\n",
    "\n",
    "###### Clear flags action='clear' \n",
    "\n",
    "This is only useful for MS, using *inpmode=\\\"table\\\"*. The 'clear' action will delete selected rows from the FLAG_CMD MS table. This choice opens the sub-parameters: \n",
    "\n",
    "```\n",
    "action = 'clear' #Action to perform in MS and/or in inpfile\n",
    " #(apply/unapply/list/plot/clear/extract)\n",
    " clearall = False #Delete all rows from FLAG_CMD\n",
    "[ rowlist = [] #FLAG_CMD rows to clearThis box is intended for CASA Inputs. Insert your text here.]{\n",
    "```\n",
    "\n",
    "The rowlist sub-parameter is a simple Python list of the row numbers of the table to consider in processing flags. The default is a blank list which indicates the desire to clear all rows. Currently it only takes fully-enumerated integer lists. Use the Python range function to generate ranges,\n",
    "\n",
    "```\n",
    "tablerows = range(0,30) + range(50,55)\n",
    "#Do not use strings such as '0~29,50~54'\n",
    "```\n",
    "\n",
    "In either case, if clearall=False then nothing will happen by default as a safeguard. If clearall=True, then a blank list will direct the deletion of the selected rows from the table.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Alert: Use this option with care. You can easily mess up the FLAG_CMD table.\n",
    "</div>\n",
    "\n",
    "###### Extract Flag Commands action='extract' \n",
    "\n",
    "This will return the requested flags (depending on *inpmode*) as a Python dictionary.\n",
    "\n",
    "```\n",
    "action = 'extract' #Action to perform in MS and/or in inpfile\n",
    " #(apply/unapply/list/plot/clear/extract)\n",
    "```\n",
    "\n",
    "The dictionary can be saved to a variable such as shown below. If a variable is not set, only the first 1000 flags will be printed to the terminal: \n",
    "\n",
    "```\n",
    "myflagd = flagcmd(vis=msfile,useapplied=True,action='extract')\n",
    "```\n",
    "\n",
    "An example of the dictionary returned by *action=\\'extract\\'* is given below:\n",
    "\n",
    "```python\n",
    "{0: {'antenna': 'PM04&&*',\n",
    "  'applied': False,\n",
    "  'command': 'antenna=PM04&&* timerange=2013/04/28/04:35:58.217~2013/04/28/04:35:58.468 ',\n",
    "  'id': '662',\n",
    "  'interval': 0.0,\n",
    "  'level': 0,\n",
    "  'mode': '',\n",
    "  'reason': 'ACD_motors_are_not_in_position.',\n",
    "  'severity': 0,\n",
    "  'time': 0.0,\n",
    "  'timerange': '2013/04/28/04:35:58.217~2013/04/28/04:35:58.468',\n",
    "  'type': ''},\n",
    " 1: {'antenna': 'CM03&&*',\n",
    "  'applied': False,\n",
    "  'command': 'antenna=CM03&&* timerange=2013/04/28/04:35:58.196~2013/04/28/04:35:58.503 ',\n",
    "  'id': '663',\n",
    "  'interval': 0.0,\n",
    "  'level': 0,\n",
    "  'mode': '',\n",
    "  'reason': 'ACD_motors_are_not_in_position.',\n",
    "  'severity': 0,\n",
    "  'time': 0.0,\n",
    "  'timerange': '2013/04/28/04:35:58.196~2013/04/28/04:35:58.503',\n",
    "  'type': ''}}\n",
    "```\n",
    "\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "##### Flagging command syntax \n",
    "\n",
    "A flagging command syntax has been devised to populate the  COMMAND column of the *FLAG_CMD* table and to direct the operation of the **flagcmd** task.\n",
    "\n",
    "The syntax is the same used in **flagdata***,*  so please check *\\\"help flagdata*\\\"  for more updated info. \n",
    "\n",
    "Commands are a string (which may contain internal \\\"strings\\\") consisting of KEY=VALUE pairs separated by whitespace (see examples below).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** There should be no whitespace between KEY=VALUE or within each KEY or VALUE, since the simple parser first breaks command lines on whitespace, then on \"=\".\n",
    "</div>\n",
    "\n",
    "[The key is the name of a parameter and the value is the value of that parameter. The parameter data types enforced in **flagdata** are the same used in these flag commands. As an example, the parameter *clipminmax* accepts only a list of double values in **flagdata** and should have the same type when given in a flag command list, e.g. *mode=\\'clip\\' clipminmax=\\[0.1,10.2\\]*]{\n",
    "\n",
    "Each key should only appear once on a given command line/string\n",
    "\n",
    "There is an implicit \\\"mode\\\" for each command, with the default being 'manual' if not given.\n",
    "\n",
    "Comment lines can start with '\\#' and will be ignored.\n",
    "\n",
    "1.  ### Data selection parameters (used by all flagging modes)  \n",
    "\n",
    "    ```\n",
    "    antenna='' \n",
    "    spw='' \n",
    "    correlation='' \n",
    "    field='' \n",
    "    scan='' \n",
    "    feed=''\n",
    "    array='' \n",
    "    timerange='' \n",
    "    uvrange='' \n",
    "    intent='' \n",
    "    observation=''\n",
    "    ```\n",
    "\n",
    "    <div class=\"alert alert-info\">\n",
    "    **Info:** a command consisting only of meta-data selection key-value pairs is a basic \"manual\" operation, i.e. flag the data meeting the selection\n",
    "    </div>\n",
    "\n",
    "2.  ### Modes with default values for relevant parameters (for further details, refer to the task **flagdata**)\n",
    "\n",
    "    a.  #### Mode manual\n",
    "\n",
    "        ```\n",
    "        autocorr=False\n",
    "        ```\n",
    "\n",
    "    b.  #### Mode clip\n",
    "\n",
    "        ```\n",
    "        datacolumn='DATA'\n",
    "        [ clipminmax=[] ]{\n",
    "         clipoutside=True\n",
    "         channelavg=False \n",
    "         clipzeros=False\n",
    "         timeavg=False\n",
    "         timebin=''\n",
    "        ```\n",
    "\n",
    "    c.  #### Mode shadow \n",
    "\n",
    "        ```\n",
    "        tolerance=0.0\n",
    "         addantenna=''\n",
    "        ```\n",
    "\n",
    "    d.  #### Mode quack\n",
    "\n",
    "        ```\n",
    "        quackinterval=0.0 \n",
    "         quackmode='beg' \n",
    "         quackincrement=False\n",
    "        ```\n",
    "\n",
    "    e.  #### Mode elevation\n",
    "\n",
    "        ```\n",
    "        lowerlimit=0.0\n",
    "         upperlimit=90.0\n",
    "        ```\n",
    "\n",
    "    f.  #### Mode tfcrop\n",
    "\n",
    "        ```\n",
    "        ntime='scan'\n",
    "         combinescans=False\n",
    "         datacolumn='DATA' \n",
    "         timecutoff=4.0 \n",
    "         freqcutoff=3.0\n",
    "         timefit='line'\n",
    "         freqfit='poly'\n",
    "         maxnpieces=7 \n",
    "         flagdimension='freqtime' \n",
    "         usewindowstats='none'\n",
    "         halfwin=1\n",
    "         extendflags=True\n",
    "         channelavg=False\n",
    "         chanbin=1\n",
    "         timeavg=False\n",
    "         timebin='0s'\n",
    "        ```\n",
    "\n",
    "    g.  #### Mode extend\n",
    "\n",
    "        ```\n",
    "        ntime='scan'\n",
    "         combinescans=False\n",
    "         extendpols=True\n",
    "         growtime=50.0\n",
    "         growfreq=50.0\n",
    "         growaround=False\n",
    "         flagneartime=False\n",
    "         flagnearfreq=False\n",
    "        ```\n",
    "\n",
    "    h.  #### Mode rflag\n",
    "\n",
    "        ```\n",
    "        ntime='scan'\n",
    "         combinescans=False\n",
    "         datacolumn='DATA'\n",
    "         winsize=3\n",
    "         timedev=''\n",
    "         freqdev=''\n",
    "         timedevscale=5.0\n",
    "         freqdevscale=5.0\n",
    "         spectralmax=1000000.0\n",
    "         spectralmin=0.0\n",
    "         extendflags=True\n",
    "         channelavg=False\n",
    "         chanbin=1\n",
    "         timeavg=False\n",
    "         timebin='0s'\n",
    "        ```\n",
    "\n",
    "    i.  #### Mode antint\n",
    "\n",
    "        ```\n",
    "        minchanfrac=0.6\n",
    "         verbose=False\n",
    "        ```\n",
    "\n",
    "    j.  #### Mode unflag\n",
    "\n",
    "        <div>\n",
    "\n",
    "        This mode does not have any sub-parameters.\n",
    "\n",
    "        </div>\n",
    "\n",
    "3.  ### Typical example of a list with flag commands \n",
    "\n",
    "    ```\n",
    "    spw='0,1'\n",
    "    antenna='ea1,ea10'\n",
    "    autocorr=True\n",
    "    mode='clip'\n",
    "    clipzeros=True\n",
    "    datacolumn='DATA'\n",
    "    mode='summary'\n",
    "    name='Initial_flags'\n",
    "    ```\n",
    "\n",
    "4.  ### Basic elaboration options for online and interface use \n",
    "\n",
    "    ```\n",
    "    id='' #flag ID tag (not necessary)\n",
    "     reason='' #reason string for flag\n",
    "     flagtime='' #a timestamp for when this flag was generated (for \n",
    "     user history use)\n",
    "    ```\n",
    "\n",
    "    <div class=\"alert alert-info\">\n",
    "    **Info:** there is no flagtime column in *FLAG_CMD* at this time, but we will propose to add this as an optional column\n",
    "    \n",
    "    **Info:** These are currently ignored and not used\n",
    "    </div>\n",
    "\n",
    "5.  ### Extended elaboration options for online and interface use Note: these are FLAG_CMD columns, but their use is not clear but included here for compatibility and future expansion\n",
    "\n",
    "    ```\n",
    "    level=N #flagging \"level\" for flags with same reason\n",
    "     severity=N #Severity code for the flag, on a scale of 0-10 in order \n",
    "     of increasing severity; user specific\n",
    "    ```\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage flag versions \n",
    "\n",
    "Managing flag versions\n",
    "\n",
    "The **flagmanager** task will allow you to manage different versions of flags in your data. These are stored inside a CASA flag versions table, under the name of the MS \\<msname\\>.flagversions. For example, for the MS jupiter6cm.usecase.ms, there will need to be jupiter6cm.usecase.ms.flagversions on disk. This is created on import (by **importasdm**, **importvla** or **importuvfits**) or when flagging is first done on an MS without a .flagversions. \n",
    "\n",
    "By default, when the .flagversions is created, this directory will contain a flags.Original table containing a copy of the original flags in the MAIN table of the MS so that you have a backup. It will also contain a file called FLAG_VERSION_LIST that has the information on the various flag versions there. The flag versions are cumulative, i.e. a specific version number contains all the flags from the lower version numbers, too. \n",
    "\n",
    "The flags are stored in an MS column of the same spectral and correlator polarization shape as the visibility data values, with Boolean 1 to indicate that a particular time, channel, polarization has been flagged or 0 for unflagged.\n",
    "\n",
    " \n",
    "\n",
    "The inputs for **flagmanager**  are:\n",
    "\n",
    "```\n",
    "vis                 =         ''        #Name of input visibility file (MS)\n",
    "mode                =     'list'        #Flag management operation (list,save,restore,delete)\n",
    "```\n",
    "\n",
    "The mode='list' option will list the available flag versions from the \\<msname\\>.flagversions file in the logger. For example:\n",
    "\n",
    "```\n",
    "CASA <102>: default('flagmanager')\n",
    "CASA <103>: vis = 'jupiter6cm.usecase.ms'\n",
    "CASA <104>: mode = 'list'\n",
    "CASA <105>: flagmanager()\n",
    "MS : /home/imager-b/smyers/Oct07/jupiter6cm.usecase.ms\n",
    "\n",
    "main : working copy in main table\n",
    "Original : Original flags at import into CASA\n",
    "flagautocorr : flagged autocorr\n",
    "flagdata_1 : Flags autosave on 2018-07-16 08:57:20]\n",
    "```\n",
    "\n",
    "*mode=\\'list\\'* will also return a Python dictionary with the available flag versions. For example:\n",
    "\n",
    "```\n",
    "myflags = flagmanager('jupiter6cm.usecase.ms', mode='list')\n",
    "\n",
    "myflags\n",
    "\n",
    "{0: {'comment': 'Original flags at import into CASA', 'name': 'Original'},1: {'comment': 'flagged autocorr', 'name': 'flagautocorr'},2: {'comment': 'Flags autosave on 2018-07-16 08:57:20', 'name': 'flagdata_1'},'MS': '/home/imager-b/smyers/Oct07/jupiter6cm.usecase.ms'}}\n",
    "```\n",
    "\n",
    "The mode parameter expands the options. For example, if you wish to save the current flagging state of vis=\\<msname\\>:\n",
    "\n",
    "```\n",
    "mode                =     'save'        #Flag management operation (list, save, restore, delete)\n",
    "versionname         =         ''        #Name of flag version (no spaces)\n",
    "comment             =         ''        #Short description of flag version\n",
    "merge               =  'replace'        #Merge option (replace, and, or)\n",
    "```\n",
    "\n",
    "  with the output version name specified by versionname. For example, the above xyflags version was written using: \n",
    "\n",
    "```\n",
    "default('flagmanager')\n",
    "vis = 'jupiter6cm.usecase.ms'\n",
    "mode = 'save'\n",
    "versionname = 'xyflags'\n",
    "comment = 'Plotxy flags'\n",
    "flagmanager()\n",
    "```\n",
    "\n",
    "  and you can see that there is now a sub-table in the flag versions directory:\n",
    "\n",
    "```\n",
    "CASA <106>: ls jupiter6cm.usecase.ms.flagversions/\n",
    "  IPython system call: ls -F jupiter6cm.usecase.ms.flagversions/\n",
    "  flags.flagautocorr  flags.Original  flags.xyflags  FLAG_VERSION_LIST\n",
    "```\n",
    "\n",
    "It is recommended that you use this task regularly to save versions during flagging.\n",
    "\n",
    "Note that if a flag version already exists under a name, the task will give a warning and add a suffix '.old.timestamp' to the previous version.\n",
    "\n",
    "You can restore a previously saved set of flags using the mode='restore' option:\n",
    "\n",
    "```\n",
    "mode                =  'restore'        #Flag management operation (list,save,restore,delete)\n",
    "versionname         =         ''        #Name of flag version (no spaces)\n",
    "merge               =  'replace'        #Merge option (replace, and, or)\n",
    "```\n",
    "\n",
    "  The merge sub-parameter will control how the flags are restored. For merge='replace', the flags in versionname will replace those in the MAIN table of the MS. For merge='and', only data that is flagged in BOTH the current MAIN table and in versionname will be flagged. For merge='or', data flagged in EITHER the MAIN or in versionname will be flagged.\n",
    "\n",
    "The mode='delete' option can be used to remove versionname from the flag versions:\n",
    "\n",
    "```\n",
    "mode                =   'delete'        #Flag management operation (list,save,restore,delete)\n",
    "versionname         =         ''        #Name of flag version (no spaces)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UV Manipulation \n",
    "\n",
    "How to modify visibility data in CASA\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify UV-data: mstransform \n",
    "\n",
    "Regridding visibilities with the task mstransform\n",
    "\n",
    "**mstransform** is a multipurpose task that provides all the functionality of **split**, **partition**, **cvel**, **hanningsmooth**, **uvcontsub** and **applycal** with the possibility of applying each of these transformations separately or together in an in-memory pipeline, thus avoiding unnecessary I/O steps. The list of transformations that **mstransform** can apply is as follows:\n",
    "\n",
    "1.  Data selection and re-indexing\n",
    "2.  Data partitioning (create output Multi-MS)\n",
    "3.  On-the-fly calibration (via \"Cal Library\")\n",
    "4.  Time averaging (weighted and baseline dependent)\n",
    "5.  UV continuum subtraction\n",
    "6.  Combination of spectral windows\n",
    "7.  Channel averaging (weighted)\n",
    "8.  Hanning smoothing\n",
    "9.  Spectral regridding and reference frame transformation\n",
    "10. Separation of spectral windows\n",
    "\n",
    "Notice that the order in the above list is not arbitrary. When various transformations are applied on the data using **mstransform**, the order in which the transformations are piped one after the other is the one shown in the above list. These operations are described in the sections that follow.\n",
    "\n",
    "Besides **mstransform** in itself, there are a series of tasks which perform only the individual operations: **split**, **hanningsmooth** and **cvel2**. Under the hood these are all based on the mstransform framework; they are provided to facilitate back compatibility, and for simplicity in cases where only the simpler operations are needed.  Notice that as of CASA 4.6, the **mstransform** based versions of **split** and **hanningsmooth** are the default ones, whereas **cvel** still is based on the old implementation by default, and the **cvel2** interface points to the **mstransform** implementation.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate spectral windows \n",
    "\n",
    "How to combine, separate, and Hanning smooth spectral windows in mstransform\n",
    "\n",
    "##### Combination of spectral windows\n",
    "\n",
    "Both **mstransform** and **cvel2** are able to combine SPWs (in **mstransform** by specifying *combinespws = True* and in **cvel2** by default). The algorithm is in general the same as the old **cvel**, however, there are two significant differences in the new framework:\n",
    "\n",
    "-   **mstransform** is able to only combine SPWs, only regrid each SPW separately or to combine all SPWs and **regrid** them together. The details about independent regridding operations are explained in the following sections. For instance, if you wish to do channel averaging while regridding in **mstransform**, please see the [section on channel averaging](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/channel-average). \n",
    "-   **mstransform** and **cvel2** automatically detect combination of SPWs with different exposure, and use the *WEIGHT* column (or *WEIGHT_SPECTRUM* if available) in addition to the geometrical factors to calculate the combined visibility in the overlapping regions.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** For the time being, **mstransform** is not able to combine SPWs with different numbers of channels. This is a limitation in the Visibility Iterator (VI/VB2) layer of CASA.\n",
    "</div>\n",
    "\n",
    "The output MS created by **mstransform** and **cvel2** has a uniform binning in spectral axis. If the *width* parameter is not specified then the size of the input bin corresponding to the lowest absolute frequency will be used as the size of the output bin, where the lowest absolute frequency is retrieved from the full list of spectral bins for all the input SPWs (after selection). Remember that in some cases, especially after certain data selection, the lowest frequency might not be part of the first input SPW ID.\n",
    "\n",
    "Note that when combining SPWs which have different polarization settings only the common polarizations to all SPWs will be part of the output MS.\n",
    "\n",
    "##### Separation of spectral windows\n",
    "\n",
    "A completely new feature in **mstransform** is the ability to separate an input SPW into several ones, or to combine various input SPWs into a single one with a uniform grid (resolving overlaps or gaps) to then separate it in several output SPWs. This option is activated under the regridding section (therefore by specifying *regridms = True*), together with the *nspw* parameter which when bigger than 1 implies that the input SPW or combination of input SPWs should be separated:\n",
    "\n",
    "```\n",
    "#In CASA\n",
    "regridms = True  #Regrid the MS to a new spw,\n",
    "    nspw = 1     #Number of output spws to create in output MS.\n",
    "```\n",
    "\n",
    "Internally, the framework will combine the selected spws before separating them so that channel gaps and overlaps are taken into account. This sub-parameter will create a regular grid of spws in the output MS. If nchan is set, it will refer to the number of output channels in each of the separated spws.\n",
    "\n",
    "##### Hanning smoothing\n",
    "\n",
    "Both **mstransform** and **hanningsmooth** are able to perform hanning smoothing (in **mstransform** by specifying *hanning = True* and in **hanningsmooth** by default).  For details on hanning smoothing please refer to the [section on Hanning Smoothing](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/hanning-smoothing-of-uv-data-hanningsmooth) and the **hanningsmooth **task documentation linked here. Please note that both **mstransform **and **hanningsmooth** will create a new MS (i.e. do not have an option to do in-place hanning smoothing). This is the only difference with respect to the old **hanningsmooth** task that existed in previous versions of CASA.  \n",
    "\n",
    "Note that straightforward channel averaging can be done as described in the [section on channel averaging](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/channel-average).\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select/Reindex UV-data \n",
    "\n",
    "Notes on visibility selection and reindexing\n",
    "\n",
    "**mstransform** / **split** are able to create a new MS with a specific data selection, for instance splitting a science target. The new MS contains only the selected data and also the subtables are re-generated to contain only the metadata matching the data selection. The details about pure split operation are described in the **split** task documentation.\n",
    "\n",
    "Keywords relevant to data selection are as follows:\n",
    "\n",
    "```\n",
    "CASA <1>: inp mstransform\n",
    "--------> inp(mstransform)\n",
    "\n",
    "vis                 =         ''        #Name of input MeasurementSet or Multi-MS.\n",
    "outputvis           =         ''        #Name of output MeasurementSet or Multi-MS.\n",
    "tileshape           =        [0]        #List with 1 or 3 elements giving the\n",
    "                                           tile shape of the disk data columns.\n",
    "field               =         ''        #Select field using ID(s) or name(s).\n",
    "spw                 =         ''        #Select spectral window/channels.\n",
    "scan                =         ''        #Select data by scan numbers.\n",
    "antenna             =         ''        #Select data based on antenna/baseline.\n",
    "correlation         =         ''        #Correlation: '' ==> all, correlation='XX,YY'.\n",
    "timerange           =         ''        #Select data by time range.\n",
    "intent              =         ''        #Select data by scan intent.\n",
    "array               =         ''        #Select (sub)array(s) by array ID number.\n",
    "uvrange             =         ''        #Select data by baseline length.\n",
    "observation         =         ''        #Select by observation ID(s).\n",
    "feed                =         ''        #Multi-feed numbers: Not yet implemented.\n",
    "datacolumn          = 'corrected'       #Which data column(s) to process.\n",
    "keepflags           =       True        #Keep *completely flagged rows* or\n",
    "                                           drop them from the output.\n",
    "usewtspectrum       =      False        #Create a WEIGHT_SPECTRUM column in the output MS.\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "New features related to data selection and re-indexing provided by **mstransform** / **split** (but not in **oldsplit**) are the following:\n",
    "\n",
    "-   Spectral weight initialization: **mstransform** can initialize the output *WEIGHT* and *SIGMA_SPECTRUM* columns by specifying *usewtspectrum = True*. The details about spectral weights initialization are described in section\n",
    "-   Tile shape specification for the data columns: **mstransform** also allows to specify a custom default tile shape for the output data columns, namely a list of 3 elements specifying the number of correlations, channels and rows to be contained in each tile, for instance *tileshape = \\[4,128,351\\]* would specify a tile with shape (4 correlations)x(128 channels)x(351 rows). This can be used to optimize the access pattern of subsequent tasks, for instance imaging tasks.\n",
    "-   Support for SPWs with different sets of correlation products: **mstransform** / **split** are both able to work when a given SPW is associated with several correlation products (like in some EVLA correlation setups). This is transparent for the user and simply works by using the spw data selection parameter normally. It also works in conjunction with the polarization parameter, so for instance if a given MS has separated RR and LL data associated with spw 0 the following data selection would work flawlessly: *spw = '0' correlation = 'LL'*\n",
    "-   Support for multiple channel selection: Both **mstransform** / **split** are also capable of working with multiple channel selection. This support also goes transparently for the user, by simply following the SPW syntax as described in the [Visibility Data Selection](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset) chapter. For example *spw = '4,7:4\\~59,8:4\\~13;18\\~594' * which means \\\"select all channels in spectral window four, channels 4 through 59 inclusive in spectral window seven; also select spectral window 8, channels 4 through 13 and 18 through 594, also inclusive.\\\". See more examples of spectral window selections in the split [examples](https://casa.nrao.edu/casadocs-devel/stable/global-task-list/task_split/examples) chapter.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On-the-fly calibration \n",
    "\n",
    "Performing on-the-fly calibration using mstransform\n",
    "\n",
    "As of CASA 4.5 **mstransform** incorporates the possibility of applying on the-the-fly (OTF) calibration by specifying *docallib* = True, which in turn allows to specify the \"Cal Library\" filename (*callib* parameter). This transformation is the first one applied to the data, producing effectively a corrected data column on-the-fly, which can be further transformed. *callib* is the filename pointing to the calibration specification file. Details on how to specify the Cal Library file can be found on [this CASA Docs page](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax), where conventions and current limitations are also described. The combination of OTF calibration and cal libraries enable complex calibrations to be applied, and for the calculation to proceed more quickly than they otherwise might.\n",
    "\n",
    "```\n",
    "docallib = True   #Enable OTF calibration\n",
    "\n",
    "callib   = ''     #Cal Library filename\n",
    "```\n",
    "\n",
    "An example of a Cal Library file is given below.\n",
    "\n",
    "    caltable='ngc5921_regression/ngc5921.bcal' calwt=True tinterp='nearest' \n",
    "    caltable='ngc5921_regression/ngc5921.fluxscale' calwt=True tinterp='nearest' fldmap='nearest' \n",
    "    caltable='ngc5921_regression/ngc5921.gcal' calwt=True field='0' tinterp='nearest' fldmap=[0] \n",
    "    caltable='ngc5921_regression/ngc5921.gcal' calwt=True field='1,2' tinterp='linear' fldmap='1' \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "See the full description of a Cal Library [here](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax).\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time average \n",
    "\n",
    "Time averaging highlights using mstransform and split\n",
    "\n",
    "**mstransform** and **split** are both able to perform a weighted time average of data.  In **mstransform** time averaging is accessed by setting *timeaverage = True* and controlled by the resulting sub-parameters of *timeaverage.* Additionally, **mstransform** is able to perform a baseline dependent time average as described in the paper Effects of Baseline Dependent Time Averaging of UV Data by W.D. Cotton [\\[1\\]](#Bibliography) .\n",
    "\n",
    "```\n",
    "#mstransform time average parameters\n",
    "\n",
    "timeaverage         = True #Average data in time.\n",
    "     timebin        = '0s' #Bin width for time averaging.\n",
    "     timespan       = ''   #Span the timebin across scan, state or both.\n",
    "     maxuvwdistance = 0.0  #Maximum separation of start-to-end baselines that can be included in an average(meters)\n",
    "```\n",
    "\n",
    "In **split** time averaging is available via top level parameters *timebin* and *combine*.  The functionality is very similar to that in the old version of split.  However, there are some differences as explained below.\n",
    "\n",
    "```\n",
    " #split time average parameters\n",
    "\n",
    "timebin   = '0s'   #Bin width for time averaging\n",
    "combine   = ''     #Span the timebin across scan, state or both\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Warning:** the timebin parameter works based on wall clock time, not integration time.  For example, if each scan is 5 seconds long, and scans are separated by 15 seconds, then timebin='25s' is the minimum value needed to combine data from 2 consecutive scans. One might assume that timebin='10s' should work to combine two 5 second scans, but it does not. This is mostly relevant to single dish data, and when using the tasks like sdtimeaverage or mstransform.\n",
    "</div>\n",
    "\n",
    "-   Whereas the old version of split used exclusively the *WEIGHT* column to perform the weighted average, **mstransform** and **split** use both *FLAG* and spectral weights (when present). To be specific *WEIGHT_SPECTRUM* is used when averaring *CORRECTED_DATA*, and *SIGMA_SPECTRUM* is used when averaging the *DATA* column.\n",
    "\n",
    "-   Also **mstransform** and **split** are able to transform the input *WEIGHT/SIGMA_SPECTRUM* according to the rules of error propagation that apply to a weighted average, which result in an output weight equals to the sum of the input weights. For a detailed reference see, Data Reduction and Error Analysis by Bevington & Robinson [\\[2\\]](#Bibliography).\n",
    "\n",
    "-   When **mstransform** and **split** process an ALMA MS and *timebin* is greater than 30s, timespan is automatically set to state, to overcome a limitation of the ALMA ASDM binary dumps.\n",
    "\n",
    "-   As of version 4.5, **mstransform** and **split** both allow timespan field in addition to scan and state.\n",
    "\n",
    "-   *maxuvdistance*: In the case of **mstransform**, when *maxuvdistance* is greater than 0 this parameter controls the maximum uv distance allowed when averaging data from the same baseline. It works in conjunction with the *timebin* parameter in the sense that the averaging process is finalized when either *timebin* is completed or *maxuvdistance* is reached. The details of the baseline dependent averaging algorithm are available here:\n",
    "\n",
    "    <ftp://ftp.cv.nrao.edu/NRAO-staff/bcotton/Obit/BLAverage.pdf>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. Effects\\ of\\ Baseline\\ Dependent\\ Time\\ Averaging\\ of\\ UV\\ Data\\ by\\ W.D.\\ Cotton\\ (OBIT\\ No.\\ 13,\\ 2008).\\ \n",
    "2. Data\\ Reduction\\ and\\ Error\\ Analysis\\ by\\ Bevington\\ &\\ Robinson\\ (3rd\\ Ed.,\\ McGraw\\ Hill,\\ 2003)\\ \n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Channel average \n",
    "\n",
    "Channel averaging highlights using mstransform and split\n",
    "\n",
    "Both **mstransform** & **split** support averaging data by frequency channel.  In **split** the amount of channel averaging (if any) is set by top-level parameter *width*.\n",
    "\n",
    "```\n",
    "width  = 1     #Number of channels to average to form one output channel\n",
    "```\n",
    "\n",
    "In **mstransform** this capability is accessed by specifying *chanaverage=True* and setting the resulting sub-parameter *chanbin*, as shown here:  \n",
    "\n",
    "```\n",
    "chanaverage = True      #Average data in channels.\n",
    "chanbin     = 1         #Width (bin) of input channels to average to form an output channel.\n",
    "```\n",
    "\n",
    "Some new features of split / mstransform relative to the old implementation of split are as follows\n",
    "\n",
    "-   Whereas the old version of split performed a flat average taking into account only the *FLAG* column, **mstransform** / **split** use both *FLAG* and spectral weights (when present), resulting in a weighted average. To be specific *WEIGHT_SPECTRUM* is used when averaging *CORRECTED_DATA*, and *SIGMA_SPECTRUM* is used when averaging the *DATA* column.\n",
    "-   Also **mstransform** / **split** are able to transform the input *WEIGHT/SIGMA_SPECTRUM* according to the rules of error propagation that apply to a weighted average, which result in an output weight equals to the sum of the input weights. For a detailed reference see, *Data Reduction and Error Analysis* [\\[1\\]](#Bibliography).\n",
    "-   Both **mstransform** / **split** drop the last output channel bin when there are not enough contributors to fully populate it. For instance, if the input SPW has 128 channels and *chanbin* is 10, the resulting averaged SPW would have 12 channels and not 13 channels.\n",
    "\n",
    "The chanbin parameter can be either a scalar or a vector. In the former case, the same chanbin is applied to all the spectral windows. In the second case, each element of the chanbin vector will apply to the selected spectral windows. Obviously the size of the chanbin vector and the number of selected spectral windows have to match.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "If spw combination and channel average are used together (combinespws=True, chanaverage = True), the chanbin parameter can only be a scalar. This is due to the fact that channel average applies to the already spw combined MS, which contains one single spw.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. Bevington\\ &\\ Robinson,\\ 3rd\\ Ed.,\\ McGraw\\ Hill,\\ 2003\\ \n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flags and data-averaging \n",
    "\n",
    "How flags are treated and propagated when using data average (time or channel average).\n",
    "\n",
    "CASA uses common infrastructure to implement data average transformations across different tasks. This infrastructure follows certain common rules to propagate flags from the original data to the averaged data. This page explains the common rules that different CASA tasks follow to produce the flags of averaged data; in other words, these rules dictate how data averaging transformations propagate the flags from the original data to the averaged data. \n",
    "\n",
    "These rules apply to [channel average](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/channel-average) and [time average](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/time-average), as implemented by\n",
    "\n",
    "-   tasks such as **mstransform** and **split**, to output averaged MeasurementSets, or\n",
    "-   tasks such as **flagdata** and **plotms**, to transform data on-the-fly and then modify the flags in the input MeasurementSets.\n",
    "\n",
    "In short, the rule that CASA follows for the propagation of flags from the original input data to the averaged data is a logical AND. This is detailed in the next section. The second subsection explains how tasks such as flagdata and plotms propagate back the averaged flags to the input MeasurementSet.\n",
    "\n",
    "In what follows we explain how CASA treats flags and data when using data averaging. By the term *data*, we refer to the data columns present in a MeasurementSet (DATA, CORRECTED_DATA, etc.). The data always have a companion FLAG column, with matching dimensions. The data also have other companion columns related to weights: WEIGHT, SIGMA, WEIGHT_SPECTRUM, SIGMA_SPECTRUM. The focus of this page is on data flags. But data average, and the use of the data weights in the average, also plays a role in the explanations below. The treatment of data weights in CASA is explained in more detail in [Data weights](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-weights).\n",
    "\n",
    "##### Propagation of flags from the original data to the averaged data\n",
    "\n",
    "For a given bin of input data and flags, the averaged flags are calculated as the logical \\\"AND\\\" of all the flags in the input bin (timebin or chanbin). The averaged flag will be set only if all the flags in the input bin are set.Let us first illustrate this with examples. For simplicity we consider some examples of channel average.The flags for every data channel are represented by an \\'X\\' (flag set) or a \\'O\\' (flag unset). There are 12 channels and we try different channel bins:\n",
    "\n",
    "    Flags in the input bin  ------------> averaged flags\n",
    "    ----------------------------------------------------\n",
    "\n",
    "                             chanbin=2\n",
    "    X X X O O X X X X X O X ------------> X O O X X O\n",
    "\n",
    "                             chanbin=3\n",
    "                            ------------> X O X O\n",
    "\n",
    "                             chanbin=4\n",
    "                            ------------> O O O\n",
    "\n",
    "The implication of this AND rule is that after applying the averaging transformation the percentage of data flagged can only remain the same or decrease. And it will tend to decrease more as the bin size increases. It will also tend to decrease more for more sparse patterns of original flags. In an averaged dataset one should expect a lower percentage of flags, proportionally to the bin size used and the sparseness of the flags of the original data.\n",
    "\n",
    "For time average the same principle applies, on a per-baseline basis, with the only difference that the bins are defined across time instead of channels.\n",
    "\n",
    "###### The AND rule of propagation of flags to the averaged data\n",
    "\n",
    "The logical \\\"AND\\\" rule can be formulated as follows. Let us consider a bin size $n$, and original data $d_i, i=0,... n-1$, with associated flags, $f_i$. Every subindex $_i$ corresponds to a value of the data column for a given baseline, time and channel. As a convention, $f_i = 1$ when the flag is set, and $f_i = 0$ when the flag is not set.For every data point produced in the averaged data, $d_{avg}$, its flag, $f_{avg}$, is calculated as:$f_{avg} = \\prod_{i=0}^{n-1} f_i$That is, the value of the averaged flag is defined as the product of the values of the flags in the input bin.\n",
    "\n",
    "###### How flags and data are averaged\n",
    "\n",
    "Does the \\\"AND\\\" rule mean that flagged data becomes unflagged via averaging? No, this doesn\\'t mean that CASA uses flagged data or unsets the flags of the initially flagged data. If any data point in the input bin is not flagged, the averaged data point will be not flagged. But this does not imply that flagged data is propagated to the averaged data. When one or more of the data in the input bin are no flagged, only the data that are not flagged are used in the average. The flagged data in the original bin are excluded from the average. These are the two possible scenarios:\n",
    "\n",
    "A\\) If one or more unflagged data points can be found in the input bin, the averaged data will be produced as follows:\n",
    "\n",
    "-   averaged data: calculated as the average of the input data points that are not flagged.\n",
    "-   averaged flag: not set\n",
    "\n",
    "B\\) Only if all the data points in the input bin are flagged, then the averaged data will be produced as follows:\n",
    "\n",
    "-   averaged data: calculated as the average of all the input data in the bin (all flagged).\n",
    "-   averaged flag: set\n",
    "\n",
    "To define an equation of data averaging with flags, let us now consider the data weights. A bin of $n$ data points $d_i, i=0,...n-1$, with flags $f_i$, are averaged into an average data point $d_{avg}$ with flag $f_{avg}$. The $d_i$ are the visibility data and the $w_i$ are their respective weights. CASA calculates the averaged data, $d_{avg}$ as:$d_{avg}= f_{avg} \\times \\sum_{i=0}^{n-1} w_i d_i  + (1-f_{avg}) \\times \\sum_{i=0}^{n-1} (1-f_i) w_i d_i = \\prod_{i=0}^{n-1} f_i \\times \\sum_{i=0}^{n-1} w_i d_i  +  (1-\\prod_{i=0}^{n-1} f_i) \\times \\sum_{i=0}^{n-1} (1-f_i) w_i d_i $\n",
    "\n",
    "There are two terms, and they are mutually exclusive\n",
    "\n",
    "-   The first one represents the case where all input data are flagged (scenario B above). The output averaged data is flagged and the averaged data is calculated from all the input data in the bin.\n",
    "-   The second term represents the case where some input data are not flagged (scenario A). The output averaged data is not flagged and the data is calculated as the average of all the unflagged input data in the bin.\n",
    "\n",
    "In any case, data that is flagged in the input data is either:a) never propagated or used after the data average (when there is other not flagged data in the bin),b) propagated but kept flagged (when all the data in the bin are flagged).\n",
    "\n",
    "##### Writing and (back)propagation of flags from the averaged data to the original data (input MeasurementSet)\n",
    "\n",
    "This section concerns tasks such as flagdata or plotms which can apply on-the-fly average, either time or frequency, flag and/or unflag data, and write the averaged flags back to the original  MeasurementSet. These tasks have the additional complexity that they need to be able to propagate back to the original MeasurementSet flags from averaged data+flags that have been transformed on-the-fly. A reverse or backward propagation is required to map the averaged flags to the original MeasurementSet.These tasks can perform the following sequence of data manipulation steps, all in one go:a) Take an input MeasurementSet and apply averaging on the data+flags.b) Edit or modify the averaged flags.c) Write the edited averaged flags back to the original input MeasurementSet.Since CASA 5.7/6.1, CASA implements two alternative approaches to step c:1) flagdata alternative: preserve pre-existing flags, flags can be added (set) but never removed (unset).2) plotms alternative: flags can be added (set) but also removed (unset).Flagdata will only add new flags (true or 1) to the original data. It will never unset a previously set flag.This is implemented as follows. If an averaged flag is set, the flag is propagated back to all the original flags in the corresponding input bin. If an averaged flag is not set, nothing is done, and the flags that might be set in the corresponding input bin remain set. As a consequence, a flagdata command that uses data average will only increase the amount of flags in the input MeasurmentSet (or simply keep the same amount, if the flagging methods applied do not add any new flags). This way, all original flags are preserved in the input MeasurementSet.In contrast, plotms will write back to the input MeasurementSet both true (1) and false (0) flag values. That is, plotms can set and unset flags, and the initially set flags in the input MeasurementSet are not necessarily preserved.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split UV-data \n",
    "\n",
    "Breaking out a subset of visibility data using split and mstransform\n",
    "\n",
    "The **split** task selects a subset of data from a MeasurementSet and creates a new MS with only those selected data.  All of the usual selection criteria can be applied (field, spectral window, antenna, time range, etc.). Additionally the user can choose to select only a single column of data (typically CORRECTED); the user may also elect to export all data columns (DATA, MODEL, CORRECTED, FLOAT_DATA). If only a single column is selected, it will  appear as the DATA column in the output MS, unless the input *datacolumn* is set to FLOAT_DATA. In this case the output column will also be FLOAT_DATA. This suite of capabilities is of great utility for creating smaller MeasurementSets for imaging and further analysis. It is also helpful in many circumstances to facilitate self-calibration, since the **gaincal** task operates from the DATA column. \n",
    "\n",
    " The top-level inputs of **split** are:\n",
    "\n",
    "```\n",
    "CASA <1>: inp split\n",
    "split :: Create a visibility subset from an existing visibility set\n",
    "\n",
    "vis           =     ''            #Name of input MeasurementSet or Multi-MS\n",
    "outputvis     =     ''            #Name of output MeasurementSet or Multi-MS\n",
    "keepmms       =     True          #If the input is a Multi-MS the output will also be a Multi-MS\n",
    "field         =     ''            #Select field using ID(s) or name(s)\n",
    "spw           =     ''            #Select spectral window/channels\n",
    "scan          =     ''            #Select data by scan numbers\n",
    "antenna       =     ''            #Select data based on antenna/baseline\n",
    "correlation   =     ''            #Correlation: '' ==> all, correlation='XX,YY'\n",
    "timerange     =     ''            #Select data by time range\n",
    "intent        =     ''            #Select data by scan intent.\n",
    "array         =     ''            #Select (sub)array by array ID number(s)\n",
    "uvrange       =     ''            #Select data bt baseline length\n",
    "observation   =     ''            #Select data by observation ID(s).\n",
    "feed          =     ''            #Multi-feed numbers: Not yet implemented.\n",
    "datacolumn    =     'corrected'   #Which data column(s) to process\n",
    "keepflags     =     True          #Keep *completely flagged rows* instead of dropping them\n",
    "width         =     1             #Number of channels to average to form one output channel\n",
    "timebin       =     '0s'          #Bin width for time averaging\n",
    "```\n",
    "\n",
    "Usually you will run **split** with *datacolumn='corrected'* as previous operations (e.g. **applycal**) will have placed the calibrated data in the *CORRECTED_DATA* column of the MS. This will produce a new MS with this *CORRECTED_DATA* in its *DATA* column. The modes available in *datacolumn* are:\n",
    "\n",
    "```\n",
    "corrected\n",
    "data\n",
    "model\n",
    "data,model,corrected\n",
    "float_data\n",
    "lag_data\n",
    "float_data,data\n",
    "lag_data,data\n",
    "all\n",
    "#float_data is used for single dish processing\n",
    "```\n",
    "\n",
    "For example, to split out 46 channels (5-50) from spw 1 of our NGC5921 calibrated dataset:\n",
    "\n",
    "```\n",
    "split(vis='ngc5921.usecase.ms',\n",
    "outputvis='ngc5921.split.ms',\n",
    "field='2', #Output NGC5921 data (field 2)\n",
    "spw='0:5~50', #Select 46 chans from spw 0\n",
    "datacolumn='corrected') #Take the calibrated data column\n",
    "```\n",
    "\n",
    "Starting in CASA 4.6.0, **split2** has been renamed to **split** and became the default in CASA. The previous implementation of **split** is still available under the name **oldsplit**. The interface of both implementations is the same, but the new **split** uses the MSTransform framework underneath. See the \\\"[Manipulating Visibilities with MSTransform](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/uv-manipulation/manipulating-visibilities-with-mstransform)\\\" chapter for detailed information on mstransform.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average in split \n",
    "\n",
    "Highlights on averaging using split\n",
    "\n",
    "Time and channel averaging are available within **split** using the *timebin* and *width* parameters. The way that time averaging operates can be further controlled by *combine*, which is a sub-parameter of *timebin.*\n",
    "\n",
    "The *timebin* parameter gives the averaging interval. It takes a quantity, e.g. *timebin=\\'30s\\'* for 30-second time averaging.  By default the time-span of time averaging will be limited by scan boundaries, *i.e.* the time average will not be extended to average data from multiple scans together. Similarly, time averaging will by default not extend across state boundaries (states are telescope-specific entities; for ALMA a state corresponds to a sub-scan).  These default limits on time averaging can be modified by setting *combine* to \\'*scan\\'*, \\'*state\\'*, or \\'*state,scan\\'* to ignore one or both types of boundaries and average across them.  *combine* is a sub-parameter of *timebin* which is enabled by selecting a non-zero time averaging interval.\n",
    "\n",
    "The *width* parameter defines the number of channels to average to form a given output channel. This can be specified globally for all spw, e.g.\n",
    "\n",
    "```\n",
    "width = 5\n",
    "```\n",
    "\n",
    "or specified per spw, e.g.\n",
    "\n",
    "```\n",
    "width = [2,3]\n",
    "```\n",
    "\n",
    "to average 2 channels of 1st spectral window selected and 3 in the second one.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "ALERT: When averaging channels **split** will produce negative channel widths (as reported by **listobs**) if frequency goes down with increasing channel number, whether or not the input channel widths are negative. The *band*widths and channel resolutions will still be positive.\"\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recalculate UVW Values \n",
    "\n",
    "How to recalculate uvw values using fixvis\n",
    "\n",
    "Sometimes the u,v,w coordinates of a MeasurementSet are not recorded correctly by the correlator. For instance, if the catalog position of a phase calibrator is in error, the control system will place the phase center on this erroneous position. Although the actual wavefront from the quasar will not be coming from the phase center, the normal calibration process will adjust all the phases to place the quasar there (because the default model is a point source at the phase center), which will yield science target images with wrong absolute positions.\n",
    "\n",
    "To fix this problem, you can use **fixvis** to shift the raw data on the phase calibrator to have the correct phase center so that your science target will then come out with the correct position. This technique was used in the [Band 9 ALMA SV data on IRAS16293](https://casaguides.nrao.edu/index.php/IRAS16293_Band9_-_Calibration_for_CASA_4.0).\n",
    "\n",
    "One useful feature of **fixvis** is that it can change the phase center of a MeasurementSet. This can be done with absolute coordinates or using offsets. An example is:\n",
    "\n",
    "```\n",
    "fixvis(vis='ngc3256.ms',outpuvis='ngc3256-fixed.ms',field='NGC3256', phasecenter='J2000 10h27m51.6s -43d54m18s')\n",
    "```\n",
    "\n",
    "which will recalculate the u,v,w coordinates relative to the new phase center for the field 'NGC3256'. Invoking **fixvis** as follows will instead re-calculate the (u,v,w) values using the existing phase center in the FIELD table of the MS \\-- \n",
    "\n",
    "```\n",
    "fixvis(vis='ngc3256.ms',outpuvis='ngc3256-fixed.ms',field='NGC3256')\n",
    "```\n",
    "\n",
    "Other parameters **fixvis** accepts are as follows \\-- \n",
    "\n",
    "```\n",
    "fixvis :: Recalculates (u, v, w) and/or changes Phase Center\n",
    "\n",
    "vis = '' #Name of the input visibility set.\n",
    "\n",
    "outputvis = '' #Name of the output visibility set. (Can be the same #as vis.)\n",
    "\n",
    "field = '' #Fields to operate on. = all.\n",
    "\n",
    "refcode = '' #reference frame to convert UVW coordinates to\n",
    "\n",
    "reuse = True #base UVW calculation on the old values?\n",
    "\n",
    "phasecenter = '' #use this direction as phase center\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hanning Smooth UV-data \n",
    "\n",
    "Highlights on Hanning smoothing of data using task hanningsmooth\n",
    "\n",
    "For strong spectral line sources (like RFI sources), the Gibbs phenomenon may cause ringing across the frequency channels of an observation. This is called the Gibbs phenomenon and a proven remedy is the Hanning smoothing algorithm. Hanning smoothing is a running mean across the spectral axis with a triangle as a smoothing kernel. The central channel is weighted by 0.5 and the two adjacent channels by 0.25 to preserve the flux; mathematically this is an N=5 sample Hann window kernel (including the outer-most zero-weight samples in the window). Hanning smoothing significantly reduces Gibbs ringing at the price of a factor of two in spectral resolution. Users should also be aware that it will introduce noise correlations between channels which can affect the interpretation of cross-channel chi-squared or uv-model fitting analyses.\n",
    "\n",
    "The new **hanningsmooth** task (based on **mstransform**) does not write to the input MS, but it always creates an output MS. It can also handle a Multi-MS and process it in parallel (see more information [here](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing/testing-using-multi-ms)).\n",
    "\n",
    "In CASA, the **hanningsmooth** task will apply Hanning smoothing to a spectral line uv data MeasurementSet. The inputs are:\n",
    "\n",
    "```\n",
    "#hanningsmooth :: Hanning smooth frequency channel data to remove Gibbs ringing\n",
    "vis                 =         ''        #Name of input MeasurementSet or Multi-MS.\n",
    "outputvis           =         ''        #Name of output MeasurementSet or Multi-MS.\n",
    "keepmms             =       True        #If the input is a Multi-MS the output will also\n",
    "                                           be a Multi-MS.\n",
    "field               =         ''        #Select field using ID(s) or name(s).\n",
    "spw                 =         ''        #Select spectral window/channels.\n",
    "scan                =         ''        #Select data by scan numbers.\n",
    "antenna             =         ''        #Select data based on antenna/baseline.\n",
    "correlation         =         ''        #Correlation: '' ==> all, correlation='XX,YY'.\n",
    "timerange           =         ''        #Select data by time range.\n",
    "intent              =         ''        #Select data by scan intent.\n",
    "array               =         ''        #Select (sub)array(s) by array ID number.\n",
    "uvrange             =         ''        #Select data by baseline length.\n",
    "observation         =         ''        #Select by observation ID(s).\n",
    "feed                =         ''        #Multi-feed numbers: Not yet implemented.\n",
    "datacolumn          =      'all'        #Input data column(s) to process.\n",
    "```\n",
    "\n",
    "The *datacolumn* parameter determines which of the data columns is to be Hanning smoothed: 'all', 'model', 'corrected', 'data', 'float_data' or 'lag_data'. 'all' will use whichever of the visibility data columns that are present in the input MS. If 'corrected' is specified, the task will smooth the input *CORRECTED_DATA* column and save the smoothed data in *DATA* of the output MS.\n",
    "\n",
    "The Hanning smoothing transformation in **mstransform** is available via a single parameter, as shown below:\n",
    "\n",
    "```\n",
    "#Hanning smooth in mstransform\n",
    "hanning   = True        #Hanning smooth data to remove Gibbs ringing\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regrid Frequency/Velocity \n",
    "\n",
    "Spectral regridding of the MS (cvel)\n",
    "\n",
    "Although not strictly a calibration operation, spectral regridding of a MS is available to aid in calibration operations (e.g. continuum subtraction) and preparation for imaging. For this purpose, the **cvel** task has been developed.\n",
    "\n",
    "The inputs are:\n",
    "\n",
    "```\n",
    "#cvel :: regrid an MS to a new spectral window / channel structure or frame\n",
    "vis                 =         ''        #Name of input MeasurementSet\n",
    "outputvis           =         ''        #Name of output MeasurementSet\n",
    "passall             =      False        #Pass through (write to output MS) non-selected data with\n",
    "                                        #no change\n",
    "field               =         ''        #Select field using field id(s) or field name(s)\n",
    "spw                 =         ''        #Select spectral window/channels\n",
    "selectdata          =       True        #Other data selection parameters\n",
    "timerange           =         ''        #Range of time to select from data\n",
    "array               =         ''        #(sub)array indices\n",
    "antenna             =         ''        #Select data based on antenna/baseline\n",
    "scan                =         ''        #scan number range\n",
    "\n",
    "mode                =  'channel'        #Regridding mode\n",
    "nchan               =         -1        #Number of channels in output spw (-1=all)\n",
    "start               =          0        #first input channel to use\n",
    "width               =          1        #Number of input channels to average\n",
    "interpolation       =   'linear'        #Spectral interpolation method\n",
    "\n",
    "phasecenter         =         ''        #Image phase center: position or field index\n",
    "restfreq            =         ''        #rest frequency (see help)\n",
    "outframe            =         ''        #Output frame (not case-sensitive, ''=keep input frame)\n",
    "veltype             =    'radio'        #velocity definition\n",
    "hanning             =      False        #If true, Hanning smooth data before regridding to remove\n",
    "                                        #Gibbs ringing.\n",
    "```\n",
    "\n",
    "The key parameters for the operation of **cvel** are the regridding *mode*, the output reference *outframe*, *veltype*, *restfreq* and the standard selection parameters (in particular *spw* and *field*).\n",
    "\n",
    "The syntax for mode options ('*channel*','*velocity*','*frequency*','*channel_b*') has been made compatible with the respective modes of **clean**. The combination of selected *spw* and *mode* will determine the output channels and spw(s):\n",
    "\n",
    "```\n",
    "    spw = '0,1'; mode = 'channel'  \n",
    "       #will produce a single spw containing all channels in spw 0 and 1  \n",
    "    spw='0:5~28^2'; mode = 'channel'  \n",
    "       #will produce a single spw made with channels (5,7,9,...,25,27)  \n",
    "    spw = '0'; mode = 'channel': nchan=3; start=5; width=4  \n",
    "       #will produce an spw with 3 output channels  \n",
    "       #new channel 1 contains data from channels (5+6+7+8)  \n",
    "       #new channel 2 contains data from channels (9+10+11+12)  \n",
    "       #new channel 3 contains data from channels (13+14+15+16)  \n",
    "    spw = '0:0~63^3'; mode='channel'; nchan=21; start = 0; width = 1  \n",
    "       #will produce an spw with 21 channels  \n",
    "       #new channel 1 contains data from channel 0  \n",
    "       #new channel 2 contains data from channel 2  \n",
    "       #new channel 21 contains data from channel 61  \n",
    "    spw = '0:0~40^2'; mode = 'channel'; nchan = 3; start = 5; width = 4  \n",
    "       #will produce an spw with three output channels  \n",
    "       #new channel 1 contains channels (5,7)  \n",
    "       #new channel 2 contains channels (13,15)  \n",
    "       #new channel 3 contains channels (21,23)\n",
    "```\n",
    "\n",
    "The simplest use of **cvel** is to shift a single spectral window into an output frame. This is done with *mode='channel'*. For example:\n",
    "\n",
    "```\n",
    "cvel(vis='test_w3oh_nohann.ms',\n",
    "     outputvis ='test_w3oh_nohann_chanbary.ms',\n",
    "     mode='channel',nchan=-1,start=0,width=1,\n",
    "     interpolation='linear',\n",
    "     phasecenter='',\n",
    "     spw='',\n",
    "     outframe='BARY')\n",
    "```\n",
    "\n",
    "will transform all SPWs into the BARY reference frame. This implies a \\\"software Doppler tracking\\\", i.e. the SPW definitions are transformed into the BARY frame and in the different integrations of the dataset, the visibilties are regridded into the transformed SPW accounting for the time-dependencies. E.g. if the original SPWs were in reference frame TOPO and thus the movent of the Earth w.r.t. the source will have smeared out line emission, the new SPWs will be in reference frame BARY and the effects of the movement of the Earth will have been removed but the number of channels will remain the same and the frequency resolution will be maximal. \n",
    "\n",
    "Mode *channel* is intended to not change the frequency resolution beyond the reference frame transformation or at least only change the resolution in units of whole channels. For most scientific applications we recommend using the *mode='velocity''* and *mode='frequency'* options, as it is easiest to determine what the resulting channel width will be in terms of velocity or frequency bandwidth. For example:\n",
    "\n",
    "```\n",
    "cvel(vis='test_w3oh_nohann.ms',\n",
    "     outputvis ='test_w3oh_nohann_cvellsrk.ms',\n",
    "     mode='velocity',nchan=45,start='-35.0km/s',width='-0.55km/s',\n",
    "     interpolation='linear',\n",
    "     phasecenter='',\n",
    "     spw='',\n",
    "     restfreq='1665.4018MHz',\n",
    "     outframe='LSRK')\n",
    "\n",
    "cvel(vis='test_w3oh_nohann.ms',\n",
    "     outputvis ='test_w3oh_nohann_cvelbary.ms',\n",
    "     mode='velocity',nchan=45,start='-35.0km/s',width='-0.55km/s',\n",
    "     interpolation='linear',\n",
    "     phasecenter='',\n",
    "     spw='',\n",
    "     restfreq='1665.4018MHz',\n",
    "     outframe='BARY')\n",
    "```\n",
    "\n",
    "will transform a MS into the LSRK and BARYcenter frames respectively.\n",
    "\n",
    "The sign of the *width* parameter determines whether the channels run along increasing or decreasing values of frequency or velocity (i.e. if the cube is reversed or not).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Info:** in order to permit the calculation of velocities from the internally stored frequencies, you need to provide a rest frequency in parameter *restfreq* when you operate in mode 'velocity'. This rest frequency will not be stored with the MS (as opposed to the rest frequency which you provide to the *clean* task which is subsequently stored with the image).\n",
    "</div>\n",
    "\n",
    "The intent of **cvel** regridding is to transform channel labels and the visibilities to a spectral reference frame which is appropriate for the science analysis, e.g. from *TOPO* to *LSRK*, e.g. to correct for Doppler shifts throughout the time of the observation. Naturally, this will change the shape of the spectral features to some extent. According to the Nyquist theorem you should oversample a spectrum with twice the numbers of channels to retain the shape. Based on some tests, however, we recommend to observe with at least 3-4 times the number of channels for each significant spectral feature (like 3-4 channels per linewidth). This will minimize regridding artifacts in **cvel**.\n",
    "\n",
    "If **cvel** has already established the grid that is desired for the imaging, clean should be run with the default *channel* mode (*width=1*). This will avoid additional regridding in **clean**. Hanning smoothing is optionally offered in **cvel**, but tests have shown that already the regridding process itself, if it involved a transformation from *TOPO* to a non-terrestrial reference frame, implies some smoothing (due to channel interpolation) such that Hanning smoothing may not be necessary.\n",
    "\n",
    "The interpolation method **fftshift** calculates the transformed visibilities by applying a FFT, then a phase ramp, and then an inverse FFT. Note that if you want to use this interpolation method, your frequency grid needs to be equidistant, i.e. it only works in mode velocity with *veltype=radio*, in mode frequency, and in mode channel (in the latter only if the input grid is itself equidistant in frequency). Note also that, as opposed to all other interpolation methods, this method will apply a constant (frequency-independent) shift in frequency which is not fully correct in the case of large fractional bandwidth of the given spectral window.\n",
    "\n",
    "The task **cvel** can also be used to transform spectral windows into the rest frame of the ephemeris object by setting the parameter *outframe* to \"SOURCE\" as in the following example:\n",
    "\n",
    "```\n",
    "cvel(vis='europa.ms', outputvis='cvel_europa.ms', outframe='SOURCE')\n",
    "```\n",
    "\n",
    "This will make **cvel** perform a transformation to the GEO reference frame followed by an additional Doppler correction for the radial velocity given by the ephemeris for the each field. (Typically, this should happen after calibration and after splitting out the spectral widows and the target of interest). The result is an MS with a single combined spectral window in reference frame REST. From this frame, further transformations to other reference frames are not possible.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine MeasurementSets \n",
    "\n",
    "Concatenating multiple datasets (concat and virtualconcat)\n",
    "\n",
    "Once you have your data in the form of CASA MeasurementSets, you can go ahead and process your data using the editing, calibration, and imaging tasks. In some cases, you will most efficiently operate on single MS for a particular session (such as calibration). Some tasks can take multiple MeasurementSets as input. For others, it is easiest to combine your multiple data files into one.\n",
    "\n",
    "If you need to combine multiple datasets, you can use the **concat** task. The default inputs are:\n",
    "\n",
    "```\n",
    "#concat :: Concatenate several visibility data sets.\n",
    "vis                     =   ['']    #Name of input visibility files to be concatenated\n",
    "concatvis               =    ''     #Name of output visibility file\n",
    "freqtol                 =    ''     #Frequency shift tolerance for considering data as the same spwid\n",
    "dirtol                  =    ''     #Direction shift tolerance for considering data as the same field\n",
    "respectname             =  False    #If true, fields with a different name are not merged even if their direction agrees\n",
    "timesort                =  False    #If true, sort by TIME in ascending order\n",
    "copypointing            =   True    #Copy all rows of the POINTING table.\n",
    "visweightscale          =    []     #List of the weight scaling factors to be applied to the individual MSs\n",
    "forcesingleephemfield   =    ''     #make sure that there is only one joint ephemeris for every field in this list\n",
    "```\n",
    "\n",
    "The *vis* parameter will take the list of MSs to combine. **concat** will presort them in time.\n",
    "\n",
    "With *visweightscale*, a list of weights can be manually specified for the respective input data sets. They will be applied at the time of the combination. To determine the appropriate weights for this procedure, one can inspect the weights (\\'Wt\\' and \\'WtSp\\' axis inputs) of the input datasets in **plotms**. The weights of the individual MSs will be scaled in the concatenated output MS by the factors in this list. SIGMA will be multiplied by 1/sqrt(factor) (i.e. the weights will be multiplied by factor). This capability can be useful for handling heterogeneous arrays, depending on how the weights were intially estimated and set.\n",
    "\n",
    "The *concatvis* parameter contains the name of the output MS. If this points to an existing file on disk, then the MS in vis will appended to it, otherwise a new MS file is created to contain the concatenated data. Be careful here!\n",
    "\n",
    "The *timesort* parameter can be used to make sure the output MS is in time order (e.g. if your input MS have concurrent times). This can possibly speed up some subsequent calibration operations.\n",
    "\n",
    "Furthermore, the parameter *copypointing* can be used to control whether the *POINTING* table will be carried along in the concatenation process or if the output MS should not contain a *POINTING* table. This table is quite large for some data (e.g. ALMA) and is mainly needed for mosaic imaging. If you are certain that you will not need it, you can save time and diskspace by setting *copypointing*=*False*.\n",
    "\n",
    "For ALMA and VLA data, **importasdm** will fill the correct coordinates from ephemerides data into the *SOURCE* table. And, as stated in the [ephemeris](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/ephemeris-data) section, **concat** will correctly merge fields which use the same ephemeris.\n",
    "\n",
    "Using the parameter *forcesingleephemfield,* you can control whether the attached tabulated ephemerides are merged into one. By default, **concat** will only merge two ephemeris fields if the first ephemeris covers the time range of the second. Otherwise, two separate fields with separate ephemerides are placed in the output MS. In order to override this behaviour and make **concat** merge the non-overlapping or only partially overlapping input ephemerides, the name or id of the field in question needs to be placed into the list in parameter *forcesingleephemfield*. Example: *forcesingleephemfield=\\'Neptune\\'* - will make sure that there is only one joint ephemeris for field Neptune in the output MS.\n",
    "\n",
    "The parameters *freqtol* and *dirtol* control how close together in frequency and angle on the sky spectral windows or field locations need to be before calling them the same.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT:** If multiple frequencies or pointings are combined using *freqtol* or *dirtol*, then the data are not changed (i.e. not rephased to the single phase center). Use of these parameters is intended to be tolerant of small offsets (e.g. planets tracked which move slightly in J2000 over the course of observations, or combining epochs observed with slightly different positions).\n",
    "</div>\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    "default('concat')\n",
    "vis = ['n4826_16apr.split.ms','n4826_22apr.split.ms']\n",
    "concatvis = 'n4826_tboth.ms'\n",
    "freqtol = '50MHz'\n",
    "visweightscale=['1','2']\n",
    "concat()\n",
    "```\n",
    "\n",
    "combines the two days in n4826_16apr.split.ms and n4826_22apr.split.ms into a new output MS called n4826_tboth.ms, and the second MS is weighted twice the first one.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT:** If you are concatenating MSs which use antennas which were moved between observations, the MS definition does only foresee a unique antenna ID, but not a unique name(!). The moved antenna will appear twice in the antenna list under the same name but on different stations and with two different IDs. The pair ('*NAME@STATION*') will be the unique identifier.\n",
    "</div>\n",
    "\n",
    "If you would like to only concatenate the subtables of several MSs, not the bulk visibility data, you can use the task **testconcat** instead of **concat** to save time and diskspace. **testconcat** has the same parameters as **concat**. It produces an output MS with the concatenated subtables and an empty *MAIN* table.\n",
    "\n",
    "Furthermore, the task **virtualconcat** permits to concatenate MSs into a [multi-MS](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing/the-multi-ms) (MMS) which is much faster as the data is moved into the MMS rather than copied and only some reindexing is done. The bulk data is not rewritten. If you want to keep a copy of the original MSs, set the parameter *keepcopy* of **virtualconcat** to True. The creation of that copy will of course consume some of the time you saved by doing a virtual concatenation. Otherwise **virtualconcat** offers the same functionality as **concat**.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UV Continuum Subraction \n",
    "\n",
    "Visibility-plane based continuum subtraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Introduction\n",
    "\n",
    "After general calibration is done and if there is significant continuum emission present in what is intended as a spectral line observation, continuum subtraction may be desirable. You can estimate and subtract continuum emission in the $uv$-plane prior to imaging or wait and subtract an estimate of it in the image-plane. Note that neither method is ideal, and the choice depends primarily upon the distribution and strength of the continuum emission. Subtraction in the $uv$-plane is desirable if continuum emission dominates the source, since deconvolution of the line emission will be more robust if it not subject to the deconvolution errors of the brighter continuum. There is also a performance benefit since the continuum is nearly the same in each channel of the observation, and it is desirable to avoid repeating its deconvolution in each channel. However, doing the continuum estimation in the $uv$-plane has the serious drawback that interpolating visibilities between channels is only a good approximation for emission from near the phase center. Thus, $uv$-plane based continuum subtraction will do an increasingly poor job for emission distributed further from the phase center. If the continuum emission is relatively weak, it is usually adequate to subtract it in the image plane; this is described in the Image Analysis section of this document. Here, we describe how to do continuum subtraction in the $uv$-plane.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Concept\n",
    "\n",
    "A good review of different approaches to the subtraction of the continuum emission is found in Cornwell, Uson & Haddad (1992) [\\[1\\].](#Bibliography)\n",
    "\n",
    "Sault (1994) [\\[2\\]](#Bibliography) gives the detailed analysis of the $uv$-plane based algorithms. We assume here that the sky brightness $I_\\nu$ at a sky position $(l,m)$ is composed of the continuum (C) and line (L) emission such that $I_\\nu(l,m)=C_\\nu(l,m)+L_\\nu(l,m)$. The continuum is estimated from fitting a polynomial selecting only \\\"line-free\\\" channels. The fitting of the visibiity spectrum is generally done for each sampling and separately for real and imaginary parts to make it a  linear process. Then the polynomial continuum model is subtracted from all channels.\n",
    "\n",
    "This technique is known to work well when the dominant continuum source is at or near phase center. Its effectiveness tends to decline as distance to the source location with respect to the phase center increases and thus residual continuum left in the subtracted data increases. The effectiveness which has the same expression as in bandwidth smearing, can be parameterized as $\\eta=\\frac{\\Delta\\nu}{\\nu}\\frac{l_{0}}{\\theta_{synth}}$ in terms of the the distance in the synthesized beam ($l_{0}/\\theta_{synth}$) from the phase center,  where $\\nu$ and 2$\\Delta\\nu$ are the observing frequency and the bandwidth, respectively. In order to the method to work well, $\\eta<<1$ must be met. If the brightest continuum emission lies beyond $\\frac{\\nu}{\\Delta\\nu}$ beams from the phase center the source need to be shifted before fitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CASA implementations\n",
    "\n",
    "Currently tasks to do $uv$-plane continuum subtraction are available in uvcontsub, uvcontsub3 and mstransform. All of these tasks are based on the same basic concept described above and achieve essentially the same output but are based on different C++ implementations. uvcontsub has been used as the standard task to do this job and it is based on calibrator tool (\\'cb\\') to solve for continuum by fitting a polynomial. It creates \\'A\\'-type (\\'additive noise\\') caltable which will be deleted before the task exit ) and this solution is applied to correct (or subtract) the rest of the data.uvconstub3 is an experimental task  built with C++ methods outside the calibrator tool in order to eliminate some of extra IOs involve in use of the cb tool. More recently mstransform has been developed to consolidate all visibility data manipulation functions to one task. A new parameter (douvcontsub) in mstransform is available in CASA 4.7 or higher. The current plan is for mstransform to eventually replace uvcontsub and uvcontsub3.\n",
    "\n",
    "In terms of parallelisation, only uvcontsub and the mstransform implementation (parameter douvcontsub) can process the input in parallel using the [mpi4casa framework](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing). See some notes here on how to handle [special cases in parallel](https://casa.nrao.edu/casadocs-devel/stable/parallel-processing/parallel-calibration) using uvcontsub.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The recommended procedures\n",
    "\n",
    "The general recommended procuedures are described below.  For detailed examples on how to use the $uv$-plane continuum subtraction tasks, please refer  to the sections for each individual task. \n",
    "\n",
    "-   Finish general calibration.\n",
    "-   Use clean/tclean task on the calibrated MS to form an exploratory cube that is useful for determining the line-free channels.\n",
    "-   Use one of uv-plane continuum subutraction tasks with as low fit order as possible to estimate and subtruct the continuum from the input MS and write the continuum-subtracted MS.\n",
    "-   Use clean/tclean with the continuum subtracted data to make an image cube of the line emission; inspect for residual continuum, tweak and repeat if needed. Computing image moments in nominally line-free channels may be a useful diagnostic if your imaging requirements are stringent.\n",
    "\n",
    " \n",
    "\n",
    "##### Using uvcontsub\n",
    "\n",
    "The inputs to **uvcontsub** are:\n",
    "\n",
    "```\n",
    "\n",
    "#uvcontsub :: Continuum fitting and subtraction in the uv plane\n",
    "vis                 =         ''        #Name of input MS.  Output goes to vis + \".contsub\"\n",
    "                                        #(will be overwritten if already exists)\n",
    "field               =         ''        #Select field(s) using id(s) or name(s)\n",
    "fitspw              =         ''        #Spectral window:channel selection for fitting the\n",
    "                                        #continuum\n",
    "combine             =         ''        #Data axes to combine for the continuum estimation\n",
    "                                        #(none, or spw and/or scan)\n",
    "solint              =      'int'        #Continuum fit timescale (int recommended!)\n",
    "fitorder            =          0        #Polynomial order for the fits\n",
    "spw                 =         ''        #Spectral window selection for output\n",
    "want_cont           =      False        #Create vis + \".cont\" to hold the continuum estimate.\n",
    "```\n",
    "\n",
    "For each baseline, and over the timescale specified in *solint*, **uvcontsub** will provide a polynomial fit to the real and imaginary parts of the (continuum-only) channels specified in *fitspw* (using the standard *spw* selection syntax), and then subtract this model from all channels specified in *spw*, or from all channels in spectral windows of *fitspw* if *spw=''*. By setting the subparameter *excludechannels=True*, the channel selection in *fitspw* will be inverted. In that case one can select the line channels themselves and/or corrupted channels that are not used in the continuum fit to the data. *fitspw* can also take frequency ranges, e.g.\n",
    "```\n",
    "fitspw='*:113.767~114.528GHz;114.744~115.447GHz'\n",
    "```\n",
    "\n",
    "where '*\\**' indicates to go across all spws.Typically, low orders for the polynomial work best, like 0th (a constant), or 1st order (a linear fit). Use higher orders with caution and check your results carefully.Usually, one should set *solint='int'* which does no averaging and fits each integration. However, if the continuum emission comes from a small region around the phase center and fitorder = 0, then you can set *solint* larger (as long as it is shorter than the timescale for changes in the visibility function of the continuum). If your scans are short enough you can also use scan averaging with *combine='scan'* and *solint='inf'.* Be warned, setting solint too large will introduce \"time smearing\" in the estimated continuum and thus not properly subtract emission not at the phase center. Increasing *solint* speeds up the calculation but it does not improve the overall result quality of **uvcontsub** - although the continuum estimates of each baseline may be noisy (just like each visibility in a continuum MS may be noisy), it is better to use the ensemble of individual fits than to average the ensemble before fitting. Note that plotms can do time and baseline averaging on the fly to help you examine noisy data.\n",
    "\n",
    "uvcontsub will append \\\".contsub\\\" for the continuum subtracted MS and \\\".cont\\\" if *want_cont=True*. Although the continuum model is available with the latter parameter, we recommend to use line-free channels for creating continuum images. The interpolation across the line channels will not gain better signal-to-noise but may introduce noise or model residuals.\n",
    "\n",
    " \n",
    "\n",
    "##### Using mstranform\n",
    "\n",
    "**mstransform** has gotten support to subtract the continuum in the UV-plane using a polynomial fit along the spectral channels. This transformation can be stacked with the rest of the transformations supported by **mstransform**. To activate continum subtraction the option *douvcontsub* must be set:\n",
    "\n",
    "```\n",
    "douvcontsub = True #Enable continuum subtraction as in task **uvcontsub**\n",
    "```\n",
    "\n",
    "The most relevant parameter to fit the continuum is *fitspw*, which allows to select which channels are supposedly free of lines and therefore represent with better fidelity the continuum. The syntax of this parameter is similar to the usual syntax for the selection of spw\\'s. For instance\n",
    "\n",
    "```\n",
    "fitspw='19:5~50;100~220,20:1~100'\n",
    "```\n",
    "\n",
    "will use channels 5 to 5 and 100 to 220 when computing the continuum of spw 19. For spw 20 it will use channels 1 to 100.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "There is currently no support to fit the continuum over several spw's at the same time. You can use **uvcontsub3** task if you need that functionality.\n",
    "</div>\n",
    "\n",
    "The output MS will contain the continuum subtracted signal. If one, on the other hand, is interested in the fitted continuum itself, then the parameter *want_cont* should be set to True. Note that in this case, if there are other transformations enabled in mstransform, the subsequent transformations will work on the fitted continuum data.\n",
    "\n",
    "The algorithm implemented by **mstransform** allows to reject some outliers in the fit by doing an iterative fit. After the first fit has been obtained, the absolute residuals of each point with respect to the fit are computed and are used as weights for the next iteration. In this way outliers are usually given less and less weight in each iteration. To enable this feature, set the parameter *niter* to a value larger than 1.\n",
    "\n",
    "```\n",
    "  niter = 1 #Number of iterations for re-weighted linear fit\n",
    "```\n",
    "\n",
    "Additionally one can control the order of the polynomial fit using parameter *fitorder*\n",
    "\n",
    "```\n",
    "fitorder = 0 #Polynomial order for the fits\n",
    "```\n",
    "\n",
    "In the long term, it is foreseen that the current **uvcontusb** and **uvcontsub3** tasks are deprecated and are substituted by a new **uvcontusb** task that uses **mstransform** under the hood.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. Cornwell,\\ T.\\ J.,\\ Uson,\\ J.\\ M.,\\ &\\ Haddad,\\ N.\\ 1992,\\ A&A,\\ 258,\\ 583\\ (\n",
    "2. Sault,\\ R.\\ J.\\ 1994,\\ A&AS,\\ 107,\\ 55\\ (\n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtract/Add Model Visibilities \n",
    "\n",
    "uvsub\n",
    "\n",
    "**uvsub** is a simple task that allows one to subtract or add the MODEL_DATA column to the CORRECTED_DATA column of a given MeasurementSet. It has only 2 parameters: *vis* and *reverse.*\n",
    "\n",
    "If the CORRECTED_DATA column does not exist then it will be created first and the DATA column will be copied into it before the addition/subtraction of the MODEL_DATA is performed.\n",
    "\n",
    "The MODEL_DATA column can either be the scratch column or a virtual one; either one will work with **uvsub**. The model visibilities are usually populated by the tasks **clean**/**tclean**, **ft**, and **setjy***.*\n",
    "\n",
    "Note that **uvsub** does the subtraction over the whole ms. If only a subsection (say *field* or *spw* selection was done whiile using **clean** or **ft**) of the MS was used in these tasks that populate the model visibilities, then the **uvsub** operation will give the expected results for only those parts. The remainder of the MS will get the CORRECTED_DATA added/subtracted with whatever existed originally in the MODEL_DATA. On initialization the model visbilities are 1 for parallel hand and 0 for cross hand. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Gaussians to Visibilities \n",
    "\n",
    "Using uvmodelfit\n",
    "\n",
    "###### UV-Plane Model Fitting (**uvmodelfit**) \n",
    "\n",
    "It is often desirable to fit simple analytic source component models directly to visibility data. Such fitting has its origins in early interferometry, especially VLBI, where arrays consisted of only a few antennas and the calibration and deconvolution problems were poorly constrained. These methods overcame the calibration uncertainties by fitting the models to calibration-independent closure quantities and the deconvolution problem by drastically limiting the number of free parameters required to describe the visibilities. Today, even with larger and better calibrated arrays, it is still desirable to use visibility model fitting in order to extract geometric properties such as the positions and sizes of discrete components in radio sources. Fits for physically meaningful component shapes such as disks, rings, and optically-thin spheres, though idealized, enable connecting source geometry directly to the physics of the emission regions.\n",
    "\n",
    "Visibility model fitting is carried out by the **uvmodelfit** task. The inputs are:\n",
    "\n",
    "```\n",
    "#uvmodelfit :: Fit a single component source model to the uv data:\n",
    "vis        =   ''       #Name of input visibility file\n",
    "field      =   ''       #field name or index\n",
    "spw        =   ''       #spectral window\n",
    "selectdata =  False     #Activate data selection details\n",
    "niter      =    5       #Number of fitting iterations to execute\n",
    "comptype   =   'P'      #Component type (P=pt source,G=ell. gauss,D=ell. disk)\n",
    "sourcepar  =  [1, 0, 0] #Starting guess (flux,xoff,yoff,bmajaxrat,bpa)\n",
    "varypar    =   []       #Which parameters can vary in fit\n",
    "outfile    =   ''       #Optional output component list table\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**ALERT**: This task currently only fits a single component.  For multiple, arbitrary shaped component fitting, we refer to the [uvmultifit](https://launchpad.net/uvmultifit) [[1]](#Bibliography) software that was developed by the Nordic [ALMA Regional Center Node](https://www.oso.nordic-alma.se/software-tools.php).  \n",
    "</div>\n",
    "\n",
    "The user specifies the number of non-linear solution iterations (*niter*), the component type (*comptype*), an initial guess for the component parameters (*sourcepar*), and optionally, a vector of Booleans selecting which component parameters should be allowed to vary (*varypar*), and a filename in which to store a CASA component list for use in other applications (*outfile*). Allowed comptypes are currently point 'P' or Gaussian 'G'.\n",
    "\n",
    "The function returns a vector containing the resulting parameter list. This vector can be edited at the command line, and specified as input (*sourcepar*) for another round of fitting.\n",
    "\n",
    "The *sourcepar* parameter is currently the only way to specify the starting inputs for the fit. For points, there are three inputs: I (total flux density), and relative direction (RA, Dec) offsets (in arcsec) from the observation's phase center. For Gaussians, there are three additional inputs: the Gaussian's semi-major axis width (arcsec), the aspect ratio, and position angle (degrees). It should be understood that the quality of the result is very sensitive to the starting inputs provided by the user. If this first guess is not sufficiently close to the global χ2 minimum, the algorithm will happily converge to an incorrect local minimum. In fact, the χ2 surface, as a function of the component's relative direction inputs, has a shape very much like the inverse of the absolute value of the dirty image of the field. Any peak in this image (positive or negative) corresponds to a local χ2 minimum that could conceivable capture the fit. It is the user's responsibility to ensure that the correct minimum does the capturing.\n",
    "\n",
    "Currently, **uvmodelfit** relies on the likelihood that the source is very near the phase center (within a beamwidth) and/or the user's savvy in specifying the starting parameters. This fairly serious constraint will soon be relieved somewhat by enabling a rudimentary form of uv-plane weighting to increase the likelihood that the starting guess is on a slope in the correct χ2 valley.\n",
    "\n",
    "Improvements in the works for visibility model fitting include:\n",
    "\n",
    "-   User-specifiable uv-plane weighting\n",
    "-   Additional component shapes, including elliptical disks, rings, and optically thin spheroids.\n",
    "-   Optional calibration pre-application\n",
    "-   Multiple components. The handling of more than one component depends mostly on efficient means of managing the list itself (not easy in command line options), which are currently under development.\n",
    "-   Combined component and calibration fitting.\n",
    "\n",
    "Example (see Figure 1):\n",
    "\n",
    "```\n",
    "##Note: It's best to channel average the data if many channels #before running a modelfit #\n",
    "split('ngc5921.ms','1445+099_avg.ms', datacolumn='corrected',field='1445*',width='63')\n",
    " \n",
    "\n",
    "#Initial guess is that it's close to the phase center\n",
    "#and has a flux of 2.0 (a priori we know it's 2.47)\n",
    "uvmodelfit('1445+099_avg.ms', #use averaged data\n",
    "           niter=5, #Do 5 iterations\n",
    "           comptype='P', #P=Point source, G=Gaussian, D=Disk\n",
    "           sourcepar=[2.0,.1,.1], #Source parameters for a point source\n",
    "           spw='0',  \n",
    "           outfile='gcal.cl') #Output component list file\n",
    "```\n",
    "\n",
    "```python\n",
    "#Output looks like:\n",
    " There are 19656 - 3 = 19653 degrees of freedom.\n",
    "  iter=0: reduced chi2=0.0418509: I=2, dir=[0.1, 0.1] arcsec\n",
    "  iter=1: reduced chi2=0.003382: I=2.48562, dir=[-0.020069, -0.0268826] arcsec\n",
    "  iter=2: reduced chi2=0.00338012: I=2.48614, dir=[0.00323428, -0.00232235] arcsec\n",
    "  iter=3: reduced chi2=0.00338012: I=2.48614, dir=[0.00325324, -0.00228963] arcsec\n",
    "  iter=4: reduced chi2=0.00338012: I=2.48614, dir=[0.00325324, -0.00228963] arcsec\n",
    "  iter=5: reduced chi2=0.00338012: I=2.48614, dir=[0.00325324, -0.00228963] arcsec\n",
    " If data weights are arbitrarily scaled, the following formal errors\n",
    "  will be underestimated by at least a factor sqrt(reduced chi2). If\n",
    "  the fit is systematically poor, the errors are much worse.\n",
    " I = 2.48614 +/- 0.0176859\n",
    " x = 0.00325324 +/- 0.163019 arcsec\n",
    " y = -0.00228963 +/- 0.174458 arcsec\n",
    " Writing componentlist to file: /home/sandrock/smyers/Testing/Patch2/N5921/gcal.cl\n",
    "```\n",
    "\n",
    "```\n",
    "#Fourier transform the component list to a model of the MS\n",
    "ft('1445+099_avg.ms', complist='gcal.cl')\n",
    "\n",
    "#Plot data versus uv-distance\n",
    "plotms(vis='1445+099_avg.ms', xaxis='uvdist', datacolumn='corrected')\n",
    "\n",
    "#Plot model data versus uv-distance\n",
    "plotms(vis='1445+099_avg.ms', xaxis='uvdist', datacolumn='model')\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "The Nordic ALMA ARC node maintains the [UVMULTIFIT](http://www.oso.nordic-alma.se/software-tools.php) package that is based on CASA and which provides  addition, powerful tools for visibility modelling. See the [Nordic ARC software page](http://www.oso.nordic-alma.se/software-tools.php) and Marti-Vidal et al. (2014)  [[1]](#Bibliography) for details.\n",
    "\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    "> <div>\n",
    ">\n",
    "> ------------------------------------------------------------------------\n",
    ">\n",
    "> </div>\n",
    ">\n",
    "> <div>\n",
    ">\n",
    "> ![443dad9cdcbb6b7f6ba2b778b0137baca052e3a2](media/443dad9cdcbb6b7f6ba2b778b0137baca052e3a2.png)\n",
    ">\n",
    "> <div>\n",
    ">\n",
    ">  \n",
    ">\n",
    "> </div>\n",
    ">\n",
    "> <div>\n",
    ">\n",
    ">   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ --------\n",
    ">   Type                                                                                                                                                                                                         Figure\n",
    ">   ID                                                                                                                                                                                                           1\n",
    ">   Plot visualizing the corrected data (red and blue points) and the uv model fit (green circles). This particular plot was made using **plotxy**, which was deprecated in CASA 5.1 - use **plotms** instead.   \n",
    ">   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ --------\n",
    ">\n",
    ">  \n",
    ">\n",
    ">\n",
    ">\n",
    "> </div>\n",
    ">\n",
    "> </div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. Marti-Vidal,\\ I.,\\ Vlemmings,\\ W.\\~H.\\~T.,\\ Muller,\\ S.,\\ &\\ Casey,\\ S.\\ 2014,\\ A&A,\\ 563,\\ A136\\ (\n",
    "1. Marti-Vidal\\ et\\ al.\\ 2014,\\ A&A\\ 563,\\ 136\\ (\n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesis Calibration \n",
    "\n",
    "Synthesis calibration overview and summary of tasks\n",
    "\n",
    "** **\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction \n",
    "\n",
    "Summary of Calibration tasks, and the Outline and Philosophy of (synthesis) calibration\n",
    "\n",
    "This chapter explains how to calibrate interferometer data within the CASA task system.  Calibration is the process of determining the net complex correction factors that must be applied to each visibility in order to make them as close as possible to what an idealized interferometer would measure, such that when the data is imaged an accurate picture of the sky is obtained.  This is not an arbitrary process, and there is a philosophy behind the CASA calibration methodology.  For the most part, calibration in CASA using the tasks is not too different than calibration in other packages such as AIPS or Miriad.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calibration tasks\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** The calibration table format changed in CASA 3.4.  CASA 4.2 is the last version that will support the **caltabconvert** function that provides conversions from the pre-3.4 caltable format to the modern format; it will be removed for CASA 4.3.  In general, it is best to recalculate calibration using CASA 3.4 or later.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** In CASA 4.2 the *gaincurve* and *opacity* parameters have been removed from all calibration tasks (as advertised in 4.1).  These calibration types are supported via the gencal task.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** As part of continuing development of a more flexible and improved interface for specifying calibration for apply, a new parameter has been introduced in **applycal** and the solving tasks: *docallib*.  This parameter toggles between use of the traditional calibration apply parameters ( *gaintable*, *gainfield*, *interp*, *spwmap*, and *calwt*), and a new *callib* parameter which currently provides access to the *experimental* Cal Library mechanism, wherein calibration instructions are stored in a file.  The default remains *docallib=False* in CASA 4.5, and this reveals the traditional apply parameters which continue to work as always, and the remainder of this chapter is still written using *docallib=False*.  Users interested in the Cal Library mechanism's flexibility are encouraged to try it and report any problems; see [here](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax \"Cal Library\") for information on how to use it, including how to convert traditional applycal to Cal Library format.  Note also that **plotms** and **mstransform** now support use of the Cal Library to enable on-the-fly calibration when plotting and generating new MSs.\n",
    "</div>\n",
    "\n",
    "The standard set of calibration solving tasks (to produce calibration tables) are:\n",
    "\n",
    "-   **bandpass** \\-\\-- complex bandpass (B) calibration solving, including options for channel-binned or polynomial solutions\n",
    "-   **gaincal** \\-\\-- complex gain (G,T) and delay (K) calibration solving, including options for time-binned or spline solutions\n",
    "-   **polcal** \\-\\-- polarization calibration including leakage, cross-hand phase, and position angle\n",
    "-   **blcal** \\-\\-- *baseline-based* complex gain or bandpass calibration\n",
    "\n",
    "There are helper tasks to create, manipulate, and explore calibration tables:\n",
    "\n",
    "-   **applycal** \\-\\-- Apply calculated calibration solutions\n",
    "-   **clearcal** \\-\\-- Re-initialize the calibration for a visibility dataset\n",
    "-   **fluxscale** \\-\\-- Bootstrap the flux density scale from standard calibration sources\n",
    "-   **listcal** \\-\\-- List calibration solutions\n",
    "-   **plotcal** \\-\\-- Plot calibration solutions\n",
    "-   **plotbandpass** \\-\\-- Plot bandpass solutions\n",
    "-   **setjy** \\-\\-- Compute model visibilities with the correct flux density for a specified source\n",
    "-   **smoothcal** \\-\\-- Smooth calibration solutions derived from one or more sources\n",
    "-   **calstat** \\-\\-- Statistics of calibration solutions\n",
    "-   **gencal** \\-\\-- Create a calibration tables from metadata such as antenna position offsets, gaincurves and opacities\n",
    "-   **wvrgcal** \\-\\-- Generate a gain table based on Water Vapor Radiometer data (for ALMA)\n",
    "-   **uvcontsub** \\-\\-- Carry out uv-plane continuum fitting and subtraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Calibration Process\n",
    "\n",
    "A work-flow diagram for CASA calibration of interferometry data is shown in the following figure.  This should help you chart your course through the complex set of calibration steps.  In the following sections, we will detail the steps themselves and explain how to run the necessary tasks and tools.\n",
    "\n",
    "![3c104435002b3d4c72951b446504e8054d203d3b](media/3c104435002b3d4c72951b446504e8054d203d3b.png){.image-inline}\n",
    "\n",
    " \n",
    "\n",
    ">Flow chart of synthesis calibration operations. Not shown are use of table manipulation and plotting tasks: **plotcal** and **smoothcal**\n",
    "  \n",
    "\n",
    " \n",
    "\n",
    "The process can be broken down into a number of discrete phases:\n",
    "\n",
    "-   **Calibrator Model Visibility Specification** \\-\\-- set model visibilities for calibrators, either unit point source visibilities for calibrators with unknown flux density or structure (generally, sources used for calibrators are approximately point-like), or visibilities derived from *a priori* images and/or known or standard flux density values.  Use the **setjy** task for calibrator flux densities and models.\n",
    "-   **Prior Calibration** \\-\\-- set up previously known calibration quantities that need to be pre-applied, such antenna gain-elevation curves, atmospheric models, delays, and antenna position offsets.  Use the **gencal** task for antenna position offsets, gaincurves, antenna efficiencies, opacity, and other prior calibrations\n",
    "-   **Bandpass Calibration** \\-\\-- solve for the relative gain of the system over the frequency channels in the dataset (if needed), having pre-applied the prior calibration. Use the **bandpass** task\n",
    "-   **Gain Calibration** \\-\\-- solve for the gain variations of the system as a function of time, having pre-applied the bandpass (if needed) and prior calibration. Use the **gaincal** task\n",
    "-   **Polarization Calibration** \\-\\-- solve for polarization leakage terms and linear polarization position angle. Use the **polcal** task.\n",
    "-   **Establish Flux Density Scale** \\-\\-- if only some of the calibrators have known flux densities, then rescale gain solutions and derive flux densities of secondary calibrators.  Use the **fluxscale** task\n",
    "-   **Smooth** \\-\\-- if necessary smooth calibration using the **smoothcal** task.\n",
    "-   **Examine Calibration** \\-\\-- at any point, you can (and should) use **plotcal** and/or **listcal** to look at the calibration tables that you have created\n",
    "-   **Apply Calibration to the Data** \\-\\-- Corrected data is formed using the **applycal** task, and can be undone using **clearcal**\n",
    "-   **Post-Calibration Activities** \\-\\-- this includes the determination and subtraction of continuum signal from line data (**uvcontsub**), the splitting of data-sets into subsets (**split**, **mstransform**), and other operations (such as simple model-fitting: **uvmodelfit**).\n",
    "\n",
    "The flow chart and the above list are in a suggested order.  However, the actual order in which you will carry out these operations is somewhat fluid, and will be determined by the specific data-reduction use cases you are following.  For example, you may need to obtain an initial gain calibration on your bandpass calibrator before moving to the bandpass calibration stage.  Or perhaps the polarization leakage calibration will be known from prior service observations, and can be applied as a constituent of prior calibration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calibration Philosophy\n",
    "\n",
    "Calibration is not an arbitrary process, and there is a methodology that has been developed to carry out synthesis calibration and an algebra to describe the various corruptions that data might be subject to: the Hamaker-Bregman-Sault Measurement Equation (ME), described [here.](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/the-measurement-equation-calibration \"Measurement Equation\")   The user need not worry about the details of this mathematics as the CASA software does that for you.  Anyway, it\\'s just matrix algebra, and your familiar scalar methods of calibration (such as in AIPS) are encompassed in this more general approach.\n",
    "\n",
    "There are a number of \\`\\`physical\\'\\' components to calibration in CASA:\n",
    "\n",
    "-   **data** \\-\\-- in the form of the MeasurementSet (MS).  The MS includes a number of columns that can hold calibrated data, model information, and weights\n",
    "-   **calibration tables** \\-\\-- these are in the form of standard CASA tables, and hold the calibration solutions (or parameterizations thereof)\n",
    "-   **task parameters** \\-\\-- sometimes the calibration information is in the form of CASA task parameters that tell the calibration tasks to turn on or off various features, contain important values (such as flux densities), or list what should be done to the data.\n",
    "\n",
    "At its most basic level, Calibration in CASA is the process of taking \\\"uncalibrated\\\" **data**, setting up the operation of calibration tasks using **task parameters**, solving for new **calibration tables**, and then applying the calibration tables to form \\\"calibrated\\\" **data**.  Iteration can occur as necessary, e.g., to re-solve for an eariler **calibration table** using a better set of prior calibration, often with the aid of other non-calibration steps (e.g. imaging to generate improved source models for \\\"self-calibration\\\").\n",
    "\n",
    "The calibration tables are the currency that is exchanged between the calibration tasks.  The \\\"solver\\\" tasks (**gaincal**, **bandpass**, **blcal**, **polcal**) take in the MS (which may have a calibration model attached) and previous calibration tables, and will output an \\\"incremental\\\" calibration table (it is incremental to the previous calibration, if any).  This table can then be smoothed using **smoothcal** if desired.\n",
    "\n",
    "The final set of calibration tables represents the cumulative calibration and is what is applied to correct the data using **applycal**. It is important to keep track of each calibration table and its role relative to others.  E.g., a provisional gain calibration solution will usually be obtained to optimize a bandpass calibration solve, but then be discarded in favor of a new gain calibration solution that will itself be optimized by use of the bandpass solution as a prior; the original gain calibration table should be discarded in this case.   On the other hand, it is also permitted to generate a sequence of gain calibration tables, each *relative* to the last (and any other prior calibration used); in this case all relative tables should be carried forward through the process and included in the final **applycal**.  It is the user\\'s responsibility to keep track of the role of and relationships between all calibration tables.  Depending on the complexity of the observation, this can be a confusing business, and it will help if you adopt a consistent table naming scheme.  In general, it is desirable to minimize the number of different calibration tables of a specific type, to keep the overall process as simple as possible and minimize the computational cost of applying them, but relative calibraition tables may sometimes be useful as an aid to understanding the origin and properties of the calibration effects.  For example, it may be instructive to obtain a short time-scale gain calibraiton relative to a long time-scale one (e.g., obtained from a single scan) to approximatly separate electronic and atmospheric effects.  Of course, calibration tables of different types are necessarily relative to each other (in the order in which they are solved).\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing for Calibration \n",
    "\n",
    "A description of the range of prior information necessary to solve for calibration\n",
    "\n",
    "There is a range of *a priori* information that may need to be initialized or estimated before calibration solving is carried out.  This includes establishing prior information about the data within the MS:\n",
    "\n",
    "-   **weight initialization** \\-\\-- if desired, initialization of spectral weights, using **initweight** (by default, unchannelized weight accounting is used, and no special action is required)\n",
    "-   **flux density models** \\-\\-- establish the flux density scale using \\\"standard\\\" calibrator sources, with models for resolved calibrators, using **setjy** as well as deriving various prior calibration quanitities using various modes of **gencal**\n",
    "-   **gain curves** \\-\\-- the antenna gain-elevation dependence\n",
    "-   **atmospheric optical depth** \\-\\-- attenuation of the signal by the atmosphere, including correcting for its elevation dependence\n",
    "-   **antenna position errors** \\-\\-- offsets in the positions of antennas assumed during correlation\n",
    "-   **ionosphere** \\-\\-- dispersive delay and Faraday effects arising from signal transmission through the magnetized plasma of the ionosphere\n",
    "-   **switched power** (EVLA) \\-\\-- electronic gains monitored by the EVLA online system\n",
    "-   **system temperature** (ALMA) \\-\\-- turn correlation coefficient into correlated flux density (necessary for some telescopes)\n",
    "-   **generic cal factors** \\-\\-- antenna-based amp, phase, delay\n",
    "\n",
    "These are all pre-determined effects and should be applied (if known) as priors when solving for other calibration terms, and included in the final application of all calibration.  If unknown, then they will be solved for or subsumed in other calibration such as bandpass or gains.\n",
    "\n",
    "Each of these will now be described in turn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Initialization\n",
    "\n",
    "See the section on [data](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-weights) weights[ ](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-weights \"weights\")for a more complete description of weight accounting in CASA.\n",
    "\n",
    "CASA 4.3 introduced initial experimental support for spectral weights.  At this time, this is mainly relevant to ALMA processing for which *spectral* $T_{sys}$ corrections, which faithfully reflect spectral sensitivity, are available.  In most other cases, sensitivity is, to a very good approximation, channel-independent after bandpass calibration (and often also before), except perhaps at the very edges of spectral windows (and for which analytic expressions of the sensitivity loss are generally unavailable).  Averaging of data with channel-dependent flagging which varies on sufficiently short timescales will also generate channel-dependent net weights (see **split** or **mstransform** for more details).\n",
    "\n",
    "By default, CASA\\'s weight accounting scheme maintains unchannelized weight information that is appropriately updated when calibration is applied.  In the case of spectral calibrations ($T_{sys}$ and bandpass), an appropriate spectral average is used for the weight update.  This spectral average is formally correct for weight update by bandpass.  For $T_{sys}$, traditional treatments used a single measurement per spectral window; ALMA has implemented spectral $T_{sys}$ to better track sensitivity as a function of channel, and so should benefit from *spectral* weight accounting as described here, especially where atmospheric emmission lines occur.  If spectral weight accounting is desired, users must re-initialize the spectral weights using the **initweights** task:\n",
    "\n",
    " \n",
    "\n",
    "```\n",
    "initweights(vis='mydata.ms', wtmode='nyq', dowtsp=True)\n",
    "```\n",
    "\n",
    "In this task, the *wtmode* parameter controls the weight initialization convention.  Usually, when initializing the weight information for a raw dataset, one should choose *wtmode=\\'nyq\\'* so that the channel bandwidth and integration time information are used to initialize the weight information (as described [here](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-weights)).  The *dowtsp* parameter controls whether or not (*True* or *False*) the spectral weights (the *WEIGHT_SPECTRUM* column) are initialized.  The default is *dowtsp=False*, wherein only the non-spectral weights (the *WEIGHT* column) will be initialized.  If the spectral weights have been initialized, then downstream processing that supports spectral weights will use and update them.  In CASA 4.3 and later, this includes **applycal**, **clean**, and **split**/**mstransform**; use of spectral weights in calibration solving (e.g., **gaincal** and other solve tasks) is scheduled for the CASA 5.0 release.\n",
    "\n",
    "Note that **importasdm** currently initializes the *non-spectral* weights using channel bandwidth and integration time information (equivalent to using *dospwt=False* in the above example.  In general, it only makes sense to run **initweights** on a raw dataset which has not yet been calibrated, and it should only be necessary if the filled weights are inappropriate, or if spectral weight accounting is desired in subsequent processing. It is usually *not* necessary to re-initialize the weight information when redoing calibration from scratch (the raw weight information is preserved in the *SIGMA*/*SIGMA_SPECTRUM* columns).  (Re-)initializing the weight information for data that has already been calibrated (with *calwt=True*, presumably) is formally incorrect and is not recommended.\n",
    "\n",
    "When combining datasets from different epochs, it is generally preferable to have used the same version of CASA (most recent is best), and with the same weight information conventions and *calwt* settings in calibration tasks.  Doing so will minimize the likelihood of arbitrary weight imbalances that might lead to net loss of sensitivity, and maximize the likelihood that *real* differences in per-epoch sensitivity (e.g., due to different weather conditions and instrumental setups) will be properly accounted for.  Modern instruments support more variety in bandwidth and integration time settings, and so use of these parameters in weight initialization is preferred (c.f. use of simple unit weight initialization, which has often been the traditional practice).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** Full and proper weight accounting for the EVLA formally depends on the veracity of the switched power calibration scheme.  As of mid-2015, use of the EVLA switched power is not yet recommended for general use, and otherwise uniform weights are carried through the calibration process.  As such, spectral weight accounting is not yet meaningful.  Facilities for post-calibration estimation of spectral weights are rudimentarily supported in **statwt**.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flux Density Models\n",
    "\n",
    "It is necessary to be sure calibrators have appropriate models set for them before solving for calibration.  Please see the task documentation for **setjy** and **ft** for more information on setting non-trivial model information in the MS.   Also, information about setting models for flux density calibrators can be found [here](https://casa.nrao.edu/casadocs-devel/stable/memo-series/reference-material/flux-density-calibrator-models-conventions-data-formats).   Fields in the MS for which no model has been explicitly set will be rendered as unpolarized unit flux density (1 Jy) point sources in calibration solving.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Antenna Gain-Elevation Curve Calibration\n",
    "\n",
    "Large antennas (such as the 25-meter antennas used in the VLA and VLBA) have a forward gain and efficiency that changes with elevation. Gain curve calibration involves compensating for the effects of elevation on the amplitude of the received signals at each antenna.  Antennas are not absolutely rigid, and so their effective collecting area and net surface accuracy vary with elevation as gravity deforms the surface.  This calibration is especially important at higher frequencies where the deformations represent a greater fraction of the observing wavelength.  By design, this effect is usually minimized (i.e., gain maximized) for elevations between 45 and 60 degrees, with the gain decreasing at higher and lower elevations.  Gain curves are most often described as 2nd- or 3rd-order polynomials in zenith angle.\n",
    "\n",
    "Gain curve calibration has been implemented in CASA for the modern VLA and old VLA (only), with gain curve polynomial coefficients available directly from the CASA data repository.  To make gain curve and antenna efficiency corrections for VLA data, use **gencal**:\n",
    "\n",
    "```\n",
    "gencal(vis='mydata.ms', caltable='gaincurve.cal', caltype='gceff')\n",
    "```\n",
    "\n",
    "Use of *caltype=\\'gceff\\'* generates a caltable that corrects for both the elevation dependence and an antenna-based efficiency unit conversion that will render the data in units of *approximate* Jy (NB: this is generally not a good substitute for proper flux density calibration, using **fluxscale**!).  Use of *caltype=\\'gc\\'* or *caltype=\\'eff\\'* can be used to introduce these corrections separately.\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Alert:** If you are not using VLA data, do not use gaincurve corrections.  A general mechanism for incorporating gaincurve information for other arrays will be made available in future releases.  The gain-curve information available for the VLA is time-dependent (on timescales of months to years, at least for the higher frequencies), and CASA will automatically select the date-appropriate gain curve information.  Note, however, that the time-dependence was poorly sampled prior to 2001, and so gain curve corrections prior to this time should be considered with caution.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Atmospheric Optical Depth Correction\n",
    "\n",
    "The troposphere is not completely transparent.  At high radio frequencies ($>$15 GHz), water vapor and molecular oxygen begin to have a substantial effect on radio observations. According to the physics of radiative transmission, the effect is threefold.  First, radio waves from astronomical sources are absorbed (and therefore attenuated) before reaching the antenna.  Second, since a good absorber is also a good emitter, significant noise-like power will be added to the overall system noise, and thus further decreasing the *fraction* of correlated signal from astrophysical sources.  Finally, the optical path length through the troposphere introduces a time-dependent phase error.  In all cases, the effects become worse at lower elevations due to the increased air mass through which the antenna is looking.  In CASA, the opacity correction described here compensates only for the first of these effects, tropospheric attenuation, using a plane-parallel approximation for the troposphere to estimate the elevation dependence.  (Gain solutions solved for later will account for the other two effects.)\n",
    "\n",
    "To make opacity corrections in CASA, an estimate of the zenith opacity is required (see observatory-specific chapters for how to measure zenith opacity).  This is then supplied to the *caltype=\\'opac\\'* parameter in **gencal** which creates a calibration table that will introduce the elevation-dependent correction when applied in later operaions. E.g. for data with two spectral windows:\n",
    "\n",
    "```\n",
    "gencal(vis='mydatas.ms',\n",
    "       caltable='opacity.cal',\n",
    "       caltype='opac',\n",
    "       spw='0,1',\n",
    "       parameter=[0.0399,0.037])\n",
    "```\n",
    "\n",
    "If you do not have an externally supplied value for *opacity*, for example from a VLA tip procedure, then you should either use an average value for the telescope, or omit this cal table and let your gain calibration compensate as best it can (e.g. that your calibrator is at the same elevation as your target at approximately the same time). As noted above, there are no facilities yet to estimate this from the data (e.g. by plotting $T_{sys}$ vs. elevation).\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    "Below, we give instructions for determining opacity values for Jansky VLA data from weather statistics and VLA observations where tip-curve data is available.  It is beyond the scope of this description to provide information for other telescopes.\n",
    "\n",
    "###### Determining opacity corrections for *modern* VLA data\n",
    "\n",
    "For the VLA site, weather statistics and/or seasonal models that average over many years of weather statistics prove to be reasonable good ways to estimate the opacity at the time of the observations. The task **plotweather** calculates the opacity as a mix of both actual weather data and seasonal model. It can be run as follows:\n",
    "\n",
    "```\n",
    "myTau=plotweather(vis='mydata.ms',doPlot=True)\n",
    "```\n",
    "\n",
    "The task plots the weather statistics if *doPlot=T*, generating a plot shown in the figure below. The bottom panel displays the calculated opacities for the run as well as a seasonal model. An additional parameter, *seasonal_weight* can be adjusted to calculate the opacities as a function of the weather data alone (*seasonal_weight=0*), only the seasonal model (*seasonal_weight=1*), or a mix of the two (values between 0 and 1). Calculated opacities are shown in the logger output, one for each spectral window.  Note that **plotweather** returns a python list of opacity values with length equal to the number of spectral windows in the MS, appropriate for use in **gencal**:\n",
    "\n",
    "```\n",
    "gencal(vis='mydata.ms', caltype='opac', spw='0,1', parameter=myTau)  \n",
    "```\n",
    "\n",
    "Note that the *spw* parameter is used non-trivially and explicitly here to indicate that the list of opacity values corresponds to the specified spectral windows.\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    "![20628a3e93b5783c9da5f4fab6cd2cf85e4eb0dd](media/20628a3e93b5783c9da5f4fab6cd2cf85e4eb0dd.png){.image-inline}\n",
    "\n",
    ">The weather information for a MS as plotted by the task {\\\\tt plotweather}.}\n",
    "  \n",
    "\n",
    " \n",
    "\n",
    "###### Determining opacity corrections for historical VLA data\n",
    "\n",
    "For VLA data, zenith opacity can be measured at the frequency and during the time observations are made using a VLA tipping scan in the observe file.  Historical tipping data are available [here.](http://www.vla.nrao.edu/astro/calib/tipper \"vla tips\")  Choose a year, and click *Go* to get a list of all tipping scans that have been made for that year.\n",
    "\n",
    "If a tipping scan was made for your observation, then select the appropriate file.  Go to the bottom of the page and click on the button that says *Press here to continue*.  The results of the tipping scan will be displayed.  Go to the section called \\'Overall Fit Summary\\' to find the fit quality and the fitted zenith opacity in percent.  If the zenith opacity is reported as 6%, then the actual zenith optical depth value is 0.060.  Use this value in **gencal** as described above.\n",
    "\n",
    "If there were no tipping scans made for your observation, then look for others made in the same band around the same time and weather conditions.  If nothing is available here, then at K and Q bands you might consider using an average value (e.g. 6% in reasonable weather).  See the VLA memo [here](http://www.vla.nrao.edu/memos/test/232/232.pdf \"ad hoc opacity\") for more on the atmospheric optical depth correction at the VLA, including plots of the seasonal variations.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Antenna-position corrections\n",
    "\n",
    "When antennas are moved, residual errors in the geographical coordinates of the antenna will cause time-dependent delay errors in the correlated data.  Normally, the observatory will solve for these offsets soon after the move and correct the correlator model, but sometimes science data is taken before the offsets are available, and thus the correction must be handled in post-processing. If the 3D position offsets for affected antennas are known, use **gencal** as follows:\n",
    "\n",
    "```\n",
    "gencal(vis='mydata.ms', caltable='antpos.cal', caltype='antpos', antenna='ea01',parameter=[0.01,0.02,0.005])\n",
    "```\n",
    "\n",
    "In this execution, the position offset for antenna ea01 is \\[1cm,2cm,0.5cm\\] in an Earth-centered right-handed coordinate system with the first axis on the prime meridian and third axis coincident with the Earth\\'s axis.  Corrections for multiple antennas can be specified by listing all affected antennas and extending the *parameter* list with as many offset triples as needed. \n",
    "\n",
    "In general, it is difficut to know what position offsets to use, of course.  For the VLA, **gencal** will look up the required offests automatically, simply by omitting the *antenna *and *parameter* arguments:\n",
    "\n",
    "```\n",
    "gencal(vis='mydata.ms', caltable='antpos.cal', caltype='antpos')\n",
    "```\n",
    "\n",
    "For the historical VLA, the antenna position coordinate system was a local one translated from the Earth\\'s center and rotated to the VLA\\'s longitude.  Use *caltype=\\'antposvla\\'* to force this coordiate system when processing old VLA data.\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ionospheric corrections\n",
    "\n",
    "CASA 4.3 introduced initial support for on-axis ionospheric corrections, using time- and direction-dependent total electron content (TEC) information obtained from the internet.  The correction includes the dispersive delay ($\\propto \\nu^{-1}$) delay and Faraday rotation ($\\propto \\nu^{-2}$) terms.  These corrections are most relevant at observing frequencies less than $\\sim$5 GHz.  When relevant, the ionosphere correction table should be generated at the beginning of a reduction along with other calibration priors (antenna position errors, gain curve, opacity, etc.), and carried through all subsequent calibration steps.  Formally, the idea is that the ionospheric effects (as a function of time and on-axis direction) will be nominally accounted for by this calibration table, and thus not spuriously leak into gain and bandpass solves, etc.  In practice, the quality of the ionospheric correction is limited by the relatively sparse sampling (in time and direction) of the available TEC information.  Especially active ionospheric conditions may not be corrected very well.  Also, direction-dependent (*within the instantaneous field-of-view*) ionosphere corrections are not yet supported.  Various improvements are under study for future releases.\n",
    "\n",
    "To generate the ionosphere correction table, first import a helper function from the casapy recipes repository:\n",
    "\n",
    "```\n",
    "from recipes import tec_maps\n",
    "```\n",
    "\n",
    "Then, generate a TEC surface image:\n",
    "\n",
    "```\n",
    "tec_maps.create(vis='mydata.ms',doplot=T,imname='iono')\n",
    "```\n",
    "\n",
    "This function obtains TEC information for the observing date and location from [NASA\\'s CDDIS Archive of Space Geodesy Data](https://cddis.nasa.gov/Data_and_Derived_Products/GNSS/atmospheric_products.html), and generates a time-dependent CASA image containing this information.  The string specified for *imname* is used as a prefix for two output images, with suffixes *.IGS_TEC.im* (the actual TEC image) and *.IGS_RMS_TEC.im* (a TEC error image).  If *imname* is unspecified, the MS name (from *vis*) will be used as the prefix.\n",
    "\n",
    "The quality of the retrieved TEC information for a specific date improves with time after the observing date as CDDIS\\'s ionospheric modelling improves, becoming optimal 1-2 weeks later.  Both images can be viewed as a movie in the CASA image **viewer**.  If *doplot=T*, the above function will also produce a plot of the TEC as a function of time in a vertical direction over the observatory.\n",
    "\n",
    "Finally, to generate the ionosphere correction caltable, pass the *.IGS\\\\\\_TEC.im* image into **gencal**, using *caltype=\\'tecim\\'*:\n",
    "\n",
    "```\n",
    "gencal(vis='mydata.ms',caltable='tec.cal',caltype='tecim',infile='iono.IGS_TEC.im')\n",
    "```\n",
    "\n",
    "This iterates through the dataset and samples the zenith angle-dependent projected line-of-sight TEC for all times in the observation, storing the result in a standard CASA caltable.  Plotting this caltable will show how the TEC varies between observing directions for different fields and times, in particular how it changes as zenith angle changes, and including the nominal difference between science targets and calibrators.\n",
    "\n",
    "This caltable should then be used as a prior in all subsequent calibration solves, and included in the final **applycal**.\n",
    "\n",
    "A few warnings:\n",
    "\n",
    "-   The TEC information obtained from the web is relatively poorly sampled in time and direction, and so will not always describe the details of the ionospheric corruption, especially during active periods.\n",
    "-   For instrumental polarization calibration, it is recommended that an *unpolarized* calibrator be used; polarized calibrators may not yield as accurate a solution since the ionospheric corrections are not yet used properly in the source polarization portion of the **polcal** solve.\n",
    "\n",
    "Special thanks are due to Jason Kooi (UIowa) for his contributions to ionospheric corrections in CASA.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Switched-power (EVLA)\n",
    "\n",
    "The EVLA is equipped with noise diodes that synchronously inject a nominally constant and known power contribution appropriate for tracking electronic gain changes with time resolution as short as 1 second.  The total power in both the ON and OFF states of the noise diodes is continuously recorded, enabling a gain calibration derived from their difference (as a fraction of the mean total power), and scaled by a the approximately known contributed power (nominally in K).  Including this calibration will render the data in units of (nominal) K, and also calibrate the data weights to units of inverse K^2^.  To generate a switched-power calibration table for use in subsequent processing, run **gencal** as follows:\n",
    "\n",
    "```\n",
    "gencal(vis='myVLAdata.ms',caltable='VLAswitchedpower.cal',caltype='evlagain')                        \n",
    "```\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    "To ensure that the weight calibration by this table works correctly, it is important that the raw data weights are proprotional to integration time and channel bandwidth.  This can be guaranteed by use of **initweights** as described above.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### System Temperature (ALMA)\n",
    "\n",
    "ALMA routinely measures $T_{sys}$ while observing, and these measurements are used to reverse the online normalization of the correlation coefficients and render the data in units of nominal K.  To generate a $T_{sys}$ calibration table, run **gencal** as follows:\n",
    "\n",
    "```\n",
    "gencal(vis='myALMAdata.ms',caltable='ALMAtsys.cal',caltype='tsys')                                    \n",
    "```\n",
    "\n",
    "The resulting calibration table should then be used in all subsequent processing the requires the specification of prior calibration.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Miscellaneous ad hoc corrections\n",
    "\n",
    "The **gencal** task supports generating ad hoc amp, phase, and delay corrections via appropriate settings of the *caltype* parameter.  Currently, such factors must be constant in time (**gencal** has no mechanism for specifying multiple timestamps for parameters), but sometimes such corrections can be useful.  See the general **gencal** task documenation for more information on this type of correction.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Virtual Model Visibilities \n",
    "\n",
    "Generating and using virtual MODEL_DATA columns in ms.\n",
    "\n",
    "The tasks that generate model visibilities (**clean**, **tclean**, **ft**, and **setjy**) can either (in most cases) save the data in a MODEL_DATA column inside of the MeasurementSet (MS) or it can save it in a virtual one. In the latter case the model visibilities are generated on demand when it is requested and the data necessary to generate that is stored (usually the Fourier transform of the model images or a component list). More detailed descriptions of the structure of an MS can be found on the [CASA Fundamentals](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals) pages. \n",
    "\n",
    "The tasks that can read and make use of the virtual model columns include calibration tasks, mstransform tasks (including **uvsubtraction**), **plotms**.\n",
    "\n",
    "Advantages of virtual model column over the real one:\n",
    "\n",
    "-   Speed of serving visibilities (in most cases because calculating models visibilities is faster than disk IO)\n",
    "-   Disk space saving (a full size of the original data size is saved)\n",
    "\n",
    "When not to use virtual model\n",
    "\n",
    "-   model image size is a significant fraction of the visibility data size (e.g large cube from a small data set). Virtual model column serving might be slower than real one\n",
    "-   when the user wants to edit the model physically via the table tool for e.g\n",
    "-   when using an FTMachine that does not support virtual model saving when imaging (AWProjectFT for e.g)\n",
    "\n",
    "Additional Information\n",
    "\n",
    "-   When both a physical model column exists along with a virtual model, then the virtual model is the one that gets served by tasks that uses the visbuffer (e.g calibration tasks)\n",
    "-   Use **delmod*** *task to manage your MODEL_DATA column and virtual model\n",
    "-   If  model data is written for a subset of the MS (say the user used *field* , *spw* and/or *intent* selection in **tclean**) then the model visibilities will be served properly for the subset in question the other part of the MS will have 1 served for parallel hand visibilities and 0 for crosshand visibilities. So be careful when doing calibration or uvsub after writing model visibilities only for a subset of the MS (this applies to using the physical scratch column MODEL_DATA too)\n",
    "-   The virtual model info is written in the SOURCE table of the MS usually (and in the main table if the SOURCE table does not exist)\n",
    "-   FTMachines (or imaging gridding mode) supporting virtual model data are:\n",
    "    -   GridFT: Standard gridder (including mutiterm and multi fields or cube),\n",
    "    -   WProjectFT: widefield wterm  (including mutiterm and multi fields or cube),\n",
    "    -   MosaicFT: mosaic imaging (including mutiterm or cube),\n",
    "    -   ComponentLists\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solve for Calibration \n",
    "\n",
    "How to solve for various calibration terms from the data itself\n",
    "\n",
    "The **gaincal**, **bandpass**, **polcal**, and **blcal** tasks actually solve for the unknown calibration parameters from the visibility data obtained on calibrator sources, placing the results in a calibration table. They take as input an MS, and a number of parameters that specify any prior calibration tables to pre-apply before computing the solution, as well as parameters controlling the exact properties of the solving process.\n",
    "\n",
    "We first discuss the parameters that are in common between many of the calibration tasks.  Subsequent sub-sections will discuss the use of each of these solving task in more detail.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common Calibration Solver Parameters\n",
    "\n",
    "There are a number of parameters that are in common between the calibration solver tasks.\n",
    "\n",
    "###### Input/output\n",
    "\n",
    "The input MeasurementSet and output calibration table are controlled by the following parameters:\n",
    "\n",
    "```\n",
    "vis          =         ''   #Name of input visibility file\n",
    "caltable     =         ''   #Name of output calibration table\n",
    "```\n",
    "\n",
    "The MS name is specified in *vis*. If it is highlighted red in the inputs then it does not exist, and the task will not execute. Check the name and path in this case.\n",
    "\n",
    "The output table name is specified in *caltable*. Be sure to give a unique name to the output table, or be careful. If the table exists, then what happens next will depend on the task and the values of other parameters. The task may not execute giving a warning that the table already exists, or will go ahead and overwrite the solutions in that table, or append them. Be careful.\n",
    "\n",
    "###### Data selection\n",
    "\n",
    "Data selection is controlled by the following parameters:\n",
    "\n",
    "```\n",
    "field        =         ''   #field names or index of calibrators: ''==>all\n",
    "spw          =         ''   #spectral window:channels: ''==>all\n",
    "intent       =         ''   #Select observing intent\n",
    "selectdata   =      False   #Other data selection parameters\n",
    "```\n",
    "\n",
    "Field and spectral window selection are so often used, that we have made these standard parameters, *field* and *spw* respectively.  Additionally, *intent* is also included as a standard parameter to enable selection by the scan intents that were specified when the observations were set up and executed. They typically describe what was intended with a specific scan, i.e. a flux or phase calibration, a bandpass, a pointing, an observation of your target, or something else or a combination. The format for the scan intents of your observations are listed in the logger when you run listobs. Minimum matching with wildcards will work, like \\*BANDPASS\\*.  This is especially useful when multiple intents are attached to scans.  Finally, observation is an identifier to distinguish between different observing runs, mainly used for ALMA.\n",
    "\n",
    "The selectdata parameter expands, revealing a range of other selection sub-parameters:\n",
    "\n",
    "```\n",
    "selectdata          =       True        #data selection parameters\n",
    "     timerange      =         ''        #time range (blank for all)\n",
    "     uvrange        =         ''        #uv range (blank for all)\n",
    "     antenna        =         ''        #antenna/baselines (blank for all)\n",
    "     scan           =         ''        #scan numbers (blank for all)\n",
    "     correlation    =         ''        #correlations (blank for all)\n",
    "     array          =         ''        #(sub)array numbers (blank for all)\n",
    "     observation    =         ''        #Select by observation ID(s)\n",
    "     msselect       =         ''        #MS selection (blank for all)\n",
    "```\n",
    "\n",
    "Note that if *selectdata=False* these parameters are not used when the task is executed, even if set non-trivially.\n",
    "\n",
    "Among the most common *selectdata=True* parameters to use is uvrange, which can be used to exclude longer baselines if the calibrator is resolved, or short baselines if the calibrator contains extended flux not accounted for in the model.  The rest of these parameters may be set according to information and values available in the listobs output.  Note that all parameters are specified as strings, even if the values to be specified are numbers.  See the section on [MS Selection](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/data-selection-in-a-measurementset) for more details on the powerful syntax available for selecting data.\n",
    "\n",
    "###### Prior calibration\n",
    "\n",
    "Calibration tables that have already been determined can be arranged for apply before solving for the new table using the following parameters:\n",
    "\n",
    "```\n",
    "docallib        =  False        #Use traditional cal apply parameters\n",
    "     gaintable  =     []        #Gain calibration table(s) to apply on the fly\n",
    "     gainfield  =     []        #Select a subset of calibrators from gaintable(s)\n",
    "     interp     =     []        #Interpolation mode (in time) to use for each gaintable\n",
    "     spwmap     =     []        #Spectral windows combinations to form for gaintable(s)\n",
    "```\n",
    "\n",
    "The *docallib* parameter is a toggle that can be used to select specification of prior calibration using the new \\\"cal library\\\" mechanism (*docallib=True*) which is described in greater detail [here.](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax)\n",
    "\n",
    "When *docalib=False*, the traditional CASA calibration apply sub-parameters will be used, as listed above.\n",
    "\n",
    "###### ***gaintable***\n",
    "\n",
    "The *gaintable* parameter takes a string or list of strings giving the names of one or more calibration tables to arrange for application. For example:\n",
    "\n",
    "```\n",
    "   gaintable = ['ngc5921.bcal','ngc5921.gcal']\n",
    "```\n",
    "\n",
    "specifies two tables, in this case bandpass and gain calibration tables respectively.\n",
    "\n",
    "The *gainfield*, *interp*, and *spwmap* parameters key off *gaintable*, taking single values or lists, with an entries for each corresponding table in specified in *gaintable*.  The caltables can be listed in *gaintable* in any order, without affecting the order in which they are applied to the data (for consistency, this is controlled internally according to the [Measurement Equation](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/the-measurement-equation-calibration) framework).  If non-trivial settings are required for only a subset of the tables listed in *gaintable*, it can be convenient to specify these tables first in *gaintable*, include their qualifying settings first in the other paramters, and omit specifications for those tables not needing qualification (sensible defaults will be used for these).\n",
    "\n",
    "###### ***gainfield***\n",
    "\n",
    "The *gainfield* parameter specifies which field(s) from each respective *gaintable* to select for apply. This is a list, with each entry a string. The default for an entry means to use all in that table. For example, use\n",
    "\n",
    "```\n",
    "   gaintable = ['ngc5921.bcal', 'ngc5921.gcal']\n",
    "   gainfield = [ '1331+305',    '1331+305,1445+099']\n",
    "```\n",
    "\n",
    "to specify selection of *1331+305* from *ngc5921.bcal* and fields *1331+305* and *1445+099* from *ngc5921.gcal*.  Selection of this sort is only needed if avoiding other fields in these caltables is necessary.  The field selection used here is the general MS Selection syntax.\n",
    "\n",
    "In addition, *gainfield* supports a special value:\n",
    "\n",
    "```\n",
    "   gainfield = [ 'nearest' ]\n",
    "```\n",
    "\n",
    "which selects the calibrator that is the spatially closest (in sky coordinates) to each of the selected MS fields specified in the *field* data selection parameter.  Note that the nearest calibrator field is evaluated once per execution and is never dependent on time, spw or any other data meta-axis.  This can be useful for running tasks with a number of different sources to be calibrated in a single run, and when this simple proximity notion is applicable.   Note that the [cal library](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/cal-library-syntax) mechanism provides increased flexibility in this area.\n",
    "\n",
    "###### ***interp***\n",
    "\n",
    "The *interp* parameter chooses the interpolation scheme to be used when pre-applying the solution in the tables. Interpolation in both time and frequency (for channel-dependent calibrations) are supported. The choices are currently \\'*nearest\\'* and \\'*linear\\'* for time-dependent interpolation, and \\'*nearest\\'*, \\'*linear\\'*, \\'*cubic\\'*, and \\'*spline\\'* for frequency-dependent interpolation.  Frequency-dependent interpolation is only relevant for channel-dependent calibration tables (like bandpass) that are undersampled in frequency relative to the data.\n",
    "\n",
    "-   *\\'nearest\\'  * just picks the entry nearest in time or freq to the visibility in question\n",
    "-   \\'*linear*\\'     calibrates each datum with calibration phases and amplitudes linearly interpolated from neighboring values in time or frequency. In the case of phase, this mode will assume that phase never jumps more than 180 degrees between neighboring points, and so phase changes exceeding this between calibration solutions cannot be corrected for.  Also, solutions will not be extrapolated arbitrarily in time or frequency for data before the first solution or after the last solution; such data will be calibrated using nearest to avoid unreasonable extrapolations.\n",
    "-   \\'*cubic*\\'   (frequency axis only) forms a 3rd-order polynomial that passes through the nearest 4 calibration samples (separately in phase and amplitude)\n",
    "-   \\'*spline*\\'   (frequency axis only) forms a cubic spline that passes through the nearest 4 calibration samples (separately in phase and amplitude)\n",
    "\n",
    "The time-dependent interp options can be appended with *\\'PD\\'* to enable a \\\"phase delay\\\" correction per spw for non-channel-dependent calibration type.  For example: \\'*linearPD*\\'.  This will adjust the time-dependent phase by the ratio of the data frequency and solution frequency and effect a time-dependent delay-like calibration over spws, and is most useful when distributing a single-spw\\'s solution (e.g.., as might be generated by *combine=\\'spw\\'* in **gaincal**) over many data spws, and when the the residual being calibrated is non-dispersively delay-like.\n",
    "\n",
    "The time-dependent interp options can also be appended with *\\'perobs\\'* to enforce observation Id boundaries in the interpolation.\n",
    "\n",
    "The frequency-dependent interp options can be appended with \\'flag\\' to enforce channel-dependent flagging by flagged bandpass channels (i.e., \\'*nearestflag*\\', \\'*linearflag*\\', \\'*cubicflag*\\', and \\'*splineflag*\\', rather than to automatically fill such channels in with interpolation (which is the default).\n",
    "\n",
    "For each *gaintable*, specify the interpolation style in quotes, with the frequency-dependent interpolation style specified after a comma, if relevant.  For example:\n",
    "\n",
    "```\n",
    "   gaintable = ['ngc5921.bcal',  'ngc5921.gcal']\n",
    "   gainfield = ['1331+305',      ['1331+305','1445+099'] ]\n",
    "   interp =    ['linear,spline', 'linear']\n",
    "```\n",
    "\n",
    "uses linear interpolation on the time axis for both cal tables, and a cubic spline for interpolation of the frequency axis in the bandpass table.\n",
    "\n",
    "###### ***spwmap***\n",
    "\n",
    "The *spwmap* parameter is used to redistribute the calibration available in a caltable flexibly among spectral windows, thereby permitting correction of some spectral windows using calibration derived from others.   The *spwmap* parameter takes a list or a list of lists of integers, with one list of integers for every caltable specified in *gaintable*.  Each list is indexed by the MS spectral window ids, and the values indicate the calibration spectral windows to use for each MS spectral window.  I.e., for each MS spw, *i*, the calibration spw *j* will be *j=spwmap\\[i\\]*. \n",
    "\n",
    "The default for *spwmap* (an empty list per *gaintable*) means that MS spectral windows will be calibrated by solutions identified with the same index in the calibration table (i.e., by themselves, typically).  Explicit specification of the default would be *spwmap=\\[0,1,2,3\\]*, for an MS with four spectral windows.   Less trivially, for a caltable containing solutions derived from and labelled as spectral windows 0 and 1, these two cal spectral windows can be mapped to any of the MS spectral windows.  E.g., (for a single *gaintable*):\n",
    "\n",
    "```\n",
    "   spwmap=[0,1,1,0]                #apply from cal spw=0 to MS spws 0,3 and from cal spw 1 to MS spws 1,2\n",
    "```\n",
    "\n",
    "For multiple gaintables, use a lists of lists (one spwmap list per gaintable), e.g.,\n",
    "\n",
    "```\n",
    "   gaintable = ['ngc5921.bcal',  'ngc5921.gcal']\n",
    "   gainfield = ['1331+305',      ['1331+305','1445+099'] ]\n",
    "   interp =    ['linear,spline', 'linear']\n",
    "   spwmap =    [ [0,1,1,0],      [2,3,2,3] ]\n",
    "```\n",
    "\n",
    "which will use bandpass spws 0 and 1 for MS spws (0,3), and (1,2), respectively, and gain spws 2 and 3 for MS spws (0,2) and (1,3), respectively.\n",
    "\n",
    "Any spectral window mapping is mechanically valid, including using specific calibration spectral windows for more than one different MS spectral window (as above) and using alternate calibration even for spectral windows for which calibration is nominally available, as long as the mapped calibration spectral windows have calibration solutions available in the caltable.  If a mapped calibration spectral window is absent from the caltable (and not merely flagged), an exception will occur.\n",
    "\n",
    "The scientific meaningfulness of a non-trivial spwmap specification is the responsibility of the user; no internal checks are performed to attempt the scientific validity of the mapping.  Usually, *spwmap* is used to distribute calibration such as Tsys, which may be measured in a wide low-resolution spectral window, to narrow high-resolution spectral windows that fall within the wide one.  It is also used to distribute calibration derived from a **gaincal** solve which was performed using *combine=\\'spw\\'* (e.g., for increased SNR) to each of the spectral windows (and perhaps others) aggregated in the solve; in this case, it may be useful to consider using the *\\'PD\\'* (\\\"phase delay\\\") interpolation option described above, to account for the frequency ratios between each of the individual MS spectral windows and the aggregated calibration spectral window. \n",
    "\n",
    "###### Absolute vs. Relative frequency in frequency-dependent interpolation\n",
    "\n",
    "<div>\n",
    "\n",
    "By default, frequency-dependent solutions are interpolated for application in absolute sky frequency units.  Thus, it is usually necessary to obtain **bandpass** solutions that cover the frequencies of all spectral windows that must be corrected.   In this context, it is mechanically valid to use *spwmap* to transfer a **bandpass** solution from a wide, low-resolution spectral window to a narrow, higher-resolution spectral window that falls within the wide one in sky frequency space.   On the other hand, if adequate data for a **bandpass** solution is unavailable for a specific spectral window, e.g., due to contamination by line emission or absorption (such as HI), or because of flagging, **bandpass** solutions from other spectral windows (i.e., at different sky frequencies) can be applied using *spwmap*.   In this case, it is also necessary to add *\\'rel*\\' to the frequency interpolation string in the *interp* parameter, as this will force the interpolation to be calculated in relative frequency units.  Specifically, the center frequency of the **bandpass** solution will be registered with the absolute center frequency of each of the MS spectral windows to which it is applied, thereby enabling relative frequency registration.  The quality of such calibration transfer will depend, of course, on the uniformity of the hardware parameters and properties determining the bandpass shapes in the observing system\\--this is often appropriate over relatively narrow bandwidths in digital observing systems, as long as the setups are sufficiently similar (same sideband, same total spectral window bandwidth, etc., though note that the channelization need not be the same).  Traditionally (e.g., at the VLA, for HI observations), **bandpass** solutions for this kind of calibration transfer have be solved by combining spectral windows on either side of the target spectral window (see the task documentation for [**bandpass**](https://casa.nrao.edu/casadocs-devel/stable/global-task-list/task_bandpass) for more information on solving with *combine=\\'spw\\'*).\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    " \n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "For example, to apply a bandpass solution from spectral window 0 (in a **bandpass** table called ngc5921.bcal) to MS spectral windows 0,1,2,3 with linear interpolation calculated in relative frequency units (and with frequency-dependent flagging respected):\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "```\n",
    "   gaintable = ['ngc5921.bcal']\n",
    "   interp =    ['nearest,linearflagrel']\n",
    "   spwmap =    [ [0,0,0,0] ]\n",
    "```\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    " \n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "When selecting channels for a **bandpass** solution that will be applied using *\\'rel\\'*, it is important to recognize that the selected channels will be centered on each of the \\_absolute\\_ centers of the MS spectral windows to which it will be applied.   An asymmetric channel selection for the **bandpass** solve will cause an undesirable shift in the relative registration on apply.   Avoid this by using symmetrical channel selection (or none) for the **bandpass** solve.\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "Also note that if relative frequency interpolation is required but *\\'rel\\'* is not used in *interp*, the interpolation mechanism currently assumes you want absolute frequency interpolation.  If there is no overlap in absolute frequency, the result will be nearest (in channel) interpolation such that the calibration edge channel closest to the visibility data will be used to calibrate that data.  \n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    " \n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    "Finally, please note that relative frequency interpolation is not yet available via the cal library.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "\n",
    " \n",
    "\n",
    "</div>\n",
    "\n",
    "###### Parallactic angle\n",
    "\n",
    "The *parang* parameter turns on the application of the antenna-based parallactic angle correction (P) in the Measurement Equation. This is necessary for polarization calibration and imaging, or for cases where the parallactic angles are different for geographically spaced antennas and it is desired that the ordinary calibration solves not absorb the inter-antenna parallactic angle phase. When dealing with only the parallel-hand data (e.g. RR, LL, XX, YY), and an unpolarized calibrator model for a co-located array (e.g. the VLA or ALMA), you can set *parang=False* and save some computational effort. Otherwise, set *parang=True* to apply this correction, especially if you are doing polarimetry.\n",
    "\n",
    "###### Solving parameters\n",
    "\n",
    "The parameters controlling common aspects of the solving process itself are:\n",
    "\n",
    "```\n",
    "solint              =      'inf'        #Solution interval: egs. 'inf', '60s' (see help)\n",
    "combine             =     'scan'        #Data axes which to combine for solve (obs, scan,\n",
    "                                        #spw, and/or field)\n",
    "preavg              =       -1.0        #Pre-averaging interval (sec) (rarely needed)\n",
    "refant              =         ''        #Reference antenna name(s)\n",
    "minblperant         =          4        #Minimum baselines _per antenna_ required for solve\n",
    "minsnr              =        3.0        #Reject solutions below this SNR\n",
    "solnorm             =      False        #Normalize solution amplitudes post-solve.\n",
    "corrdepflags        =      False        #Respect correlation-dependent flags\n",
    "```\n",
    "\n",
    "The time and frequency (if relevant) solution interval is specified in *solint*. Optionally a frequency interval for each solution can be added after a comma, e.g. *solint=\\'60s,300Hz\\'*. Time units are in seconds unless specified differently. Frequency units can be either \\'*ch*\\' or \\'*Hz*\\' and only make sense for bandpass or frequency dependent polarization calibration.  On the time axis, the special value \\'inf\\' specifies an infinite solution interval encompassing the entire dataset, while \\'int\\' specifies a solution every integration.  Omitting the frequency-dependent solution interval will yield per-sample solutions on this axis.  You can use time quanta in the string, e.g. *solint=\\'1min\\'* and *solint=\\'60s\\'* both specify solution intervals of one minute. Note that \\'*m*\\' is a unit of distance (meters); \\'*min*\\' must be used to specify minutes. The *solint* parameter interacts with *combine* to determine whether the solutions cross scan, field, or other meta-data boundaries.\n",
    "\n",
    "The parameter controlling the scope of each solution is *combine*. For the default, *combine=\\'\\'*, solutions will break at *obs*, *scan*, *field*, and *spw* boundaries. Specification of any of these in *combine* will extend the solutions over the specified boundaries (up to the solint). For example, *combine=\\'spw\\'* will combine spectral windows together for solving, while *combine=\\'scan\\'* will cross scans, and *combine=\\'obs,scan\\'* will use data across different observation IDs and scans (usually, obs Ids consist of many scans, so it is not meaningful to combine obs Ids without also combining scans). Thus, to do scan-based solutions (single solution for each scan, per spw, field, etc.), set\n",
    "\n",
    "```\n",
    "   solint = 'inf'\n",
    "   combine = ''\n",
    "```\n",
    "\n",
    "To obtain a single solution (per spw, per field) for an entire observation id (or the whole MS, if there is only one obsid), use:\n",
    "\n",
    "```\n",
    "   solint = 'inf'\n",
    "   combine = 'scan'\n",
    "```\n",
    "\n",
    "You can specify multiple choices for combination by separating the axes with commas, e.g.:\n",
    "\n",
    "```\n",
    "   combine = 'scan,spw'\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Care should be exercised when using *combine='spw'* in cases where multiple groups of concurrent spectral windows are observed as a function of time. Currently, only one aggregate spectral window can be generated in a single calibration solve execution, and the meta-information for this spectral window is calculated from all selected MS spectral windows. To avoid incorrect calibration meta-information, each spectral window group should be calibrated independently (also without using *append=True*). Additional flexibility in this area will be supported in a future version.\n",
    "</div>\n",
    "\n",
    "The reference antenna is specified by the *refant* parameter.  Ordinary MS Selection antenna selection syntax is used.  Ideally, use of *refant* is useful to lock the solutions with time, effectively rotating (after solving) the phase of the gain solutions for all antennas such that the reference antennas phase remains constant at zero.  In **gaincal,** it is also possible to select a *refantmode*, either \\'*flex*\\' or \\'*strict*\\'.  A list of antennas can be provided to this parameter and, for refantmode=\\'flex\\', if the first antenna is not present in the solutions (e.g., if it is flagged), the next antenna in the list will be used, etc.   See the documentation for the **rerefant** task for more information.  If the selected antenna drops out, the next antenna specified (or the next nearest antenna) will be substituted for ongoing continuity in time (at its current value) until the refant returns, usually at a new value (not zero), which will be kept fixed thenceforth.  You can also run without a reference antenna, but in this case the solutions will formally float with time; in practice, the first antenna will be approximately constant near zero phase. It is usually prudent to select an antenna near the center of the array that is known to be particularly stable, as any gain jumps or wanders in the *refant* will be transferred to the other antenna solutions. Also, it is best to choose a reference antenna that never drops out, if possible.Setting a *preavg* time will let you average data over periods shorter than the solution interval first before solving on longer timescales.  This is necessary only if the visibility data vary systematically within the solution interval in a manner independent of the solve-for factors (which are, by construction, considered constant within the solution interval), e.g., source linear polarization in **polcal**.  Non-trivial use of *preavg* in such cases will avoid loss of SNR in the averaging within the solution interval. \n",
    "\n",
    "The minimum signal-to-noise ratio allowed for an acceptable solution is specified in the *minsnr* parameter. Default is *minsnr=3*.\n",
    "\n",
    "The *minblperant* parameter sets the minimum number of baselines to other antennas that must be preset for each antenna to be included in a solution. This enables control of the constraints that a solution will require for each antenna. \n",
    "\n",
    "The *solnorm* parameter toggles on the option to normalize the solution after the solutions are obtained. The exact effect of this depends upon the type of solution (see **gaincal**, **bandpass**, and **blcal**).  Not all tasks use this parameter.One should be aware when using *solnorm* that if this is done in the last stage of a chain of calibration, then the part of the calibration that is normalized away will be lost. It is best to use this in early stages (for example in a first bandpass calibration) so that later stages (such as final gain calibration) can absorb the lost normalization scaling. It is generally not strictly necessary to use *solnorm=True* at all, but it is sometimes helpful if you want to have a normalized bandpass for example.\n",
    "\n",
    "The *corrdepflags* parameter controls how visibility vector flags are interpreted. If *corrdepflags=False* (the default), then when any one or more of the correlations in a single visibility vector is flagged (per spw, per baseline, per channel), it treats all available correlations in the single visibility vector as flagged, and therefore it is excluded from the calibration solve. This has been CASA\\'s traditional behavior (prior to CASA 5.7), in order to be conservative w.r.t. flags. If instead *corrdepFlags=True* (for CASA 5.7+), correlation-dependent flags will be respected exactly and precisely as set, such that any available unflagged correlations will be used in the solve for calibration factors.  For the tasks currently supporting the *corrdepflags* parameter (*gaincal, bandpass, fringefit*), this means any unflagged parallel-hand correlations will be used in solving, even if one or the other parallel-hand (or either of the cross-hands) is flagged.  Note that the *polcal* task does not support *corrdepflags* since polarization calibration is generally more sensitive to correlation-dependence in the flagging in ways which may be ill-defined for partial flagging; this stricture may be relaxed in future for non-leakage solving modes.  Most notably, this feature permits recovery and calibration of visibilities on baselines to antennas for which one polarization is entirely flagged, either because the antenna did not have that polarization at all (e.g., heterogeneous VLBI, where flagged visibilities are filled for missing correlations on single-polarization antennas), or one polarization was not working properly during the observation. \n",
    "\n",
    "###### Appending calibration solutions to existing tables\n",
    "\n",
    "The *append* parameter, if set to *True*, will append the solutions from this run to existing solutions in *caltable*. Of course, this only matters if the table already exists. If *append=False* and the specified caltable exists, it will overwrite it (if the caltable is not open in another process).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "The *append* parameter should be used with care, especially when also using *combine* in non-trivial ways. E.g., calibration solves will currently refuse to append incongruent aggregate spectral windows (e.g., observations with more than one group of concurrent spectral windows) when using *combine='spw'*. This limitation arises from difficulty determining the appropriate spectral window fan-out on apply, and will be relaxed in a future version.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gain Calibration \n",
    "\n",
    "General gain and bandpass calibration\n",
    "\n",
    "In general, gain calibration includes solving for time- and frequency-dependent multiplicative calibration factors, usually in an antenna-based manner.  CASA supports a range of options.\n",
    "\n",
    "Note that polarization calibration is described in detail in a [different section](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/synthesis-calibration/instrumental-polarization-calibration).\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequency-dependent calibration: **[bandpass](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_bandpass){.task-name}** \n",
    "\n",
    "Frequency-dependent calibration is discussed in the general task documentaion for **[bandpass](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_bandpass){.task-name}**.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gain calibration: **[gaincal](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_gaincal){.task-name}** \n",
    "\n",
    "Gain calibration is discussed in the general task documentation for **[gaincal](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_gaincal){.task-name}**.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flux density scale calibration: [fluxscale](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_fluxscale){.task-name} \n",
    "\n",
    "Flux density scale calibration is discussed in the general task documentation for **[fluxscale](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_fluxscale){.task-name}**.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline-based (non-closing) calibration: [blcal](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_blcal){.task-name} \n",
    "\n",
    "Non-closing baseline-based calibration is disussed in the general task documentation for **[blcal](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/global-task-list/task_blcal){.task-name}**.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polarization Calibration \n",
    "\n",
    "Solving for instrumental polarization\n",
    "\n",
    "Instrumental polarization calibration is necessary because the polarizing hardware in the receiving system will, in general, be impure and non-orthogonal at a level of at least a few percent.  These instrumental polarization errors are antenna-based and generally assumed constant with time, but the algebra of their effects is more complicated than the simple \\~scalar multiplicative gain calibration.  Also, the net gain calibration renders the data in an arbitrary cross-hand phase frame that must also be calibrated.   The **polcal** task provides support for solving for instrumental polarization (poltype=\\'Df\\' and similar) and cross-hand phase (\\'Xf\\').   Here we separately describe the heuristics of solving for instrumental polarization for the circular and linear feed bases.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polarization Calibration in the Circular Basis\n",
    "\n",
    "Fundamentally, with good ordinary gain and bandpass calibration already in hand, good polarization calibration must deliver both the instrumental polarization and position angle calibration. An unpolarized source can deliver only the first of these, but does not require parallactic angle coverage. A polarized source can only also deliver the position angle calibration if its polarization position angle is known a priori. Sources that are polarized, but with unknown polarization degree and angle, must always be observed with sufficient parallactic angle coverage (which enables solving for the source polarization), where \\\"sufficient\\\" is determined by SNR and the details of the solving mode.\n",
    "\n",
    "These principles are stated assuming the instrumental polarization solution is solved using the \\\"linear approximation\\\" where cross-terms in more than a single product of the instrumental or source polarizations are ignored in the [Measurement Equation](https://casa.nrao.edu/casadocs-devel/stable/casa-fundamentals/the-measurement-equation-calibration).  A more general non-linearized solution, with sufficient SNR, may enable some relaxation of the requirements indicated here, and modes supporting such an approach are currently under development.\n",
    "\n",
    "For instrumental polarization calibration, there are 3 types of calibrator choice, listed in the following table:\n",
    "\n",
    "  Cal Polarization   PA Coverage   Poln Model?   *poltype*     Result\n",
    "  ------------------ ------------- ------------- ------------- -----------------------\n",
    "  Zero               any           Q=U=0         *\\'Df\\'*      D-terms only\n",
    "  Unknown            2+ scans      ignored       *\\'Df+QU\\'*   D-terms and Q,U\n",
    "  Known, non-zero    2+ scans      Set Q,U       *\\'Df+X\\'*    D-terms and Pos Angle\n",
    "\n",
    "Note that the parallactic angle ranges spanned by the scans in the modes that require this should be large enough to give good separation between the components of the solution. In practice, 60 degrees is a good target.\n",
    "\n",
    "Each of these solutions should be followed with a \\'Xf\\' solution on a source with known polarization position angle (and correct fractional Q+iU in the model).\n",
    "\n",
    "The **polcal** task will solve for the \\'Df\\' or \\'Xf\\' terms using the model visibilities that are in the model attached to the MS. Calibration of the parallel hands must have already been obtained using **gaincal** and **bandpass** in order to align the amplitude and phase over time and frequency. This calibration must be supplied through the *gaintable* parameters, but any caltables to be used in **polcal** must agree (e.g. have been derived from) the data in the DATA column and the FT of the model. Thus, for example, one would not use the caltable produced by **fluxscale** as the rescaled amplitudes would no longer agree with the contents of the model.\n",
    "\n",
    "Be careful when using resolved calibrators for polarization calibration.  A particular problem is if the structure in Q and U is offset from that in I. Use of a point model, or a resolved model for I but point models for Q and U, can lead to errors in the \\'Xf\\' calibration. Use of a *uvrange* will help here. The use of a full-Stokes model with the correct polarization is the only way to ensure a correct calibration if these offsets are large.\n",
    "\n",
    "###### A note on channelized polarization calibration\n",
    "\n",
    "When your data has more than one channel per spectral window, it is important to note that the calibrator polarization estimate currently assumes the source polarization signal is coherent across each spectral window. In this case, it is important to be sure there is no large cross-hand delay still present in your data. Unless the online system has accounted for cross-hand delays (typically intended, but not always achieved), the gain and bandpass calibration will only correct for parallel-hand delay residuals since the two polarizations are referenced independently. Good gain and bandpass calibration will typically leave a single cross-hand delay (and phase) residual from the reference antenna.  Plots of cross-hand phases as a function of frequency for a strongly polarized source (i.e., that dominates the instrumental polarization) will show the cross-hand delay as a phase slope with frequency. This slope will be the same magnitude on all baselines, but with different sign in the two cross-hand correlations. This cross-hand delay can be estimated using the *gaintype=\\'KCROSS\\'* mode of **gaincal** (in this case, using the strongly polarized source *3C286*):\n",
    "\n",
    "```\n",
    "   gaincal(vis='polcal_20080224.cband.all.ms',\n",
    "           caltable='polcal.xdelcal',\n",
    "           field='3C286',\n",
    "           solint='inf',   \n",
    "           combine='scan',\n",
    "           refant='VA15',\n",
    "           smodel=[1.0,0.11,0.0,0.0],       \n",
    "           gaintype='KCROSS',       \n",
    "           gaintable=['polcal.gcal','polcal.bcal'])\n",
    "```\n",
    "\n",
    "Note that *smodel* is used to specify that *3C286* is polarized; it is not important to specify this polarization stokes parameters correctly in scale, as only the delay will be solved for (not any absolute position angle or amplitude scaling). The resulting solution should be carried forward and applied along with the gain (.gcal) and bandpass (.bcal) solutions in subsequent polarization calibration steps.\n",
    "\n",
    "###### Circular Basis Example\n",
    "\n",
    "In the following example, we have a MS called *polcal_20080224.cband.all.ms* for which we already have bandpass, gain and cross-hand delay solutions.  An instrumental polarization calibrator with unknown linear polarization has been observed.  We solve for the instrumental polarization and source linear polarization with **polcal** using *poltype=\\'Df+QU\\'* as follows:\n",
    "\n",
    "```\n",
    "polcal(vis= 'polcal_20080224.cband.all.ms',\n",
    "       caltable='polcal.pcal',\n",
    "       field='2202+422',       \n",
    "       solint='inf',   \n",
    "       combine='scan',\n",
    "       preavg=300.0,       \n",
    "       refant='VA15',       \n",
    "       poltype='Df+QU',       \n",
    "       gaintable=['polcal.gcal','polcal.bcal','polcal.xdelcal])\n",
    "```\n",
    "\n",
    "This run of **polcal** assumes that the model stored in the MS for *2202+422* is the one that was used to obtain the net gain calibration stored in *polcal.gcal* (i.e., we have not substituted a fluxscale result, which would create an inconsistent scale). \n",
    "\n",
    "Alternatively, if we have an instrumental polarization calibrator that we know is unpolarized, we run polcal with poltype=\\'Df\\':\n",
    "\n",
    "```\n",
    "polcal(vis='polcal_20080224.cband.all.ms',\n",
    "       caltable='polcal.pcal',\n",
    "       field='0319+415',\n",
    "       refant='VA15',       \n",
    "       poltype='Df',       \n",
    "       gaintable=['polcal.gcal','polcal.bcal','polcal.xdelcal])\n",
    "```\n",
    "\n",
    "In general, if there is more than one calibrator suitable for instrumental polarization calibration, it is useful to obtain a solution from each of them, and compare results.  The instrumental polarization should not vary with field, of course.  Note that it is not yet possible to effectively use *combine=\\'field\\'* for instrumental polarization calibration solves with **polcal**, unless the prior models for all fields are set to the correct apparent linear polarization for each.\n",
    "\n",
    "Having obtained the instrumental polarization calibration, we solve for the cross-hand phase using the flux density calibrator (for which the instrinsic linear polarization is known):\n",
    "\n",
    "```\n",
    "polcal(vis='polcal_20080224.cband.all.ms',\n",
    "       caltable= 'polcal.polx',\n",
    "       field='0137+331',\n",
    "       refant='VA15',       \n",
    "       poltype='Xf',\n",
    "       smodel=[1.0,-0.0348,-0.0217,0.0],       #the fractional Stokes for 0137+331 (3C48)\n",
    "       gaintable=['polcal.gcal','polcal.bcal','polcal.xdelcal','polcal.pcal'])\n",
    "```\n",
    "\n",
    "Note that the correct fractional polarization has been specified for *0137+331*.  It is not necessary to use the correct absolute total and linearly polarized flux densities here, since the Xf calibration is entirely phase-like.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polarization Calibration in the Linear Feed Basis\n",
    "\n",
    "CASA now supports instrumental polarization calibration for the linear feed basis at a level that is practical for the general user. Some details remain to be implemented with full flexibility, and much of what follows will be streamlined in future releases.\n",
    "\n",
    "Calibrating the instrumental polarization for the linear feed basis is somewhat more complicated than the circular feed basis because the polarization effects (source and instrument) appear in all four correlations at first or zeroth order (whereas for circular feeds, the polarization information only enters the parallel hand correlations at second order). As a result, e.g., the time-dependent gain calibration will be distorted by any non-zero source polarization, and some degree of iteration will be required to isolate the gain calibration if the source polarization is not initially known. These complications can actually be used to advantage in solving for the instrumental calibration; in can be shown, for example, that a significantly linearly polarized calibrator enables a better instrumental polarization solution than an unpolarized calibrator.\n",
    "\n",
    "In the following example, we show the processing steps for calibrating the instrumental polarization using a strongly (\\>5%) polarized point-source calibrator (which is also the time-dependent gain calibrator) that has been observed over a range of parallactic angle (a single scan is not sufficient). We assume that we have calibrated the gain, bandpass, and cross-hand delay as described [elsewhere](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/synthesis-calibration/gain-calibration), and that the gain calibration was obtained assuming the calibrator was unpolarized.\n",
    "\n",
    "######  Linear Basis Example\n",
    "\n",
    "First, we import some utility functions from the CASA recipes area:\n",
    "\n",
    "```\n",
    "from recipes.almapolhelpers import *\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Our MS in this example is called *polcal_linfeed.ms*.  We begin by assuming we already have a bandpass calibration result (obtained by conventional means) stored in *polcal.bcal*.  We first solve for a time-dependent gain solution on the instrumental polarization calibrator, which we expect to be significantly polarized, but for which we do not yet have a polarization model:\n",
    "\n",
    "```\n",
    "gaincal(vis='polcal_linfeed.ms',\n",
    "        caltable='polcal.gcal',  \n",
    "        field='1',                 #the instrumental polarization calibrator\n",
    "        solint='int',             \n",
    "        smodel=[1,0,0,0],          #assume zero polarization\n",
    "        gaintype='G',       \n",
    "        gaintable=['polcal.bcal'],\n",
    "        parang=T)                  #so source poln properly rotated\n",
    "```\n",
    "\n",
    "Since the gain calibrator was assumed unpolarized, the time-dependent gain solutions contain information about the source polarization. This can be seen by plotting the amp vs. time for this cal table using *poln=\\'/\\'.*  The antenna-based polarization amplitude ratios will reveal the sinusoidal (in parallactic angle) function of the source polarization. Run the utility method **qufromgain** to extract the apparent source polarization estimates for each spw:\n",
    "\n",
    "```\n",
    "qu=qufromgain('polcal.gcal')\n",
    "```\n",
    "\n",
    "The source polarization reported for all spws should be reasonably consistent. This estimate is not as good as can be obtained from the cross-hands (see below) since it relies on the gain amplitude polarization ratio being stable which may not be precisely true.  However, this estimate will be useful in resolving an ambiguity that occurs in the cross-hand estimates.\n",
    "\n",
    "Next we estimate both the XY-phase offset and source polarization from the cross-hands. The XY-phase offset is a spectral phase-only bandpass relating the X and Y systems of the reference antenna.  If the XY-phase is solved for in a channel-dependent manner (as below), it is strictly not necessary to have solved for the cross-hand delay as described above, but it does not hurt, as it allows reasonably coherent channel averages for data examination (we assume below that we have obtained the cross-hand delay solution at this stage). The source polarization occurs in the cross-hands as a sinusoidal function of parallactic angle that is common to both cross-hands on all baselines (for a point-source). If the XY-phase bandpass is uniformly zero, then the source linear polarization function will occur entirely in the real part of the cross-hand visibilities. Non-zero XY-phase has the effect of rotating the source linear polarization signature partially into the imaginary part, where circular (and instrumental) polarization occur (cf. the circular feed basis where the cross-hand phase merely rotates the position angle of linear polarization). The following **gaincal** solve averages all baselines together and first solves for a channelized XY-phase (the slope of the source polarization function in the complex plane in each channel), then corrects the slope and solves for a channel-averaged source polarization. This calibration is obtained using *gaintype=\\'XYf+QU\\'* in **gaincal**:\n",
    "\n",
    "```\n",
    "gaincal(vis='polcal_linfeed.ms',\n",
    "        caltable='polcal.xy0amb',  #possibly with 180deg ambiguity\n",
    "        field='1',                 #the calibrator\n",
    "        solint='inf',   \n",
    "        combine='scan',\n",
    "        preavg=200.0,              #minimal parang change\n",
    "        smodel=[1,0,1,0],          #non-zero U assumed\n",
    "        gaintype='XYf+QU',       \n",
    "        gaintable=['polcal.gcal','polcal.bcal','polcal.xdelcal])  #all prior calibration\n",
    "```\n",
    "\n",
    "Note that we imply non-zero Stokes U in *smodel*; this is to enforce the assumption of non-zero source polarization signature in the cross-hands in the ratio of data and model. This solve will report the center-channel XY-phase and apparent Q,U for each spw. The Q,U results should be recognizable in comparison to that reported by **qufromgain** above. However, since the XY-phase has a 180 degree ambiguity (you can rotate the source polarization signature to lie entirely in the visibility real part by rotating clockwise or counter-clockwise), some or all spw Q,U estimates may have the wrong sign. We correct this using the **xyamb** utility method, using the *qu* obtained from *qufromgain* above (which is not ambiguous):\n",
    "\n",
    "```\n",
    "S=xyamb(xy='polcal.xy0amb',qu=qu,xyout='polcal.xy0')\n",
    "```\n",
    "\n",
    "The python variable *S* now contains the mean source model (Stokes I =1; fractional Q,U; V=0) that can be used in a revision of the gain calibration and instrumental polarization calibration.\n",
    "\n",
    "Next we revise the gain calibration using the full polarization source model:\n",
    "\n",
    "```\n",
    "gaincal(vis='polcal_linfeed.ms',\n",
    "        caltable='polcal.gcal1',  \n",
    "        field='1',        \n",
    "        solint='int',             \n",
    "        smodel=S,                  #obtained from xyamb\n",
    "        gaintype='G',       \n",
    "        gaintable=['polcal.bcal'],\n",
    "        parang=T)                  #so source poln properly rotated\n",
    "```\n",
    "\n",
    "Note that *parang=T* so that the supplied source linear polarization is properly rotated in the parallel-hand visibility model. This new gain solution can be plotted with *poln=\\'/\\'* as above to show that the source polarization is no longer distorting it. Also, if **qufromgain** is run on this new gain table, the reported source polarization should be statistically indistinguishable from zero.\n",
    "\n",
    " Finally, we can now solve for the instrumental polarization:\n",
    "\n",
    "```\n",
    " polcal(vis= 'polcal_linfeed.ms',\n",
    "        caltable='polcal.dcal',\n",
    "        field='1',\n",
    "        solint='inf',\n",
    "        combine='scan',\n",
    "        preavg=200,\n",
    "        poltype='Dflls',      #freq-dep LLS solver\n",
    "        refant='',            #no reference antenna\n",
    "        smodel=S,\n",
    "        gaintable=['polcal.gcal1','polcal.bcal','polcal.xdelcal','polcal.xy0'])\n",
    "```\n",
    "\n",
    "Note that no reference antenna is used since this solve will produce an absolute instrumental polarization solution that is registered to the assumed source polarization (*S*) and prior calibrations. Applying a refant (referring all instrumental polarization terms to a reference antennas X feed, which would then be assumed perfect) would, in fact, discard valid information about the imperfections in the reference antennas X feed. (Had we used an unpolarized calibrator, we would not have a valid xy-phase solution, nor would we have had access to the absolute instrumental polarization solution demonstrated here.)\n",
    "\n",
    "A few points:\n",
    "\n",
    "-   Since the gain, bandpass, and XY-phase calibrations were obtained prior to the instrumental polarization solution and maybe distorted by it, it is generally desirable to re-solve for them using this instrumental polarization solution as a prior calibration. In effect, this means iterating the sequence of calibration steps using all of the best of the available information at each stage, including the source polarization (and *parang=T*). This is a generalization of traditional self-calibration.\n",
    "-   If the source linear polarization fraction and position angle is known *a priori*, the processing steps outlined above can be amended to use that source polarization assertion in the gain and instrumental calibration solves from the start. The *qufromgain* method is then not needed (but can be used to verify assumptions), the **gaincal(***\\...,gaintype=XYf+QU,\\...***)** should not be altered (parallactic angle coverage is still required!), and the **xyamb** run should use the *a priori* polarization for *qu*. If there is likely to be a large systematic offset in the mean feed position angle, iteration of the gain, bandpass, and instrumental polarization terms is required to properly isolate the calibration effects.\n",
    "-   Note that the above process does not explicitly include a position angle calibration. In effect, the estimated source polarization sets the mean feed position angle as the reference position angle, and this is usually within a degree or so of optimal for linear feeds. If your mean X feed position angle is not 0 degrees, and your MS does not account for the offset in its FEED subtable, be careful in your interpretation of the final position angle. Currently, the circular feed-specific position angle calibration modes of **polcal(**\\...,*poltype=\\'Xf\\',\\...***)** will not properly handle the linear feed basis; this will be fixed in a future release.    \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Water Vapor Radiometers \n",
    "\n",
    "Create phase correction gain table from ALMA Water Vapor Radiometer (WVR) data\n",
    "\n",
    "The task **wvrgcal** generates a gain table based on Water Vapor Radiometer (WVR) data and is used for ALMA data reduction. Briefly, the task enables a Bayesian approach to calculating the coefficients that convert the outputs of the ALMA 183 GHz water-vapor radiometers (mounted on each antenna) into estimates of path fluctuations which can then be used to correct the observed interferometric visibilities.\n",
    "\n",
    "The CASA task is an interface to the executable wvrgcal, which is part of the CASA 5 distribution and can also be called from outside CASA. The wvrgcal software is based on the libair and libbnmin libraries which were developed by Bojan Nikolic at the University of Cambridge as part of EU FP6 ALMA Enhancement program. CASA 5 contains version 2.1 of wvrgcal. The algorithmic core of wvrgcal is described in three ALMA memos (number 587 [\\[1\\]](#Bibliography), 588  [\\[2\\]](#Bibliography), and 593 [\\[3\\]](#Bibliography) ) which describe the algorithms implemented in the software.\n",
    "\n",
    "The CASA task interface to wvrgcal follows closely the interface of the shell executable at the same time staying within the CASA task parameter conventions. In ALMA data, the WVR measurements belonging to a given observation are contained in the ASDM for that observation. After conversion to an MS using **importasdm**, the WVR information can be found in separate spectral windows. As of April 2016, it is still one single spectral window for all WVRs, however, the ID of the spectral window may vary between datasets. The **wvrgcal** task identifies the SPW autonomously, but it can also be specified via the parameter *wvrspw* (see below). The specified spectral window(s) must be present in the MS for **wvrgcal** to work. This is not to be mixed up with the list of spectral windows for which solutions should be calculated and which can be specified with the parameter *spw*. Note that **wvrgcal** will calculate a correction only for the scans with the words ON_SOURCE, SIGNAL, or REFERENCE in the scan intent. The various features of **wvrgcal** are then controlled by a number of task parameters (see the list above). They have default values which will work for ALMA data. An example for a typical **wvrgcal** call can be found in the ALMA CASA guide for the NGC 3256 analysis:\n",
    "\n",
    "```\n",
    "wvrgcal(vis='uid___A002_X1d54a1_X5.ms',\n",
    "     caltable='cal-wvr-uid___A002_X1d54a1_X5.W',\n",
    "     toffset=-1,\n",
    "     segsource=True, tie=[\"Titan,1037-295,NGC3256\"], statsource=\"1037-295\",\n",
    "     wvrspw=[4],\n",
    "     spw=[17,19,21,23])\n",
    "```\n",
    "\n",
    "Here, *vis* is the name of input visibility file which as mentioned above also contains the WVR data and *caltable* is the name of the output gain calibration table. WVR data is typically in spectral window 0, but in the example above, the data are contained in spectral window 4. Although **wvrgcal** should automatically identify this SPW, it is explicitly specified with the *wvrspw* parameter in the above example. The *toffset* parameter is the known time offset in seconds between the WVR measurements and the visibility integrations for which they are valid. For ALMA, this offset is presently -1 s (which is also the default value).\n",
    "\n",
    "The parameter *segsource* (segregate source) controls whether separate coefficients are calculated for each source. The default value True is the recommended one for ALMA. When *segsource* is True, the subparameter *tie* is available. It permits the formation of groups of sources for which common coefficients are calculated as well as possible. The *tie* parameter ensures best possible phase transfer between a group of sources. In general it is recommended to tie together all of the sources in a single Science Goal (in ALMA speak) and their phase calibrator(s). The recommended maximum angular distance up to which two sources can be tied is 15 degrees. The parameter statsource controls for which sources statistics are calculated and displayed in the logger. This has no influence on the generated calibration table.\n",
    "\n",
    "Via the parameter *spw*, one can control for which of the input spectral windows **wvrgcal** will calculate phase corrections and store them in the output calibration table. By default, solutions for all spectral windows are written except for the ones containing WVR data. The **wvrgcal** task respects the flags in the Main and ANTENNA table of the MS. The parameter *mingoodfrac* lets the user set a requirement on the minimum fraction of good measurements for accepting the WVR data from an antenna. If antennas are flagged, their WVR solution is interpolated from the three nearest neighboring antennas. This process can be controlled with the new parameters *maxdistm* and *minnumants*. The former sets the maximum distance an antenna used for interpolation may have from the flagged one. And *minnumants* sets how many near antennas there have to be for interpolation to take place. For more details on the WVR Phase correction, see also the the ALMA Memo \"Quality Control of WVR Phase Correction Based on Differences Between WVR Channels\" by B. Nikolic, R. C. Bolton & J. S. Richer [\\[4\\]](#Bibliography) , see also ALMA memo 593 [\\[3\\]](#Bibliography).\n",
    "\n",
    "######  Statistical parameters shown in the logger output of wvrgcal\n",
    "\n",
    "The **wvrgcal** task writes out a variety of information to the logger, including various statistical measures of the performance. This allows the user to judge whether WVR correction is appropriate for the MS, to check whether any antennas have problematic WVR values, and to examine the predicted performance of the WVR correction when applied. For each set of correction coefficients which are calculated (the number of coefficient sets are controlled by the parameters *nsol*, *segsource* and *tie*), the **wvrgcal** output to the logger first of all shows the time sample, the individual temperatures of each of the four WVR channels, and the elevation of the source in question at that time. For each of these coefficient sets, it then gives the evidence of the bayesian parameter estimation, the calculated precipitable water vapor (PWV) and its error in mm, and the correction coefficients found for each WVR channel (dTdL).\n",
    "\n",
    "The output then shows the statistical information about the observation. First of all it gives the start and end times for the parts of the observation used to calculate these statistics (controlled by *segsource*). It then shows a break down for each of the antennas in the data set. This gives the antenna name and number; whether or not it has a WVR (column WVR); whether or not it has been flagged (column FLAG); the RMS of the path length variation with time towards that antenna (column RMS); and the discrepancy between the RMS path length calculated separately for different WVR channels (column Disc.). These values allow the user to see if an individual WVR appears to have been suffering from problems during the observation, and to flag that antenna using *wvrflag* if necessary. This discrepancy value, Disc., can in addition be used as a simple diagnostic tool to evaluate whether or not the WVR correction caltable created by **wvrgcal** should be applied. In the event of the WVR observations being contaminated by strong cloud emission in the atmosphere, the attempt by **wvrgcal** to fit the water vapor line may not be successful, and applying the produced calibration table can in extreme cases reduce the quality of the data. However, these weather conditions should identified by a high value in the discrepancy column produced when running **wvrgcal**.\n",
    "\n",
    "Discrepancy values of greater than a 1000 microns usually indicate strong cloud contamination of the WVR data, and the output calibration table should probably not be applied. If the values are between 100 and 1000 microns, then the user should manually examine the phases before and after applying the caltable to decide if WVR correction is appropriate. Work is underway at ALMA to provide additional routines to at least partially remove the cloud component from the WVR data before calculating phase corrections. CASA 4.7 will contain a first tested version of such a tool. After the antenna-by-antenna statistics, the output then displays some estimates of the performance of the **wvrgcal** correction. These are the thermal contribution from the water vapor to the path fluctuations per antenna (in microns), the largest path fluctuation found on a baseline (in microns), and the expected error on the path length calculated for each baseline due to the error in the coefficients (in microns).\n",
    "\n",
    "######  Antenna position calculation\n",
    "\n",
    "The information about antenna pointing direction is by default taken from the POINTING table. Should this table not be present for some reason, the user can instead switch to determining the antenna positions from the phase directions in the FIELD table (under the assumption that all antennas were pointing ideally). The switch is performed by setting the parameter *usefieldtab* to True.\n",
    "\n",
    "######  Spectral window selection\n",
    "\n",
    "By default, **wvrgcal** puts solutions for all spectral windows of the MS into the output calibration table. Since usually only the spectral windows are of interest in which the science target and the calibrators were observed, it is not necessary to store solutions for other spectral windows. The spectral windows for which solutions are stored can be selected with the parameter *spw*, e.g. spw = \\[17,19,21,23\\] will make **wvrgcal** write only solutions for spectral windows 17, 19, 21, and 23. With respect to the input WVR spectral windows, **wvrgcal** will by default regard all windows with 4 channels as WVR data. In typical ALMA data there is only one such spectral window in each ASDM. This may change in the future. In any case, the input WVR spectral window(s) can be selected with the optional parameter *wvrspw*. The syntax is the same as for the parameter *spw* above.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. [ALMA\\ Memo\\ 587](http://library.nrao.edu/public/memos/alma/memo587.pdf)\\ \n",
    "2. [ALMA\\ Memo\\ 588](http://library.nrao.edu/public/memos/alma/memo588.pdf)\\ \n",
    "3. [ALMA\\ Memo\\ 593](http://library.nrao.edu/public/memos/alma/memo593.pdf)\\ \n",
    "4. [ALMA\\ Memo\\ \"Quality\\ Control\\ of\\ WVR\\ Phase\\ Correction\\ Based\\ on\\ Differences\\ Between\\ WVR\\ Channels\"](https://casa.nrao.edu/Memos/memoqachannels.pdf)\\ \n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine/Edit Cal Tables \n",
    "\n",
    "How to plot, list, and adjust calibration tables\n",
    "\n",
    "Information on examination and manipulation of calibration tables can be found in the task documentation for **plotcal**, **listcal**, **calstat**, **smoothcal**, and **browsetable**.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Calibration \n",
    "\n",
    "How to apply calibration to generate data for imaging\n",
    "\n",
    "Please see the task documentation for **applycal** for details on application of calibration.\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Dish Calibration \n",
    "\n",
    "Motivation, background, and process for calibrating single-dish observations\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview \n",
    "\n",
    "Chapter overview\n",
    "\n",
    "This section describes the motivation, background, and process for calibrating ALMA single-dish observations.\n",
    "\n",
    "Below are brief descriptions of the calibration process, followed by a description of the various observing modes, and then a step-by-step description of the calibration process in CASA.\n",
    "\n",
    "It is recommended that newcomers review the description of calibration in [Single-dish calibration: background](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/single-dish-calibration/single-dish-calibration-background) and descriptions of various observing modes in [Single-dish observing modes](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/single-dish-calibration/single-dish-observing-modes) before examining the reduction processes decribed in [Single-dish data calibration and reduction](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/single-dish-calibration/single-dish-data-calibration-and-reduction). Future directions are broadly outlined in [Future development goals for CASA single-dish](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/single-dish-calibration/future-development-goals-for-casa-single-dish).\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Background SD Calibration \n",
    "\n",
    "Brief description of calibrating ALMA single-dish observations\n",
    "\n",
    "Like any single-dish telescope, ALMA\\'s single dish antennas (nominally, four 12m antennas) detect and quantify brightness temperature ($T_B$, in Kelvin). In the Rayleigh-Jeans approximation, the Planck blackbody law reduces to $T_B=\\frac{B\\lambda^2}{2k}$.  \n",
    "\n",
    "An ALMA single-dish observation includes contributions from sky targets in the beam, the telescope surface and receiver equipment, the ground (through reflections), the atmosphere and cosmic background, and any other electronics (necessarily noisy) following the receiver front end. Observations made with a single dish towards a target ($T_{ON}$) are calibrated using an additional observation towards blank sky (i.e. sky at a similar elevation, absent of any target emission at the frequencies of interest to the observer ($T_{OFF}$)).\n",
    "\n",
    "To determine the signal from the target, we can compute:\n",
    "\n",
    "$\\frac{T_{targ}}{T_{sys}}=\\frac{T_{ON}-T_{OFF}}{T_{OFF}}$.   (In CASA, this is accomplished during the \\\"sky calibration\\\" step).\n",
    "\n",
    "The position of the OFF is made as close as possible (in az/el) to the ON position.  As a practical matter, there may be some differences in the two measurements aside from the target being in the ON position. In most cases, the differences arise chiefly from the atmospheric contribution, though any target coincidentally within the beam of the OFF measurement will contaminate and affect the accuracy of the OFF measurement, and consequently, the measurement of the calibrated brightness temperature of the target.\n",
    "\n",
    "To calibrate single dish data, we require a measurement of $T_{sys}$, which is done though $T_{atm}$ (i.e. \\\"atmosphere\\\") measurements at the start of each scheduling block.  (In CASA, this is applied through the $T_{sys}$ calibration step.)  $T_{sys}$ determination includes separate observations of the sky, and two \\\"loads\\\" of different, known temperatures.\n",
    "\n",
    "Note that $T_{sys}(\\nu)$ measurements are spectral; that is, they determine $T_{sys}$ as function of frequency. Since they incorporate an observation of the sky, they may include atmospheric features such as the water absorption line in Band 5 at $\\sim$183 GHz. So the calibration of the entire band must be done in the frequency domain.\n",
    "\n",
    "It is policy that ALMA single-dish data must only be observed to supplement and be combined with interferometer observations. Therefore, the single-dish data needs to be converted from its native units of brightness temperature ($T_A^*$) to flux density units (Jy/beam) before combination with the interferometric data. The conversion from $T_A^*$ to Jy/beam is done empirically, and incorporates a factor for forward beam efficiency. The empirical conversion (Jy to K) is computed through mapping observations (done recently in time) of a standard target - either a planet or a quasar - and the scaling from $T_A^*$ to Jy/beam is then made simply and directly from the calibrator map and applied to the science target map. \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bibliography\n",
    "\n",
    "1. O\\'Neil,\\ 2002\\ in\\ \\\"The\\ NAIC/NRAO\\ School\\ on\\ Single\\ Dish\\ Radio\\ Astronomy\\\"\\ C.\\ Salter,\\ et.al\\ eds.\\ (\n",
    "2. PdBI\\ mm\\ astro\\ summer\\ school\\ notes\\ (Dutrey,\\ Dutrey\\ &\\ Neri;\\ Guélin)\\ \n",
    "3. Unpublished\\ ALMA\\ memo:\\ Robert\\ Lucas,\\ 2005\\ \n",
    "^\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing Modes \n",
    "\n",
    "ALMA modes for observing: PS, OTF, and OTF-raster\n",
    "\n",
    "At present, ALMA single dish observing has three modes: PS (position switched), OTF (on the fly), and OTF-raster (Rasterized on the fly). These have slightly different observation/scanning patterns, and also have differences in the cadence and position of the OFF measurements.\n",
    "\n",
    "In the case of the PS mode, the OFF position is specified by the PI before the observations.  The OFF positions have a specific and periodic cadence and should, where possible, be at approximately the same azimuth as the observations of the science target. Note that PS mode observations can include mapping observations, and this is actually the general mode for ALMA single-dish observations.\n",
    "\n",
    "For OTF-raster, the telescope scans the observing target, including some additional length on either side of the target.  The reference data are interpolated from the OFF positions at the edge of the scans. It is assumed that the bandpass profile varies slowly as a function of scan position. This mode yields a slightly better calibration than position switching, since the variation in the air mass is typically more consistent between the OFF data and the target.  At present, ALMA uses OTF-raster mode to calibrate observations of the amplitude (i.e. Jy-to-K) calibrators.\n",
    "\n",
    "For OTF mode, the observations are not rasterized.  The scanning pattern for OTF observations can take several forms.  Solar observations, for example, use a double-circle scan. In this case the entire periphery of the observed region is identified as an OFF measurement.  The OTF-raster mode, on the other hand, uses the first and last points of the raster rows as the OFF. A mean bandpass is formed from the OFF measurements, interpolated in time, and applied to any measurements not identified as OFF.  For OTF and OTF-raster, specific OFF posiotions are not explicitly nominated prior to the observations. \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calibration & Reduction \n",
    "\n",
    "Reduction details and method\n",
    "\n",
    "##### Single-dish data calibration and reduction\n",
    "\n",
    "Generally, the calibration of ALMA single-dish data requires essentially only two steps - the application of the $T_{sys}$ calibration, and the application of the \\\"sky\\\" calibration (i.e. OFF). With just these steps, the product is $T_A^*$ in units of Kelvin. While the steps are described in detail here, an example of the full single-dish calibration process can be found in the [M100 Band 3 Single Dish CASAguide](https://casaguides.nrao.edu/index.php/M100_Band3_SingleDish_4.3).\n",
    "\n",
    "In the following description, we refer to data in the ALMA-native format of ASDM (ALMA Science Data Model) with a variable name *asdm*, while we refer to the CASA-native format of MeasurementSet with a variable name *sd_ms*. In the case of single-dish data, the MeasurementSet data are not formally *visibilities*, since they are simply auto-correlations.\n",
    "\n",
    "1.  **importasdm**: Import the ASDM\n",
    "2.  **listobs** - List observation parameters\n",
    "3.  **flagdata** and **flagcmd** - A priori flagging\n",
    "4.  **gencal**, **applycal**, and **sdcal**- Generate and apply the $T_{sys}$ and sky calibration tables\n",
    "5.  **flagdata** - Do initial flagging\n",
    "6.  **applycal** -  Calibrate the data into Kelvins\n",
    "7.  **sdbaseline** - Subtract the baseline\n",
    "\n",
    "**1. Import of the ASDM: *ImportASDM***\n",
    "\n",
    "Import of ASDM data and conversion into the MeasurementSet format is achieved via the **importasdm** task. The task settings are a little different to those used when importing interferometer ASDMs. For instance, *bdfflags=False* will de-select application of the BDF format flags, which are of no consequence in the normal reduction process, and *with_pointing_correction=True* will directly apply the *measured* pointing direction (in Azimuth and Elevation) to the data, rather than the *commanded* pointing positions. For example:\n",
    "\n",
    "```\n",
    "importasdm(asdm, asis='Antenna Station Receiver Source CalAtmosphere CalWVR CorrelatorMode SBSummary', bdfflags=False, process_caldevice=False, with_pointing_correction=True)\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "**2. List observations parameters: *listobs* **\n",
    "\n",
    "**listobs** works for single dish observations in the same way as for interferometry, and will detail the calibration scans.  It identifies pointing, $T_{sys}$, and target scans, the science target and OFF scans and their cadence, the correlator frequencies and configuration, and the antennas used in the observations. Unique to the single-dish data is the \\#OFF_SOURCE intent. This task is used to identify which spectral windows are used for $T_{sys}$ observations.  This information is critical for those who wish to build their own calibrations.\n",
    "\n",
    "```\n",
    "listobs(sd_ms)\n",
    "```\n",
    "\n",
    "produces feedback in the logger (or optionally, to a file) from which we can determine which spectral windows are $T_{sys}$ observations and which are science observations.\n",
    "\n",
    "```python\n",
    "Spectral Windows: (25 unique spectral windows and 2 unique polarization setups)\n",
    "SpwID Name #Chans Frame Ch0(MHz) ChanWid(kHz) TotBW(kHz) CtrFreq(MHz) BBC Num Corrs\n",
    "\n",
    "  0  BB_1#SQLD                                       1   TOPO  195994.575   2000000.000   2000000.0 195994.5750        1  XX  YY\n",
    "  1  BB_2#SQLD                                       1   TOPO  197932.075   2000000.000   2000000.0 197932.0750        2  XX  YY\n",
    "  2  BB_3#SQLD                                       1   TOPO  207994.575   2000000.000   2000000.0 207994.5750        3  XX  YY\n",
    "  3  BB_4#SQLD                                       1   TOPO  209994.575   2000000.000   2000000.0 209994.5750        4  XX  YY\n",
    "  4  WVR#NOMINAL                                     4   TOPO  184550.000   1500000.000   7500000.0 187550.0000        0  XX\n",
    "  5  X436890472#ALMA_RB_05#BB_1#SW-01#FULL_RES     128   TOPO  196986.763    -15625.000   2000000.0 195994.5750        1  XX  YY\n",
    "  6  X436890472#ALMA_RB_05#BB_1#SW-01#CH_AVG         1   TOPO  195978.950   1796875.000   1796875.0 195978.9500        1  XX  YY\n",
    "  7  X436890472#ALMA_RB_05#BB_2#SW-01#FULL_RES     128   TOPO  198924.263    -15625.000   2000000.0 197932.0750        2  XX  YY\n",
    "  8  X436890472#ALMA_RB_05#BB_2#SW-01#CH_AVG         1   TOPO  197916.450   1796875.000   1796875.0 197916.4500        2  XX  YY\n",
    "  9  X436890472#ALMA_RB_05#BB_3#SW-01#FULL_RES     128   TOPO  207002.388     15625.000   2000000.0 207994.5750        3  XX  YY\n",
    "  10 X436890472#ALMA_RB_05#BB_3#SW-01#CH_AVG         1   TOPO  207978.950   1796875.000   1796875.0 207978.9500        3  XX  YY\n",
    "  11 X436890472#ALMA_RB_05#BB_4#SW-01#FULL_RES     128   TOPO  209002.388     15625.000   2000000.0 209994.5750        4  XX  YY\n",
    "  12 X436890472#ALMA_RB_05#BB_4#SW-01#CH_AVG         1   TOPO  209978.950   1796875.000   1796875.0 209978.9500        4  XX  YY\n",
    "  13 BB_1#SQLD                                       1   TOPO  183375.638   2000000.000   2000000.0 183375.6378        1  XX  YY\n",
    "  14 BB_2#SQLD                                       1   TOPO  181427.463   2000000.000   2000000.0 181427.4627        2  XX  YY\n",
    "  15 BB_3#SQLD                                       1   TOPO  169374.840   2000000.000   2000000.0 169374.8404        3  XX  YY\n",
    "  16 BB_4#SQLD                                       1   TOPO  170917.638   2000000.000   2000000.0 170917.6378        4  XX  YY\n",
    "  17 X1857092512#ALMA_RB_05#BB_1#SW-01#FULL_RES   4096   TOPO  183162.808       122.070    500000.0 183412.7471        1  XX  YY\n",
    "  18 X1857092512#ALMA_RB_05#BB_1#SW-01#CH_AVG        1   TOPO  183412.686    500000.000    500000.0 183412.6861        1  XX  YY\n",
    "  19 X1857092512#ALMA_RB_05#BB_2#SW-01#FULL_RES   4096   TOPO  181177.524       122.070    500000.0 181427.4627        2  XX  YY\n",
    "  20 X1857092512#ALMA_RB_05#BB_2#SW-01#CH_AVG        1   TOPO  181427.402    500000.000    500000.0 181427.4017        2  XX  YY\n",
    "  21 X1857092512#ALMA_RB_05#BB_3#SW-01#FULL_RES   4096   TOPO  169587.670   -122.070    500000.0 169337.7310        3  XX  YY\n",
    "  22 X1857092512#ALMA_RB_05#BB_3#SW-01#CH_AVG        1   TOPO  169337.670    500000.000    500000.0 169337.6700        3  XX  YY\n",
    "  23 X1857092512#ALMA_RB_05#BB_4#SW-01#FULL_RES   4096   TOPO  171158.788   -122.070    500000.0 170908.8487        4  XX  YY\n",
    "  24 X1857092512#ALMA_RB_05#BB_4#SW-01#CH_AVG        1   TOPO  170908.788    500000.000    500000.0 170908.7877        4  XX  YY\n",
    "```\n",
    "\n",
    "From this output, we see the science spectral windows are 17, 19, 21 and 23, and have 4096 channels, while the $T_{sys}$ spectral windows at 5, 7, 9 and 11 have 128 channels.\n",
    "\n",
    " \n",
    "\n",
    "**3. A priori flagging: *flagcmd/flagdata***\n",
    "\n",
    "**flagcmd** works the same way on single-dish data as for interferometry. In this case, invoking it here applies flagging, by default, from the FLAG_CMD file within the MeasurementSet.\n",
    "\n",
    "```\n",
    "flagcmd(vis = 'uid___A002_Xb978c3_X5c4b.ms', inpmode = 'table', useapplied = True, action = 'apply')\n",
    "```\n",
    "\n",
    "**flagdata** is used at this point to remove problematic data. Conventionally, 5% of the edges of the bands are removed, as these parts of the band are significantly and detrimentally affected by the low-sensitivity edges of the filter passband. In principle, they can be retained in the cases where spectral lines of interest fall in that area, though the sensitivity losses are significant.\n",
    "\n",
    "Users should examine their spectra using **plotms**, and ensure any atmospheric lines are properly accounted for. This is particularly true for Band 5 which has a strong atmospheric absorption line at $\\sim$183 GHz. There is no real way to remove the signature of the atmospheric lines in position-switched data, since the elevations of the ON (science target) and OFF (sky-calibration position) are almost always different, and therefore have different air masses. The most effective approach in this case is to complete the normal calibrations as described here, then apply a judiciously-selected bandpass correction polynomial and spectral window channel range, as described by the **sdbaseline** step below.\n",
    "\n",
    "```\n",
    "flagdata(vis=vis, mode='manual', spw='17:0~119;3960~4079,19:0~119;3960~4079,21:0~119;3960~4079,23:0~119;3960~4079', action='apply', flagbackup=True)\n",
    "```\n",
    "\n",
    "Both steps **flagcmd** and **flagdata** are generally useful, but care should be taken in case the emission lines of interest are being inadvertantly flagged out.\n",
    "\n",
    " \n",
    "\n",
    "**4. Generation of the **$T_{sys}$ and $T_{sky}$ calibration tables: *gencal, sdcal and applycal*\n",
    "\n",
    "There are two ways to proceed in CASA when computing and applying calibration tables for single dish observations.\n",
    "\n",
    "1.  Build the $T_{sys}$ calibration tables with **gencal**, build the sky calibration tables with **sdcal,** and apply them with **applycal**\n",
    "2.  Build and apply both the $T_{sys}$ and sky calibration tables with **sdcal**\n",
    "\n",
    "The second option is faster, but users familar with the **gencal** and **applycal** tasks may prefer the first option.\n",
    "\n",
    "In either case, the mapping between the $T_{sys}$ scans and science scans must be determined either by examination of the output of **listobs**, or by running the **sdcal** and specifying the method to be used to obtain the OFF position. Usually ALMA will take position-switched observations via *mode=*\\'*ps*\\', though other alternatives exist which do not need any OFF positions to be explicitly observed. The OFF can be obtained from the source data itself via *mode=*\\'*otfraster*\\' or *mode=*\\'*off*\\'.\n",
    "\n",
    " \n",
    "\n",
    "In the first of the two cases mentioned above (having identified the target spectral windows as 17,19,21 and 23, and using a target identified by the variable name, \\\"source\\\") :\n",
    "\n",
    "```\n",
    "gencal(vis = sd_ms, caltable = sd_ms+'.tsys', caltype = 'tsys')\n",
    "\n",
    "sdcal(infile = sd_ms, outfile = sd_ms+'.sky', calmode = 'ps')\n",
    "\n",
    "from recipes.almahelpers import tsysspwmap\n",
    "tsysmap = tsysspwmap(vis = sd_ms, tsystable = sd_ms+'.tsys', trim = False)\n",
    "\n",
    "applycal(vis = sd_ms, applymode = 'calflagstrict', spw = '17,19,21,23', field = source, gaintable = [sd_ms+'.tsys', sd_ms+'.sky'], gainfield = ['nearest', source], spwmap = tsysmap)\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "In the second case:\n",
    "\n",
    "```\n",
    "sdcal(infile=sd_ms, calmode='ps,tsys,apply')\n",
    "```\n",
    "\n",
    "Note that we didn\\'t specify the $T_{sys}$ spectral windows in the call to **sdcal. ** For ALMA single-dish data from Cycle 3 onward, this is okay since the $T_{sys}$ and science data share the same spectral window.   Alternatively, the mapping between the $T_{sys}$ and science spectral windows can be explicitly set with *spwmap* and *spw.* In this case, we would use:\n",
    "\n",
    "```\n",
    "sdcal(infile=vis, calmode='ps,tsys,apply', spwmap={17:[17], 19:[19], 21:[21],23:[23]}, spw='17,19,21,23')\n",
    "```\n",
    "\n",
    "The general structure of *spwmap* is {Tsys spw 0: \\[science spw 0\\],\\....,Tsys spw n: \\[science spw n\\]} for 0 to n spectral windows.\n",
    "\n",
    "**gencal** applied at this stage builds (and optionally applies) the $T_{sys}$ calibration tables. These calibrations are an intrinsic part of the ASDM. There are no re-computations applied to the $T_{sys}$ data by CASA. Ultimately, the $T_{sys}$ calibration tables will be applied in the **applycal** step, consistent with the descriptions of calibrations given in the sections above. We point out that the $T_{sys}$ calibrations are a multiplicative factor, so the order of the application of the $T_{sys}$ cal tables relative to the application of the $T_{sky}$ calibrations is immaterial.\n",
    "\n",
    "**8. Subtracting the baseline: *sdbaseline***\n",
    "\n",
    "It\\'s important at this point to define exactly what is meant by *baseline* in the context of single-dish data. In interferometry, *baseline* refers to the spatial separation of antenna pairs.  For a single dish observation, *baseline* refers to the spectral pattern produced by the atmosphere and instrument. Since single-dish antennas measure total power, not an interference pattern, they are responsive to emission wherever it exists within the single-dish beam or signal path. This signal is dominated by the receiver/correlator/backend sampling function, but has a significant time-varying component usually dominated by atmospheric fluctuations. The power yielded by atmospheric fluctuations are invisible to interferometer observations, as they are in the *near field*, and are therefore generally resolved out from the data.  Note, though, that the atmospheric variability can contaminate interferometric measurements by introducing a decoherence in phase, and such losses in phase are not relevant for single-dish observations.\n",
    "\n",
    "**sdbaseline** removes a spectral baseline from the data on a per-integration basis. The options here are extensive, and baseline subtraction can be complex when emission is strongly variable throughout the map, or when there are nearby atmospheric absorption features.  But CASA is effective at choosing intelligent defaults with *mode=\\'auto\\'*. With *mode=\\'auto\\'*, CASA will examine the brightness variability per integration and determine the most appropriate channel ranges for computing the spectral baseline, based on the mean absolute deviation of the channels. This approach is successful even when applied to spectra crowded heavily with emission lines.  As long as the emission-free parts of the spectrum have statistically significant representation in the data, then the *mode=\\'auto\\'* will be successful. Baseline corrections employed by CASA are subtracted, and therefore can be applied iteratively, as needed.\n",
    "\n",
    "**sdbaseline** supports Polynomial, Chebychev and Sinusoid baseline removal. Sinusoidal baselines are determined with a Fourier transform of the spectral data - again, an automatic mode is available, where CASA will determine the most significant Fourier components and remove them, though specific wavenumbers can be explicitly added or removed on top of the automatic operation. Sinusoidal components occur in many single-dish telescopes, and are a typical manifestation of a standing-wave resonation of the main-reflector/subreflector cavity. ALMA has employed scattering cones in the single-dish subreflectors to effectively mitigate the strength of this standing wave. It\\'s worth noting that removal of Fourier components should be applied with utmost caution; the result is effectively a convolution of the spectra with a spectral filter, and MUST affect the resulting emission spectra. Users who use this baseline mode should explore and characterize the consequences and subsquent error propagation, in the context of their own data.In this example, we remove a 1st order polynomial from spectral windows 17, 19, 21 & 23, automatically finding and masking out any lines brighter than 5 $\\sigma$, and referencing the \\\"corrected\\\" (i.e. calibrated) data column.\n",
    "\n",
    "```\n",
    "sdbaseline(infile = sd_ms, datacolumn = 'corrected', spw = '17,19,21,23', maskmode = 'auto', thresh = 5.0, avg_limit = 4, blfunc = 'poly', order = 1, outfile = sd_ms+'.cal')\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "Note that at this point, the product dataset (sd_ms+\\'.cal) has only four spectral windows. These are (if all is going well) the science observations which are $T_{sys}$ and sky calibrated, and are now bandpass-corrected.\n",
    "\n",
    " \n",
    "\n",
    "**9. Convert the Science Target Units from Kelvin to Jansky: *scaleAutocorr***\n",
    "\n",
    "To convert the units of the single-dish observations from $T_A^*$ (K) into Janskys and to prepare for combination with interferometer data, we need to obtain the empirically-determined Jy-to-K conversion data. These data already take into account any correlator non-linearities and also factor in the various subsystem efficiencies. \n",
    "\n",
    "The easiest way to obtain this is simply with a call to a specialized CASA task that obtains the Jy-to-K factors that accesses polynomal fits from ongoing calibration campaign data.\n",
    "\n",
    "```\n",
    "jyperk = es.getJyPerK(sd_ms+'.cal')\n",
    "```\n",
    "\n",
    "The contents of this variable jyperk is a python dictionary:\n",
    "\n",
    "```\n",
    "for ant in jyperk.keys():\n",
    "for spw in jyperk[ant].keys():\n",
    "scaleAutocorr(vis=sd_ms+'.cal', scale=jyperk[ant][spw]['mean'], antenna=ant, spw=spw)\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "**scaleAutocorr** simply applies the scaling from $T_A^*$ to Jy/beam. The scaling factors are determined empirically, as part of the QA2-level calibrations provided by ALMA. The scaling factors are to be provided to **scaleAutocorr** as a float, but are most conveniently applied in calls that iterate through antenna and spectral window, where the Jy-per-K factors are retained as a list with the format:\n",
    "\n",
    " \n",
    "\n",
    "```python\n",
    " jyperk = \n",
    "\n",
    "  { antenna01_name { spw0: { 'mean': 44.345, 'n': '', 'std': ''},\n",
    "\n",
    "              spw1: { 'mean': 44.374, 'n': '', 'std': ''},\n",
    "\n",
    "              spw2: { 'mean': 44.227, 'n': '', 'std': ''},\n",
    "\n",
    "              spw3: { 'mean': 44.203, 'n': '', 'std': ''}},\n",
    "\n",
    "    antenna02_name: { spw0: { 'mean': 44.345, 'n': '', 'std': ''},\n",
    "\n",
    "              spw1: { 'mean': 44.374, 'n': '', 'std': ''},\n",
    "\n",
    "              spw2: { 'mean': 44.227, 'n': '', 'std': ''},\n",
    "\n",
    "              spw3: { 'mean': 44.203, 'n': '', 'std': ''}}}\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    "which can be iterated and applied to the actual data with the following loop:\n",
    "\n",
    "```\n",
    "\n",
    "to_amp_factor = lambda x: 1. / sqrt(x)\n",
    "\n",
    " \n",
    "\n",
    "for ant in jyperk.keys():\n",
    "\n",
    "   factors=[]\n",
    "\n",
    "   for spw in jyperk[ant].keys():\n",
    "\n",
    "      factors.append(jyperk[ant][spw]['mean'])\n",
    "\n",
    "   gencal(vis=sd_ms, caltable=sd_ms+'.jy2ktbl', caltype='amp', spw=\",\".join(str(x) for x in jyperk[ant].keys()), parameter=map(to_amp_factor, factors))\n",
    "\n",
    "   applycal(vis=sd_ms+'.cal', gaintable=sd_ms+'.jy2ktbl')\n",
    "\n",
    "```\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future Development Goals \n",
    "\n",
    "Ongoing software development goals for CASA single-dish\n",
    "\n",
    "The top development priority for CASA single-dish data reduction is the conversion to the MeasurementSet format for the full reduction process. Dispensing with the ASAP (scan table) format will help unify data processing by providing a more homogenous basis for data processing, reduction, and analysis, as well as streamline and make more versatile the development aspects; current and future developers need only be familiar with one overall format of data. As such, ASAP will be gone in 5.1. However, please note that the **importasap** task is the only exception and will not go away even after removing ASAP. This task supports importing existing scantables in CASA for backward compatibility.There is also significant active development to add header information to plots made by **plotms**. While preserving the multi-plot capability and building a layout that will not cramp or obfuscate the plot output, header information (i.e. target name, frequency, integration time, etc.) can be optionally added to the plots output by **plotms**.There are a number of additional improvements that we do not detail here. ALMA-related development requests and bug notices can be sent to the CASA Single Dish Team via the [ALMA Helpdesk](https://help.almascience.org/).\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cal Library Syntax \n",
    "\n",
    "How to use Cal Library\n",
    "\n",
    "The \\\"Cal Library\\\" is a new means of expressing calibration application instructions.  It has nominally been available in **applycal** and the calibration solve tasks since CASA 4.1, via the *docallib=True* parameter, as an alternative to the traditional parameters (e.g., *gaintable*, etc.)  that most users continue to use.  As of CASA 4.5, we have deployed use of the Cal Library for *on-the-fly* calibration in **plotms** and **mstransform**.  In CASA 4.5, our intent is to demonstrate the Cal Library and begin familiarizing users with it.  The capabilities remain limited in some ways, and new features, additional flexibility, and broader deployment in more tasks will be offered in later releases.This page describes basic use of the Cal Library.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Please note the section on current (CASA 4.5, 4.6, 4.7, 5.*) limitations.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Cal Library usage\n",
    "\n",
    "The Cal Library is a means of specifying calibration instructions in an ascii file, rather than via the traditional *gaintable/gainfield/interp/spwmap/calwt* parameters that often become clumsy when many caltables are involved, and which have rather limited flexibility.  Instead of specifying the traditional parameters, the file name is specified in the *callib* parameter in **applycal** or **plotms** (in **applycal** one must also specifiy *docallib=True*).  For example, to correct an MS called *my.ms*, with a Cal Library file called *mycal.txt*:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',docallib=True,callib='mycal.txt')\n",
    "```\n",
    "\n",
    "In a Cal Library file, each row expresses the calibration apply instructions for a particular caltable and (optionally) a specific selection of data in the MS to which it is to be applied.For example, if *mycal.txt* contains:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' tinterp='linear' calwt=True\n",
    "```\n",
    "\n",
    "this will arrange a caltable called *cal.G* to be applied (with no detailed selection) to all MS data with linear interpolation in time, and with the weights also calibrated.  It corresponds to these settings for the traditional parameters in **applycal**:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',gaintable='cal.G',gainfield='',interp='linear',\n",
    "         spwmap=[],calwt=True)\n",
    "```\n",
    "\n",
    "If a bandpass table, *cal.B*, is also available for application, one might use the following Cal Library file:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' tinterp='linear' calwt=True\n",
    "caltable='cal.B' finterp='linear' calwt=False\n",
    "```\n",
    "\n",
    "This example arranges the same instructions for *cal.G*, and adds a bandpass table that will be interpolated linearly in frequency (the default for time-dependent interpolation is linear, if the bandpass table contains more than one time sample), without weight calibration.  The corresponding form with the traditional parameters is:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',gaintable=['cal.G','cal.B'], gainfield=['',''],\n",
    "         interp=['linear','linear,linear'],\n",
    "         spwmap=[],calwt=[True,False])\n",
    "```\n",
    "\n",
    "In general, the Cal LIbrary file should be easier to read and manage than the traditional parameters as the number of specified caltables grows.A more complicated example, involving non-trivial *spwmap* as well as field selection (*fldmap*) in the caltable:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' tinterp='linear' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.B' finterp='linear' fldmap='3' spwmap=[0,0,0,0] calwt=False\n",
    "```\n",
    "\n",
    "In this case, solutions from *cal.G* will be selected based on directional proximity (*\\'nearest\\'*) for each MS field via the *fldmap* parameter, and spw 2 will be calibrated by spw 1 solutions.  For *cal.B*, solutions from field id 3 will be selected exclusively from the caltable, with spw 0 calibrating all MS spws (of which there are apparently 4).  The corresponding settings for the traditional parameters is as follows:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['linear','linear,linear'],\n",
    "         spwmap=[[0,1,1,3],[0,0,0,0]],calwt=[True,False])\n",
    "```\n",
    "\n",
    "Comment lines may be included in the cal library file by starting a line with the $#$ character.  (Partial line comments are *not* supported, as yet.)  Existing cal library lines can be turned off (for experimentation purposes) by making those lines comments with $#$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More advanced Cal Library Usage\n",
    "\n",
    "The real power of the Cal Library arises from the ability to specify calibration instructions for a caltable *per MS selection*.  This enables consolidating what would be multiple **applycal** executions using the traditional parameters into a single execution.  Extending the example from above, if the MS field *\\'cal\\'* should be calibrated by *cal.G* with *\\'nearest\\'* interpolation in time, and the field *\\'sci\\'* with *\\'linear\\'* interpolation in time, the following Cal Library file will achieve this:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' field='cal' tinterp='nearest' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.G' field='sci' tinterp='linear' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.B' finterp='linear' fldmap='3' spwmap=[0,0,0,0] calwt=False\n",
    "```\n",
    "\n",
    "Note that the algorithm for selecting solutions from the caltable (*fldmap=\\'nearest\\'*, which may resolve differently for the two MS fields) hasn\\'t been changed, but it could be.  In fact, any of the calibration parameters can be adjusted per MS selection, except *calwt*, which if set to *True* for any MS selection, will be forced to *True* for all (to maintain weight consistency within the MS).  MS selection by spw, intent, and obs id can also be used (see the glossary below).The pair of **applycal** executions corresponding to this Cal Library would be:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',field='cal',gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['nearest','linear,linear'], spwmap=[[0,1,1,3],[0,0,0,0]],calwt=[True,False])\n",
    "\n",
    "applycal(vis='my.ms',field='sci',gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['linear','linear,linear'], spwmap=[[0,1,1,3],[0,0,0,0]],calwt=[True,False])\n",
    "```\n",
    "\n",
    "When there are many fields to which to apply carefully-selected calibration, *fldmap=\\'nearest\\'* may not properly select the correct calibrator fields for each target field.  In this case, the index list style form of *fldmap* (like *spwmap*) can be used (where field ids 1,4,6 are calibators, and 2,5,7 are the corresponding science fields):\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' field='1,2,3,4,5,6,7' tinterp='nearest' fldmap=[0,1,1,3,4,4,6,6] spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.B' finterp='linear' fldmap='3' spwmap=[0,0,0,0] calwt=False\n",
    "```\n",
    "\n",
    "In this example, field 1 will calibrate itself and field 2.  Similarly, 4 will calibrate itself and 5, and 6 will calibrate itself and 7.   The bandpass calibrator (3) has been included, too, calibrating itself.  Field indices are specified in the *field* and *fldmap* parameters here, for clarity.   While field names can be used in *field*, the *fldmap* parameter, which in this form is an indexing list, can only interpret indices (note that field 0 is also explicitly included in the *fldmap* to preserve the integrity of the indexing). \n",
    "\n",
    "If multiple calibrators are required for each individual science fields, use the string selection form of *fldmap*, and specify separate entries for each science field:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.G' field='1,3,4,6,8,9,10' tinterp='nearest' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.G' field='2' tinterp='linear' fldmap='1,8' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.G' field='5' tinterp='linear' fldmap='4,9' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.G' field='7' tinterp='linear' fldmap='6,10' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.B' finterp='linear' fldmap='3' spwmap=[0,0,0,0] calwt=False\n",
    "```\n",
    "\n",
    "The additional calibrators for science fields 2, 5, and 7 are 8, 9, and 10, respectively.  The first entry for *cal.G* accounts for all calibrators (including field 3, the bandpass calibrator), using *fldmap=\\'nearest\\'* to ensure they are each calibrated solely by themselves.  Then, in separate entries, fields 1 and 8 are selected for field 2, fields 4 and 9 are selected for field 5, and fields 6 and 10 are selecterd for field 7.   When using the string selection style in *fldmap*, field names can be used, if desired.\n",
    "\n",
    " \n",
    "\n",
    "##### Exclusivity\n",
    "\n",
    "Since the Cal Library permits MS-selection-specific calibration specifications, it is even possible to specify different caltables for different MS selections, and take advantage of an implicit *exclusivity* property of the Cal Library.  In the above example, the G calibration for the *\\'cal\\'* and *\\'sci\\'* fields may come from different caltables, *\\'cal.Gcal\\'* and *\\'cal.Gsci\\',* respectiveily (these caltables may have been solved with different solution intervals, for example).  We would specify the Cal Library as follows:\n",
    "\n",
    "```\n",
    "#mycal.txt cal library file\n",
    "caltable='cal.Gcal' field='cal' tinterp='nearest' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.Gsci' field='sci' tinterp='linear' fldmap='nearest' spwmap=[0,1,1,3] calwt=True\n",
    "caltable='cal.B' finterp='linear' fldmap='3' spwmap=[0,0,0,0] calwt=False\n",
    "```\n",
    "\n",
    "In this case, the *cal.B* table would be applied to both fields as before, but *cal.Gcal* would only be applied to field *\\'cal\\'* and *cal.Gsci* would only be applied to field *\\'sci\\'*.   Both tables would ignore data from the field they weren\\'t intended for.   The corresponding pair of **applycal** calls would be executed as follows:\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',field='cal',gaintable=['cal.Gcal','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['nearest','linear,linear'], spwmap=[[0,1,1,3],[0,0,0,0]],calwt=[True,False])\n",
    "\n",
    "applycal(vis='my.ms',field='sci',gaintable=['cal.Gsci','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['linear','linear,linear'], spwmap=[[0,1,1,3],[0,0,0,0]],calwt=[True,False])\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "NB: The Cal Libaray exclusivity property described here only works in CASA version 5.3 and later.  In prior versions, the Cal Library system implicitly assumed that all caltables specifed in the Cal Library were nominally intended for all data selections and would have as much MS-selection-specificty as needed explicitly included.   In that case, missing explicit specifications would result in an error message indicating that the Cal Library was missing an explicit MS-selection-specific entry.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Rules (current, as of CASA 4.5, 4.6, 4.7, 5.\\*)\n",
    "\n",
    "-    Each non-comment line in the Cal Library file must contain a valid (existing) caltable name\n",
    "-    Blank lines (i.e., containing whitespace only) will be ignored\n",
    "-    All parameters (see glossary below) are name/value pairs using an equals sign, delimited with spaces (no commas!)\n",
    "-   Only those parameters (see glossary) for which non-default values are required need be specified\n",
    "-   Each set of coordinated instructions must occur on a single line (there is no line continuation operator, as yet)\n",
    "-   If detailed MS selection is used, care must be exercised to ensure it is mutually exclusive over all MS rows for the same caltable; there is currently no internal checking for redundancy, and only the last calibration instructions for a particular MS selection will be invoked\n",
    "-   Full-line comments are supported by inserting the $#$ character as the first non-whitespace character in the line.  This mechanism can be used to turn off ordinary cal library lines.\n",
    "-   When quoted items within a selection string are used, e.g. field=\\'\\\"B0007+106; J0010+109\\\",GRB021004\\', the string must have double quotation marks enclosing single quotation marks or single quotation marks enclosing double quotation marks.  Parsing will fail with a syntax error if the enclosed marks match the outer marks.  Note: the enclosed quotation marks are not needed; field=\\'B0007+106; J0010+109,GRB021004\\' would work, with the field names separated by commas.\n",
    "\n",
    "##### Limitations\n",
    "\n",
    "-   Application of parallactic angle corrections is not yet supported within the Cal Library file (this only affects use in plotms, where there is no parang parameter)\n",
    "-   Some parametrized calibration tables (*BPOLY*, *GSPLINE*) are not yet supported\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion from Existing applycal Scripts\n",
    "\n",
    "To convert exiting **applycal** commands, a simple experimental function, **applycaltocallib** is available.  To access it, type (within CASA):\n",
    "\n",
    "```\n",
    "from callibrary import applycaltocallib\n",
    "```\n",
    "\n",
    "Then, chose a filename for the cal library file, and supply existing settings for **applycal** parameters (*field*, *spw*, *intent*, *gaintable*, *gainfield*, *interp*, *spwmap*, *calwt*) to the **applycaltocallib** function:\n",
    "\n",
    "```\n",
    "callibfile='mycallib.txt'\n",
    "applycaltocallib(filename=callibfile,append=False,\n",
    "                 field,spw,intent,gaintable,gainfield,\n",
    "                 interp,spwmap,calwt)\n",
    "```\n",
    "\n",
    "If *append=False*, the specified *filename* will be overwritten, if it already exists.  If *append=True*, new entries will be appended to the existing *filename*.  Only parameters with non-trivial **applycal** settings need be included.  In general, if *gaintable* is a python list, it is best if *gainfield*, *interp*, *spwmap*, and *calwt* (where non-trivially set) are also lists.For example, if your conventional script contains the following **applycal** executions (duplicated from above):\n",
    "\n",
    "```\n",
    "applycal(vis='my.ms',field='cal',\n",
    "         gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['nearest','linear,linear'],\n",
    "         spwmap=[[0,1,1,3],[0,0,0,0]],\n",
    "         calwt=[True,False])\n",
    "applycal(vis='my.ms',field='sci',\n",
    "         gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "         interp=['linear','linear,linear'],\n",
    "         spwmap=[[0,1,1,3],[0,0,0,0]],\n",
    "         calwt=[True,False])\n",
    "```\n",
    "\n",
    "\\...these can be edited to **applycaltocallib** executions as:\n",
    "\n",
    "```\n",
    "callibfile='mycallib.txt'\n",
    "applycaltocallib(filename='mycallib.txt',append=False,\n",
    "                 field='cal',\n",
    "                 gaintable=['cal.G','cal.B'], gainfield=['nearest','3'],\n",
    "                 interp=['nearest','linear,linear'],\n",
    "                 spwmap=[[0,1,1,3],[0,0,0,0]],\n",
    "                 calwt=[True,False])\n",
    "applycaltocallib(filename='mycallib.txt',append=True,\n",
    "                 field='sci',\n",
    "                 gaintable=['cal.G','cal.B'],\n",
    "                 gainfield=['nearest','3'],\n",
    "                 interp=['linear','linear,linear'],\n",
    "                 spwmap=[[0,1,1,3],[0,0,0,0]],\n",
    "                 calwt=[True,False])\n",
    "```\n",
    "\n",
    "After running them, *mycallib.txt* will contain:\n",
    "\n",
    "```\n",
    "caltable='cal.B' calwt=False field='cal' tinterp='linear' finterp='linear' fldmap='3' spwmap=[0, 0, 0, 0]\n",
    "caltable='cal.G' calwt=True field='cal' tinterp='nearest' fldmap='nearest' spwmap=[0, 1, 1, 3]\n",
    "caltable='cal.B' calwt=False field='sci' tinterp='linear' finterp='linear' fldmap='3' spwmap=[0, 0, 0, 0]\n",
    "caltable='cal.G' calwt=True field='sci' tinterp='linear' fldmap='nearest' spwmap=[0, 1, 1, 3]\n",
    "```\n",
    "\n",
    "Note that the *cal.B* table is specified separately for the *\\'cal\\'* and *\\'sci\\'* fields with otherwise the same parameters; thus, those two lines could be manually consolidated to a single line with unified field selection, yielding:\n",
    "\n",
    "```\n",
    "caltable='cal.B' calwt=False field='cal,sci' tinterp='linear' finterp='linear' fldmap='3' spwmap=[0, 0, 0, 0]\n",
    "caltable='cal.G' calwt=True field='cal' tinterp='nearest' fldmap='nearest' spwmap=[0, 1, 1, 3]\n",
    "caltable='cal.G' calwt=True field='sci' tinterp='linear' fldmap='nearest' spwmap=[0, 1, 1, 3]\n",
    "```\n",
    "\n",
    "The field selection for the first row could be removed entirely if *cal.B* will be used uniformly for all fields in the MS (equivalently, *field=\\'\\'*).  This sort of row consolidation is optional, but it may have useful memory efficiency benefits when running **applycal**, and so is recommended.The **applycaltocallib** function should be considered experimental and used with care, and the resulting file examined thoroughly for correctness, since this function will not do any internal duplication checking or other sanity checks.  All other current constraints and limitations on cal libraries (as noted above) will apply.\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glossary\n",
    "\n",
    "This is a list of recognized Cal Library parameters.  For each, the default is indicated.  Additional parameters enhancing flexibility will be added in CASA 4.5 and later.\n",
    "\n",
    "###### General\n",
    "\n",
    "-   *caltable* \\-\\-- the name of the caltable for which the instructions on the current line apply; no default; required\n",
    "\n",
    "###### MS Selection\n",
    "\n",
    "Use these parameters to implement calibration instructions specific to particular MS selections (using standard MS Selection syntax, except where noted):\n",
    "\n",
    "-   *field* \\-\\-- the MS field selection for which the calibration instructions on the current line apply; default=*\\'\\'* (all fields)\n",
    "-   *spw* \\-\\-- the MS spw selection for which the calibration instructions on the current line apply; default=*\\'\\'* (all spws) Note that channel selection will be ignored, since the Cal Library does not support variety in calibration application at channel granularity.\n",
    "-   *intent* \\-\\-- the MS intent selection for which the calibration instructions on the current line apply; default=*\\'\\'* (all intents)\n",
    "-   *obs* \\-\\-- the MS observation id selection for which the calibration instructions on the current line apply; default=*\\'\\'* (all obs ids)\n",
    "\n",
    "######  Interpolation/application\n",
    "\n",
    "-   *tinterp* \\-\\-- the time-dependent interpolation mode; default=*\\'linear\\'* options: *\\'linear\\'*, *\\'nearest\\'*\n",
    "-   *finterp* \\-\\-- the chan-dependent interpolation mode (only relevant for channelized caltables); default=\\'linear\\' options: *\\'nearest\\', \\'linear\\', \\'cubic\\', \\'spline\\'*\n",
    "-   *calwt* \\-\\-- weight calibration; default=*True*  options: *True*, *False*\n",
    "\n",
    "###### Calibration mapping\n",
    "\n",
    "The following *\\*map* parameters enable selection on the caltable.  For each *\\*map* parameter, the basic specification is an ordered list indicating the caltable selection indices intended for each MS index on that axis.  E.g., *spwmap=\\[0,1,1,3\\]* means MS spws 0,1,3 will each be be calibrated by the same spw index from the caltable, and MS spw 2 will be calibrated by cal spw 1.  The *\\*map* parameters support other short-hand options as well, as indicated below.  For defaults, \\\"index identity\\\" means that each MS index will be calibrated by the corresponding caltable index, and \\\"no explicit mapping\\\" means that no filter will be applied to that axis, and all available solutions on the axis will be included.\n",
    "\n",
    "-   *spwmap* \\-\\-- spectral window mapping; default=index identity\n",
    "-   *fldmap* \\-\\-- field mapping; default=*\\[\\]* (no explicit mapping); additional options: *\\'nearest\\'* or a string indicating field selection on the caltable (same as traditional *gainfield* options)\n",
    "-   *antmap* \\-\\-- antenna id mapping; default=index identity\n",
    "-   *obsmap* \\-\\-- obs id mapping; default=*\\[\\]* (no explicit mapping)\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Weights \n",
    "\n",
    "A detailed description of visibility weighting\n",
    "\n",
    "Visibility weight initialization and calibration has undergone several improvements in CASA 4.2.2 and CASA 4.3. This appendix briefly describes the formal weight definitions, and the changes occurring in these CASA versions.  If data sets shall be combined that were reduced with different CASA versions, the weights may need to be adjusted accordingly. This can be achieved, e.g. by running the same version of **statwt** on all datasets before combination. The best option, however, is to use a single CASA version for all reductions, preferrably 4.2.2 or later.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**NOTE**: Post-calibration weights, e.g. imaging weights or tapers are not covered here.\n",
    "</div>\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The *SIGMA* and *WEIGHT* columns\n",
    "\n",
    "Formally, in CASA 4.2.2 and later, the *SIGMA* column in the measurement set will reflect the per-channel noise of the *DATA* column as it depends on the channel bandwidth $\\Delta \\nu$ and the length of an integration $\\Delta t$:\n",
    "\n",
    "$SIGMA = \\frac{1}{\\sqrt{2\\Delta \\nu \\Delta t}}$\n",
    "\n",
    "The factor of $\\sqrt{2}$ is for cross-correlations only and auto-correlation data follows:\n",
    "\n",
    "$SIGMA = 1/\\sqrt{\\Delta \\nu \\Delta t}$.\n",
    "\n",
    "*SIGMA* will only be updated if the time and channel widths are modified along with any *DATA* column manipulation, e.g. through averaging, binning, smoothing, etc. (tasks like **mstransform**, **cvel**, **split**, **exportuvfits**, etc).\n",
    "\n",
    "The *WEIGHT* column reflects how much weight each *CORRECTED_DATA* sample should receive when data are combined (e.g., in averaging). To start with, *WEIGHT* is initialized from the *SIGMA* column via:\n",
    "\n",
    "$WEIGHT = \\frac{1}{{SIGMA}^2} = 2 \\Delta \\nu \\Delta t$\n",
    "\n",
    "Data calibration by **applycal** with *calwt=True* will calculate and modify the *WEIGHT* values but not *SIGMA*. Calibration applies multiplicative factors and the *WEIGHT* of a visibility on a baseline between antennas $i$ and $j$ is calculated via:\n",
    "\n",
    "$WEIGHT_{ij}=\\frac{c_i c_j}{{SIGMA}_{ij}^2}$\n",
    "\n",
    "where $c_i$ and $c_j$ are the net antenna-based power calibration factors derived by **applycal** ($c_i=c_j$ for auto-correlation data). In the table below, we list the definitions of antenna-based $c$ for different calibration procedures and CASA versions. When more than one calibration is applied, the product of the relevant weight factors is used.\n",
    "\n",
    "                                      $<=$CASA 4.2.1                                                CASA 4.2.2/4.3                                 $>=$CASA 4.4 *(WEIGHT_SPECTRUM)*\n",
    "  -------------------- ----------------------------------------------------------------------------------------- ---------------------------------------------------------------------------- ------------------------------------------------------------------------------\n",
    "  Initialization                           $1.0$                         $2 \\Delta \\nu \\Delta t$           $2 \\Delta \\nu \\Delta t$\n",
    "  System Temperature    $\\frac{1}{<\\sqrt{T_{\\rm sys, k}}>_{k}^{2}}$   $\\frac{1}{<T_{\\rm sys, k}>_k}$      $\\frac{1}{T_{\\rm sys, k}}$\n",
    "  Gain                                   $||G||^2$                              $||G||^2$                         $||G||^2$\n",
    "  Bandpass                   $\\frac{1}{<||B||^{-1}>_{k}^{2}}$               $<||B||^{2}>_{k}$                 $<||B||^{2}>_{k}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights in CASA 4.2.1 and Earlier\n",
    "\n",
    "The *SIGMA* and *WEIGHT* columns are initialized with values of $1.0$.  Traditionally, this convention was adequate for datasets with uniform sampling in time in frequency; a global weight scale factor would not affect calibration and imaging fidelity. In data manipulation operations (e.g., **split**, etc.), *SIGMA* was treated as a per-channel value and *WEIGHT* as a per-spw (all channels) weight. Combined with unit initialization, this difference in definition could lead to incongruent weight scales for different spectral windows, in particular if bandwidth and channel count varied. CASA 4.2.1 is therefore not recommended for datasets which have variety in spectral window bandwidth and channelization and for which spectral windows are to be combined in imaging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights in CASA 4.2.2\n",
    "\n",
    "In CASA 4.2.2 the *SIGMA* and *WEIGHT* columns are properly initialized via the definition in the above equations. Both are defined as per-channel values. Also, the weight calibration factors have been subtly updated to improve robustness, as indicated in the Table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights in CASA 4.3\n",
    "\n",
    "In CASA 4.3 frequency variations of the *WEIGHT* and *SIGMA* values are (optionally) captured in additional *WEIGHT_SPECTRUM* and *SIGMA_SPECTRUM* columns. This allows accommodation of variations of effective sensitivity on a channel by channel basis (e.g. band edges, atmospheric lines, spectral $T_{\\rm sys}$ variation etc.). *WEIGHT_SPECTRUM* will be recognized in the **applycal** task as well as in **mstransform** and **clean**. Calibration solvers, however, will not yet calculate and modify *WEIGHT_SPECTRUM*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights in CASA 4.4 and later\n",
    "\n",
    "Full support of *WEIGHT_SPECTRUM*.  \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ephemeris Data \n",
    "\n",
    "Overview of handling ephemeris data in CASA\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ephemeris Objects \n",
    "\n",
    "Background information concerning ephemeris objects\n",
    "\n",
    "Since ALMA Cycle 3, the ALMA observatory includes in each raw dataset (SDM) all necessary ephemerides in the so-called Ephemeris table, an XML file which corresponds to the ephemeris used during the observation. Upon import to MS format, the task **importasdm** will translate the xml ephemerides into separate CASA ephemeris tables for each field, which have the same format as those used by the task **setjy**. Examples can be found in the subdirectory \\\"data/ephemerides/JPL-Horizons\\\" in each CASA distribution.\n",
    "\n",
    "The ephemeris tables are automatically attached to the corresponding field(s) and can be used whenever needed. They have two main use cases:\n",
    "\n",
    "1.  An ephemeris table is necessary for the *spectral* frame transformation of the visibilities to the source rest frame *permanently* when creating a new MS using the tasks **cvel, cvel2,** or **mstransform,** or *on-the-fly* during imaging using the task **tclean** by setting the parameter *specmode* to \\\"cubesource\\\". The ephemeris provides the location of the phase center and the radial velocity of the target.\n",
    "2.  An ephemeris table is also necessary if your observation has tracked some other phase center but you would like to track the location described by the ephemeris. This can be achieved by setting the parameter *phasecenter* of task **tclean** to the string \\\"TRACKFIELD\\\". See the **tclean** documentation for more details.\n",
    "\n",
    "The ephemerides used by ALMA are originally for the observer location of ALMA (topocentric). They use the ICRS coordinate reference frame and typically have a time spacing of ten or twenty minutes. For the later transformation of the spectral reference frame, however, a geocentric ephemeris is necessary. The **importasdm** task will therefore by default also perform a conversion from the ALMA observer location to the geocenter. This is controlled by the **importasdm** parameter *convert_ephem2geo* which is True by default.\n",
    "\n",
    "The spectral reference frame of the visibilities in the SDM is always topocentric (TOPO), the observer reference frame. To analyze spectral lines in an ephemeris source, it can be helpful to transform the visibilities to the source rest spectral frame (REST). This is in particular necessary when the velocity of the source varies significantly throughout the observation (which can, e.g., happen if the observation is spread over serveral days). As mentioned above, this offline software Doppler-shift correction can be achieved in two ways, either permanently or on-the-fly. This is described further below.\n",
    "\n",
    "When an ephemeris is attached to a field of the MS FIELD table, the object position does not correspond to the direction columns of the FIELD table but is retrieved by linearly interpolating from the ephemeris table for the given time. The nominal entry of the direction column then *changes its meaning to an angular offset* with respect to the ephemeris. Thus, if the field center is exactly at the position described by the ephemeris, the nominal entries of the direction column are zero for right ascension and declination. The offset feature of the FIELD table direction column comes into play in the case of a mosaic: if there are a number of fields with nearby positions, the fields can share an ephemeris; they all reference the same ephemeris table via the optional column EPHEMERIS_ID, but have different offsets in their direction column entries.\n",
    "\n",
    "Because the nominal FIELD table direction column entries do not correspond to the actual object position, one should obtain the object position with the following special tool method:\n",
    "\n",
    "```\n",
    "msmd.phasecenter()\n",
    "```\n",
    "\n",
    "or the more general:\n",
    "\n",
    "```\n",
    "ms.getfielddirmeas()\n",
    "```\n",
    "\n",
    "(see the inline CASA help for details on these tools). The default time of the position is taken from the TIME column of the FIELD table.\n",
    "\n",
    "###### Permanent spectral frame transformation creating a new MS\n",
    "\n",
    "Either with either the task **cvel** or its faster implementation **cvel2** (which uses internally the same code as the task **mstransform**) or with **mstransform**, a new MS can be created which contains visibilities in the spectral reference frame of the source. All three tasks should produce the same result. As a matter of fact, an online Doppler-shift tracking corresponding to the velocity of the source at the beginning of the observation is applied during observations. This online correction allows one to tune the spectral windows adequately to match the requested rest frequencies, but the labelling of the spectral frame of the raw data remains in TOPO.\n",
    "\n",
    "The user must set the *outframe* parameter of **cvel**, **cvel2**, or **mstransform** to \\\"SOURCE\\\". This will lead to a transformation from the TOPO to the GEO reference frame followed by an additional time-dependent Doppler correction according to the radial velocity of the object as given by its ephemeris.\n",
    "\n",
    "Such MSes should then be imaged using the setting \\\"cubedata\\\" for the parameter *specmode* in **tclean**. The resulting spectral reference frame in the MS is named \\\"REST\\\".\n",
    "\n",
    "###### On-the-fly spectral frame transformation within tclean\n",
    "\n",
    "If a permanent storage of spectrally transformed visibilities in a new MS is not needed, cubes with the spectral frame of the ephemeris object can also be obtained by letting the task **tclean** perform the frame transformation on-the-fly. This is simply achieved by setting parameter *specmode* to the string \\\"cubesource\\\". The resulting cube will also have the reference frame named \\\"REST\\\".\n",
    "\n",
    " \n",
    "\n",
    "In summary, with ephemerides included in the ALMA raw data and the added support for this in the **importasdm** task, the user rarely needs to worry about how to obtain the right ephemeris in the right format and how to attach it properly to the MS. This process is transparent and only a few logger messages indicate that it is happening (see CASA Docs pages on [\\'Manipulate Ephemeris Objects\\'](https://casa.nrao.edu/casadocs-devel/stable/calibration-and-visibility-data/ephemeris-data/manipulation-of-ephemeris-objects) if a new ephemeris needs to be added to an existing MS). The correct time-dependent positions, radial velocities, and object distances are used in all relevant tasks such as **listobs**, **plotms**, and, as described above, **cvel**, **cvel2**, **mstransform**, and **tclean**. For Solar-System object flux calibrators, the task **setjy** will, however, only extract the nominal position from the SDM ephemeris and otherwise use its internal set of ephemerides since these contain additionally needed object parameters. Care has to be taken when trying to extract the field positions from the FIELD table as the nominal direction column entries will only be offsets (w.r.t. the ephemeris position) when an ephemeris is attached.\n",
    "\n",
    "As opposed to ALMA data which use a tabulated representation of the ephemerides, VLA data use a polynomial representation of the positions and radial velocities. Also this representation is supported. The polynomial ephemeris is internally tabulated with a default time step of 0.001 days and then processed as in the ALMA case. The **importasdm** parameter *polyephem_tabtimestep* can be used to control the step size of the tabulation.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulate Ephemeris Objects \n",
    "\n",
    "How to work with ephemeris objects in CASA\n",
    "\n",
    "When an astronomical object has a proper motion, in particular objects in our solar system, a static (RA,Dec) position in the FIELD table of the MeasurementSet will not accurately describe the time-dependent position. Prior to CASA 4.2, there was no support for ephemeris objects other than the built-in reference frames for the Sun, the Moon, and the planets out to PLUTO. With CASA 4.2, several new features were introduced which help the user to attach an arbitrary ephemeris to a given field and work with the object from calibration to imaging. These can be used when no ephemeris table was provided by the observatory, or in cases where the use of an improved ephemeris table is necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ephemeris tables\n",
    "\n",
    "The CASA format for ephemeris tables was introduced in the early development stages of CASA in connection with the Measures module. The me tool (see [CASA Tools](https://casa.nrao.edu/casadocs-devel/stable/old-pages/casa-tasks-and-tools/casa-tools) on using the tool kit, as well as the inline help on the me tool inside CASA for specific usage) permits position calculations based on ephemerides in this format. Two examples for such tables can be found in the distribution directory in subdirectory data/ephemerides: VGEO is an ephemeris of Venus in the geocentric reference frame while VTOP is an ephemeris for the same object in the TOPO reference fame for the observatory location of the VLA. With the introduction of solar system source models (Butler) in the **setjy** task, a nearly complete set of ephemerides for the larger bodies in our solar system had to be made available. These are stored in nearly the same format as the above examples VGEO and VTOP (but with a few enhancements) in directory data/ephemerides/JPL-Horizons. If your object's ephemeris is among those stored in data/ephemerides/JPL-Horizons, you can simply copy the ephemeris from there. Otherwise, you can request the ephemeris from the JPL-Horizons using the CASA commands (for example):\n",
    "\n",
    "```\n",
    "#For CASA5 (for CASA6, the location of request is TBD)\n",
    "import recipes.ephemerides.request as jplreq\n",
    "jplreq.request_from_JPL(objnam='Mars',startdate='2012-01-01',enddate='2013-12-31',date_incr='0.1 d', get_axis_orientation=False,\n",
    "get_axis_ang_orientation=True,\n",
    "get_sub_long=True, use_apparent=False, get_sep=False,\n",
    "return_address='YOUR_EMAIL_ADDESS',\n",
    "mailserver='YOUR_MAIL_SERVER_ADDRESS')\n",
    "```\n",
    "\n",
    "where you need to fill in the parameters objnam, startdate, enddate,date_incr (the time interval between individual ephemeris table entries), return_address (your email address where you want to receive the ephemeris), and mailserver (the smtp server through which you want to send the request email). The other parameters should be set as shown. Within a short time, you should receive the requested ephemeris as an email from NASA's JPL-Horizonssystem. Save the email into a file with the \"save as\" function of your mail client. See the next section on how to attach it to your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using fixplanets to attach ephemerides to a field of a MeasurementSet\n",
    "\n",
    "As of CASA 4.6.0, importasdm fills the SOURCE coodinates with the correct postions based on the ephemerides table. Alternatively, one can use the task **fixplanets** to set the ephemeris of a given field in a MeasurementSet. Here is an example:\n",
    "\n",
    "```\n",
    "fixplanets(vis='uid___A002_X1c6e54_X223.ms',\n",
    "field='Titan', fixuvw=True, direction='mytitanephemeris')\n",
    "```\n",
    "\n",
    "where you need to set the parameters vis to the name of your MS and the parameter field to the name of the field to which you want to attach the ephemeris. The parameter direction must be set to the name of your ephemeris table. Accepted formats are (a) the CASA format (as in VGEO or the ephemerides in data/ephemerides/JPL-Horizons as described above) and (b) the JPL-Horizons mail format which you obtain by saving an ephemeris email you received from JPL-Horizons. The parameter fixuvw should be set to True in order to trigger a recalculation of the UVW coordinates in your MS based on the new ephemeris. The task **fixplanets** can also be used for other field direction modifications. Please refer to the help text of the task.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Note that among the ephemerides in the directory data  /ephemerides/JPL-Horizons/ you should only use those ending in  '_J2000.tab'. They are the ones in J2000 coordinates.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use of the ephemeris after attachment\n",
    "\n",
    "Once you have attached the ephemeris to a field of an MS, it will automatically be handled in tasks like **split** and **concat** which need to hand on the ephemeris to their output MSs. In particular **concat** recognizes when fields of the MSs to be concatenated use the same ephemeris and merges these fields if the time coverage of the provided ephemeris in the first MS also covers the observation time of the second MS. The ephemeris of the field in the first MS will then be used for the merged field. In order to inspect the ephemeris attached to a field, you can find it inside the FIELD subdirectory of your MS. The optional column EPHEMERIS_ID in the FIELD table points to the running number of the ephemeris table. A value of −1 indicates that no ephemeris is attached. Note that in case an ephemeris is attached to a field, the direction column entries for that field in the FIELD table will be interpreted as an offset to the ephemeris direction and are therefore set to (0.,0.) by default. This offset feature is used in mosaic observations where several fields share the same ephemeris with different offsets. The time column in the FIELD table should be set to the beginning of the observation for that field and serves as the nominal time for ephemeris queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spectral frame transformation to the rest frame of the ephemeris object in task cvel \n",
    "\n",
    "The ephemerides contain radial velocity information. The task **cvel** can be used to transform spectral windows into the rest frame of the ephemeris object by setting the parameter outframe to \"SOURCE\" as in the following example:\n",
    "\n",
    "```\n",
    "cvel(vis='europa.ms',\n",
    "outputvis='cvel_europa.ms', outframe='SOURCE', mode = 'velocity',\n",
    "width = '0.3km/s', restfreq = '354.50547GHz')\n",
    "```\n",
    "\n",
    "This will make **cvel** perform a transformation to the GEO reference frame followed by an additional Doppler correction for the radial velocity given by the ephemeris for the each field. (Typically, this should happen after calibration and after splitting out the spectral widows and the target of interest). The result is an MS with a single combined spectral window in reference frame REST. From this frame, further transformations to other reference frames are not possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ephemerides in ALMA datasets \n",
    "\n",
    "The ALMA Science Data Model (the raw data format for ALMA data) now foresees an Ephemeris table. This feature has been in use since the beginning of ALMA Cycle 3 both for science targets and calibrator objects. With ALMA Cycle 3 (or later) datasets, the task **importasdm** will automatically translate the contents of the ASDM Ephemeris table into separate ephemeris tables in CASA format and attach them to the respective fields.\n",
    "\n",
    "In the case of mosaics, all fields belonging to a mosaic on an ephemeris object will share the same ephemeris. The individual mosaic pointings will use the offset mechanism described above to define the position of each field.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imaging ALMA observations with tclean \n",
    "\n",
    "As of CASA 5.3, the tclean task can automatically handle the imaging of ALMA observations (both single-execution and multi-execution datasets, and both single-field and mosaics) by using the new *phasecenter=\\'TRACKFIELD\\'* option. This option will use the ephemeris tables attached to each measurementSet by the ALMA control system. These tables will have ultimately been provided by the observatory for the case of large bodies (those selectable in the ALMA Observing Tool), or by the PI as attachments in the Observing Tool for the case of smaller bodies.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**WARNING***:*  if you want to use the old method of concatenating calibrated MeasurementSets by using the *forcesingleephemfield* parameter to create a common joint ephemeris table, then you must still set *phasecenter='TRACKFIELD'* in tclean order to get a sensible image, even though you are passing it only one (concatenated) MeasurementSet. If not, you may get a corrupt image, even if you select a subset of data only from the first execution block in the concatenated MS.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imaging observations from other telescopes with tclean\n",
    "\n",
    "For non-ALMA data, or to use a newer ephemeris than was available at the time of the ALMA observations, the user may set the phasecenter parameter to the name of an ephemeris file, constructed as described in the earlier section above. Alternatively, the user may set the phasecenter to the common name of the following bodies: \\'MERCURY\\', \\'VENUS\\', \\'MARS\\', \\'JUPITER\\', \\'SATURN\\', \\'URANUS\\', \\'NEPTUNE\\', \\'PLUTO\\', \\'SUN\\', \\'MOON\\', in which case the standard DE200 ephemeris table distributed with CASA will be used."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
