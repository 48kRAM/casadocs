

# Calculation of Weights for Data with Varying Integration Time 

Knowledgebase Article: Calculation of Weights for Data with Varying Integration Time

**George Moellenbrock****Original 18 Dec 2018, latest edited version 04 Nov 2019**When the nominal weights are expected to be uniform (becauseintegration time, channel bandwidth, effective Tsys, collecting area,etc. are all uniform, or the visibilities are normalized), extractingweight information from the apparent statistics of otherwise stablevisibility measurements is a simple matter of calculating the apparentsimple variance in the visibility real and imaginary parts over asufficient local sample of values. The real and imaginary partvariances should be approximately equal, and the inverse of their meanis the correct weight to assign to each of the visibility valueswithin the sample. Here, \"stable visibility\" means no *systematic*variation of amplitude or phase within the localsample. Noise-dominated visibilities are ideal; otherwise,well-calibrated data with no true visibility variation aredesirable. These conditions are also needed for the more general casedescribed below.When the integration time (aka \"exposure\") varies within the localsample (such as can be generated by averaging of the datapost-correlation, where the number of samples per averaging bin mayvary, especially at the end of scans), we expect the correct variancefor each visibility to be inversely proportional to the netintegration time, and this complicates the calculation. It isnecessary to determine a weighted variance per unit inverseintegration time, wherein the sample weights for the variancecalculation are the per-visibility integration times, e$_i$. If the onlyreason the underlying variance differs among samples is the variableintegration time, then a uniform normalized variance estimate of thewhole sample may be obtained by scaling the residual data per sampleby the square root of their (known) integration times. Here, residualdata means any underlying visibility signal\-\--presumably the averageof the visibility samples, using nominal (proportional to integrationtime, etc.) weights\-\--has been subtracted. The simple variance of thisrescaled sample is, in effect, the variance per unit inverseintegration time.For visibilities V$_i$, with integration times e$_i$:\<var$_{norm}$\> = Sum (e$_i$ (V$_i$ - \<V\>)$^2$ / N    \[1\]where \<V\> = Sum (w$_i$ V$_i$) / Sum (w$_i$)       \[1a\]and w$_i$ are the nominal data weights presumably proportional tointegration time and other relevant factors. In practice, we couldprobably just use w$_i$ = e$_i$ in equation \[1a\] since all of the otherrelevant factors witin w$_i$ are assumed constant within thesample. Note that the units of \<var$_{norm}$\> are in squared visibilityamplitude (Jy$^2$, presumably) times seconds. Note also that \<var$_{norm}$\>is essentially the simple variance of the ensemble \sqrt(e[$_i$).dV$_i$\](where dV$_i$ is (V$_i$-\<V\>)), i.e., of the residual visibilities scaledso that their noise is independent of integration time.The normalized weight-per-unit-integration time is thus the inverse of\<var$_{norm}$\>:W$_{norm}$ = 1/\<var$_{norm}$\>                      \[2\]and per-datum revised weights may be calculated as:W$_i$ = W$_{norm}$ \* e$_i$                         \[3\]Another way of arriving at this result is to calculate a weightedvariance:\<var\> = Sum (e$_i$ (V$_i$ - \<V\>)$^2$) / Sum(e$_i$)   \[4\]which corresponds to the (simple) mean exposure time, which is:\<e\> = Sum(e$_i$) / N                         \[5\]The product of these yields \<var$_{norm}$\>, as above in \[1\]:\<var$_{norm}$\> = \<var\>\<e\>                      \[6\]and W$_{norm}$ may be formed and applied as in \[2\] and \[3\] above.This calculation should be done for both real and imaginary parts ofthe visibility sample and averaged, or for both parts jointly, and \[3\]used to form the revised weights.NB: In calculating sample variance, it is generally customary toacknowledge the loss of one degree of freedom due to use of the meanvisibility, \<V\> in the calculation. Essentially, \<V\> will have afinite error that tends to bias the resulting variance downward. Forsimple variance calculations, a factor N/(N-1) is applied to thevariance calculation to unbias it, and this factor can be significantfor modest N. Since a non-trivially weighted mean is used in the above(otherwise simple, non-weighted) variance calculation (eqn \[1\]), itmay be appropriate to consider a more carefully weighted calculationfor the N/(N-1) factor. The required factor is:D = 1 - ( Sum(w$_i$\^2) / Sum(w$_i$)\^2 ) \[9\]where w$_i$ are the a priori nominal weights used in \[1a\] above. Thisfactor can be shown to equal (N-1)/N and so should be *divided* intothe \<var$_{norm}$\> result.However, since the nominal error in the variance (and thus theweights) will be \<10% (an accuracy we are unlikely to achieve ingeneral anyway) for N\>10, and will be uniform over many sample groupsin the overall statwt execution, we assume that it is adequate to use thesimpler N/(N-1) factor, or omit it entirely.

